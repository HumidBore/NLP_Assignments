{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "iE-OJaA7wap3"
      },
      "outputs": [],
      "source": [
        "#General imports\n",
        "import copy\n",
        "import os  \n",
        "import pandas as pd  \n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np  \n",
        "import re\n",
        "import seaborn as sb\n",
        "import sys \n",
        "from tqdm import tqdm\n",
        "from typing import Callable, List, Dict, Tuple, Set\n",
        "\n",
        "#sklearn and tensorflow imports\n",
        "from sklearn.metrics import f1_score\n",
        "from tensorflow.keras.layers import Bidirectional,  Dense, Dropout, Embedding, GRU, Input, LSTM, TimeDistributed\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.random import set_seed"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#fixed seeds to get reproducible results\n",
        "np.random.seed(42)\n",
        "set_seed(42)"
      ],
      "metadata": {
        "id": "OwtabSzSZIBd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXlE3OHGzaYq"
      },
      "source": [
        "#Bulding the dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQ0PSVGsWZBW"
      },
      "source": [
        "## Dataset download and extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIj22FhCyKoA",
        "outputId": "6be08319-f526-4ba0-cca7-7461a632db5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current working directory: /content\n",
            "Successful download\n",
            "Successful extraction\n"
          ]
        }
      ],
      "source": [
        "import urllib.request  #  download files\n",
        "import zipfile  #  unzip files\n",
        "\n",
        "DATASET_NAME = \"dataset.zip\"\n",
        "DATASET_FOLDERNAME = \"Dataset\"\n",
        "DATASET_SUBFOLDER = \"dependency_treebank/\"\n",
        "SPLIT_DISTRIBUTION = [100, 150, 199]\n",
        "\n",
        "working_folder = os.getcwd()\n",
        "\n",
        "print(\"Current working directory: \" + str(working_folder))\n",
        "\n",
        "dataset_folder = os.path.join(os.getcwd(), DATASET_FOLDERNAME)\n",
        "\n",
        "if not os.path.exists(dataset_folder):\n",
        "    os.makedirs(dataset_folder)\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/dependency_treebank.zip'\n",
        "\n",
        "dataset_path = os.path.join(dataset_folder, \"dataset.zip\")\n",
        "\n",
        "if not os.path.exists(dataset_path):\n",
        "    urllib.request.urlretrieve(url, dataset_path)\n",
        "    print(\"Successful download\")\n",
        "\n",
        "with zipfile.ZipFile(dataset_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(dataset_folder)\n",
        "    print(\"Successful extraction\")\n",
        "\n",
        "#update folder to the extracted one\n",
        "dataset_folder = os.path.join(dataset_folder, DATASET_SUBFOLDER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekoJOGSg7CDd",
        "outputId": "f748ed48-54d4-459f-fbb0-b1a81ffa3b78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Dataset/dependency_treebank/\n"
          ]
        }
      ],
      "source": [
        "print(dataset_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sI97CALV0C34"
      },
      "source": [
        "## Dataframe construction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JpNObbHg0HqV"
      },
      "outputs": [],
      "source": [
        "def encode_dataset(dataset_folder: str, \n",
        "                   split_dist: list(), ) -> Dict[str,pd.DataFrame]:\n",
        "    \n",
        "    df_dict = {\"train\": pd.DataFrame(columns=['sentence', 'labels']),\n",
        "                \"val\": pd.DataFrame(columns=['sentence', 'labels']),\n",
        "                \"test\":pd.DataFrame(columns=['sentence', 'labels'])}\n",
        "    split = \"\"\n",
        "\n",
        "    for filename in sorted(os.listdir(dataset_folder)):\n",
        "        file_path = os.path.join(dataset_folder, filename)\n",
        "        try:\n",
        "            if os.path.isfile(file_path):\n",
        "                with open(file_path, mode='r', encoding='utf-8') as text_file:\n",
        "                    # read it and extract \n",
        "                    document_number = filename.split(\"_\")[1].split(\".\")[0]\n",
        "                    if int(document_number) <= split_dist[0]:\n",
        "                        split = \"train\"\n",
        "                    elif split_dist[0] < int(document_number) <= split_dist[1]:\n",
        "                        split = \"val\"\n",
        "                    else:\n",
        "                        split = \"test\"\n",
        "\n",
        "                    df_file = pd.read_table(\n",
        "                        file_path, \n",
        "                        delimiter='\\t', \n",
        "                        names=['word', 'label'], \n",
        "                        usecols=[0,1],\n",
        "                        skip_blank_lines=False)\n",
        "                    \n",
        "                    #splitting file content in sentences\n",
        "                    idx = list(df_file.loc[df_file.isnull()['word']].index)\n",
        "                    idx.append(len(df_file))\n",
        "                    prev = 0\n",
        "                    for sep in idx:\n",
        "                        df_sentence = pd.DataFrame({\n",
        "                            'sentence': [df_file['word'][prev:sep].to_list()], \n",
        "                            'labels': [df_file['label'][prev:sep].to_list()]})\n",
        "                        df_dict[split] = pd.concat([df_dict[split], df_sentence], ignore_index=True)\n",
        "                        prev = sep + 1\n",
        "                    \n",
        "        except Exception as e:\n",
        "            print('Failed to process %s. Reason: %s' % (file_path, e))\n",
        "            sys.exit(0)\n",
        "\n",
        "    return df_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ocXNiUzD5bOv"
      },
      "outputs": [],
      "source": [
        "df_dict = encode_dataset(dataset_folder, SPLIT_DISTRIBUTION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "FW074bfD54DK",
        "outputId": "399f6ce2-1c23-4519-ea64-f55f555a0b68"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            sentence  \\\n",
              "0  [Pierre, Vinken, ,, 61, years, old, ,, will, j...   \n",
              "1  [Mr., Vinken, is, chairman, of, Elsevier, N.V....   \n",
              "2  [Rudolph, Agnew, ,, 55, years, old, and, forme...   \n",
              "3  [A, form, of, asbestos, once, used, to, make, ...   \n",
              "4  [The, asbestos, fiber, ,, crocidolite, ,, is, ...   \n",
              "\n",
              "                                              labels  \n",
              "0  [NNP, NNP, ,, CD, NNS, JJ, ,, MD, VB, DT, NN, ...  \n",
              "1  [NNP, NNP, VBZ, NN, IN, NNP, NNP, ,, DT, NNP, ...  \n",
              "2  [NNP, NNP, ,, CD, NNS, JJ, CC, JJ, NN, IN, NNP...  \n",
              "3  [DT, NN, IN, NN, RB, VBN, TO, VB, NNP, NN, NNS...  \n",
              "4  [DT, NN, NN, ,, NN, ,, VBZ, RB, JJ, IN, PRP, V...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3f1d99a8-2801-49af-9281-72a88376ef4d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Pierre, Vinken, ,, 61, years, old, ,, will, j...</td>\n",
              "      <td>[NNP, NNP, ,, CD, NNS, JJ, ,, MD, VB, DT, NN, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Mr., Vinken, is, chairman, of, Elsevier, N.V....</td>\n",
              "      <td>[NNP, NNP, VBZ, NN, IN, NNP, NNP, ,, DT, NNP, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[Rudolph, Agnew, ,, 55, years, old, and, forme...</td>\n",
              "      <td>[NNP, NNP, ,, CD, NNS, JJ, CC, JJ, NN, IN, NNP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[A, form, of, asbestos, once, used, to, make, ...</td>\n",
              "      <td>[DT, NN, IN, NN, RB, VBN, TO, VB, NNP, NN, NNS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[The, asbestos, fiber, ,, crocidolite, ,, is, ...</td>\n",
              "      <td>[DT, NN, NN, ,, NN, ,, VBZ, RB, JJ, IN, PRP, V...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3f1d99a8-2801-49af-9281-72a88376ef4d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3f1d99a8-2801-49af-9281-72a88376ef4d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3f1d99a8-2801-49af-9281-72a88376ef4d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df_dict[\"train\"].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "kinbChSf56cz",
        "outputId": "ddc0779c-f71e-42cc-dfdc-c1824015d2e6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            sentence  \\\n",
              "0  [A, House-Senate, conference, approved, major,...   \n",
              "1  [For, the, Agency, for, International, Develop...   \n",
              "2  [The, conference, approved, at, least, $, 55, ...   \n",
              "3  [The, agreement, on, Poland, contrasts, with, ...   \n",
              "4  [These, fiscal, pressures, are, also, a, facto...   \n",
              "\n",
              "                                              labels  \n",
              "0  [DT, NNP, NN, VBD, JJ, NNS, IN, DT, NN, IN, JJ...  \n",
              "1  [IN, DT, NNP, IN, NNP, NNP, ,, NNS, VBD, $, CD...  \n",
              "2  [DT, NN, VBD, IN, JJS, $, CD, CD, IN, JJ, NN, ...  \n",
              "3  [DT, NN, IN, NNP, VBZ, IN, DT, JJ, NNS, VBG, I...  \n",
              "4  [DT, JJ, NNS, VBP, RB, DT, NN, IN, VBG, DT, NN...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7446a6d5-b818-4412-812d-1ccb514f091f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[A, House-Senate, conference, approved, major,...</td>\n",
              "      <td>[DT, NNP, NN, VBD, JJ, NNS, IN, DT, NN, IN, JJ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[For, the, Agency, for, International, Develop...</td>\n",
              "      <td>[IN, DT, NNP, IN, NNP, NNP, ,, NNS, VBD, $, CD...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[The, conference, approved, at, least, $, 55, ...</td>\n",
              "      <td>[DT, NN, VBD, IN, JJS, $, CD, CD, IN, JJ, NN, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[The, agreement, on, Poland, contrasts, with, ...</td>\n",
              "      <td>[DT, NN, IN, NNP, VBZ, IN, DT, JJ, NNS, VBG, I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[These, fiscal, pressures, are, also, a, facto...</td>\n",
              "      <td>[DT, JJ, NNS, VBP, RB, DT, NN, IN, VBG, DT, NN...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7446a6d5-b818-4412-812d-1ccb514f091f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7446a6d5-b818-4412-812d-1ccb514f091f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7446a6d5-b818-4412-812d-1ccb514f091f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df_dict[\"val\"].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "D7U5NfKo57x6",
        "outputId": "fa42169f-73d1-4d74-fa0a-1d952eca88ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            sentence  \\\n",
              "0  [Intelogic, Trace, Inc., ,, San, Antonio, ,, T...   \n",
              "1  [The, move, boosts, Intelogic, Chairman, Asher...   \n",
              "2  [Mr., Ackerman, already, is, seeking, to, oust...   \n",
              "3  [The, action, followed, by, one, day, an, Inte...   \n",
              "4  [In, New, York, Stock, Exchange, composite, tr...   \n",
              "\n",
              "                                              labels  \n",
              "0  [NNP, NNP, NNP, ,, NNP, NNP, ,, NNP, ,, VBD, P...  \n",
              "1  [DT, NN, VBZ, NNP, NNP, NNP, NNP, POS, NN, TO,...  \n",
              "2  [NNP, NNP, RB, VBZ, VBG, TO, VB, NNP, NNP, IN,...  \n",
              "3  [DT, NN, VBN, IN, CD, NN, DT, NNP, NN, IN, PRP...  \n",
              "4  [IN, NNP, NNP, NNP, NNP, JJ, NN, NN, ,, NNP, N...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-96d58dd9-2837-45f0-8e89-35a7883216c0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Intelogic, Trace, Inc., ,, San, Antonio, ,, T...</td>\n",
              "      <td>[NNP, NNP, NNP, ,, NNP, NNP, ,, NNP, ,, VBD, P...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[The, move, boosts, Intelogic, Chairman, Asher...</td>\n",
              "      <td>[DT, NN, VBZ, NNP, NNP, NNP, NNP, POS, NN, TO,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[Mr., Ackerman, already, is, seeking, to, oust...</td>\n",
              "      <td>[NNP, NNP, RB, VBZ, VBG, TO, VB, NNP, NNP, IN,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[The, action, followed, by, one, day, an, Inte...</td>\n",
              "      <td>[DT, NN, VBN, IN, CD, NN, DT, NNP, NN, IN, PRP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[In, New, York, Stock, Exchange, composite, tr...</td>\n",
              "      <td>[IN, NNP, NNP, NNP, NNP, JJ, NN, NN, ,, NNP, N...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-96d58dd9-2837-45f0-8e89-35a7883216c0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-96d58dd9-2837-45f0-8e89-35a7883216c0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-96d58dd9-2837-45f0-8e89-35a7883216c0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df_dict[\"test\"].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "e2i-qWdRdjV-"
      },
      "outputs": [],
      "source": [
        "x = {\"train\": df_dict['train']['sentence'],\n",
        "     \"val\": df_dict['val']['sentence'],\n",
        "     \"test\": df_dict['test']['sentence']}\n",
        "\n",
        "y = {\"train\": df_dict['train']['labels'],\n",
        "     \"val\": df_dict['val']['labels'],\n",
        "     \"test\": df_dict['test']['labels']}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vf1URJEz-ADo"
      },
      "source": [
        "# Glove Embedding model, vocabulary and OOV detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0Xhe6fjWvqv"
      },
      "source": [
        "## Load Glove embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "S5nCta0f9_X0"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "import gensim.downloader as gloader\n",
        "\n",
        "def load_GloVe_embedding(embedding_dimension: int = 50) -> gensim.models.keyedvectors.KeyedVectors:\n",
        "    \"\"\"\n",
        "    Loads a pre-trained word embedding model via gensim library.\n",
        "\n",
        "    :param embedding_dimension: size of the embedding space to consider\n",
        "\n",
        "    :return\n",
        "        - pre-trained word embedding model (gensim KeyedVectors object)\n",
        "    \"\"\"\n",
        "    download_path = \"glove-wiki-gigaword-{}\".format(embedding_dimension)\n",
        "    try:\n",
        "        emb_model = gloader.load(download_path)\n",
        "    except ValueError as e:\n",
        "        print(\"Invalid embedding model name! Check the embedding dimension:\")\n",
        "        print(\"Glove: 50, 100, 200, 300\")\n",
        "        raise e\n",
        "\n",
        "    return emb_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afdQh5i8CDsh",
        "outputId": "9ccc2841-b989-4269-c4e3-a2b4130b2aa0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 66.0/66.0MB downloaded\n"
          ]
        }
      ],
      "source": [
        "EMBEDDING_DIMENSION = 50\n",
        "glove_emb_model = load_GloVe_embedding(EMBEDDING_DIMENSION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZUuz-bW_BO3"
      },
      "source": [
        "##Creating initial vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "l98tkgAW_DGT"
      },
      "outputs": [],
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "def build_vocabulary(sr: pd.Series) -> List[str]:\n",
        "    \"\"\"\n",
        "    Given a dataset, builds the corresponding word vocabulary.\n",
        "\n",
        "    :param df: dataset from which we want to build the word vocabulary (pandas.DataFrame)\n",
        "    :return:\n",
        "      - vocabulary: set of unique terms that build up the vocabulary\n",
        "    \"\"\"\n",
        "    vocabulary = []\n",
        "    for sentence in tqdm(sr):\n",
        "        for token in sentence:\n",
        "            if token not in vocabulary:\n",
        "                vocabulary.append(token)\n",
        "\n",
        "    return vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9D37IdA4AeHo",
        "outputId": "ac6b70fa-7308-4c14-b8ab-906e067d4931"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1963/1963 [00:00<00:00, 2087.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Debug] train vocabulary size: 8009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1299/1299 [00:00<00:00, 2581.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Debug] val vocabulary size: 5892\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 652/652 [00:00<00:00, 4056.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Debug] test vocabulary size: 3623\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "vocabulary_dict = {}\n",
        "for split in df_dict.keys():\n",
        "    vocabulary_dict[split] = build_vocabulary(x[split])\n",
        "    print()\n",
        "    print(f'[Debug] {split} vocabulary size: {len(vocabulary_dict[split])}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzQ6qRPF_86z"
      },
      "source": [
        "## OOV detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "hvm7cbv1BYtq"
      },
      "outputs": [],
      "source": [
        "def check_OOV_terms(vocabulary: List[str],\n",
        "                    word_listing: List[str]):\n",
        "    \"\"\"\n",
        "    Checks differences between pre-trained embedding model vocabulary\n",
        "    and dataset specific vocabulary in order to highlight out-of-vocabulary terms.\n",
        "\n",
        "    :param embedding_model: pre-trained word embedding model (gensim wrapper)\n",
        "    :param word_listing: dataset specific vocabulary (list)\n",
        "\n",
        "    :return\n",
        "        - list of OOV terms\n",
        "    \"\"\"\n",
        "    embedding_vocabulary = set(vocabulary)\n",
        "    oov = set(word_listing).difference(embedding_vocabulary)\n",
        "    return list(oov)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2MnS5ilADqv",
        "outputId": "b487dfc2-6d33-47a6-b8bd-24736e1ef734"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total OOV terms: 2346 (29.29%)\n"
          ]
        }
      ],
      "source": [
        "OOV1 = check_OOV_terms(glove_emb_model.vocab.keys(), vocabulary_dict[\"train\"])\n",
        "OOV1_percentage = float(len(OOV1)) * 100 / len(vocabulary_dict[\"train\"])\n",
        "print(f\"Total OOV terms: {len(OOV1)} ({OOV1_percentage:.2f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPySrACEC5D3"
      },
      "source": [
        "A lot of words are OOV simply because they start with capital letter, so we will lower all the words and check again the OOV. Before this section we can insert a graph showing the OOV words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CB364Xx_C2vo",
        "outputId": "aef7585e-462e-47dd-a6a5-88de1c394148"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total OOV terms: 359 (4.48%)\n"
          ]
        }
      ],
      "source": [
        "OOV1_lowercase = check_OOV_terms(glove_emb_model.vocab.keys(), [v.lower() for v in vocabulary_dict[\"train\"]])\n",
        "OOV1_lowercase_percentage = float(len(OOV1_lowercase)) * 100 / len(vocabulary_dict[\"train\"])\n",
        "print(f\"Total OOV terms: {len(OOV1_lowercase)} ({OOV1_lowercase_percentage:.2f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWzR_D1dGI-u",
        "outputId": "b7eda733-b7d5-463f-defa-456c8e3738e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "737.5\n",
            "415.8\n",
            "pramual\n",
            "custom-chip\n",
            "akerfeldt\n",
            "95,142\n",
            "money-market\n",
            "twindam\n",
            "3\\/4\n",
            "money-fund\n",
            "two-sevenths\n",
            "12,252\n",
            "post-hearing\n",
            "recession-inspired\n",
            "school-research\n",
            "meinders\n",
            "2,303,328\n",
            "capital-gains\n",
            "382-37\n",
            "macheski\n",
            "antitrust-law\n",
            "mehrens\n",
            "100,980\n",
            "derel\n",
            "glenham\n",
            "234.4\n",
            "stock-manipulation\n",
            "bridgestone\\/firestone\n",
            "ensrud\n",
            "times-stock\n",
            "pattenden\n",
            "roof-crush\n",
            "2645.90\n",
            "chemplus\n",
            "social-studies\n",
            "flightiness\n",
            "moleculon\n",
            "1.457\n",
            "374.19\n",
            "investor-relations\n",
            "456.64\n",
            "index-arbitrage\n",
            "re-thought\n",
            "unfair-trade\n",
            "revenue-desperate\n",
            "circuit-breaker\n",
            "superpremiums\n",
            "more-efficient\n",
            "autions\n",
            "4.898\n",
            "centerbank\n",
            "subminimum\n",
            "38.375\n",
            "mortgage-based\n",
            "ac-130u\n",
            "purepac\n",
            "dollar-yen\n",
            "374.20\n",
            "-rrb-\n",
            "durable-goods\n",
            "bumkins\n",
            "landonne\n",
            "three-sevenths\n",
            "wheel-loader\n",
            "lap-shoulder\n",
            "271,124\n",
            "16,072\n",
            "home-market\n",
            "chilver\n",
            "trading-company\n",
            "ariail\n",
            "lezovich\n",
            "macmillan\\/mcgraw-hill\n",
            "forest-products\n",
            "415.6\n",
            "cray-3\n",
            "computer-system-design\n",
            "automotive-parts\n",
            "4,393,237\n",
            "wine-buying\n",
            "kalipharma\n",
            "37-a-share\n",
            "cotran\n",
            "buttoned-down\n",
            "top-yielding\n",
            "foreign-stock\n",
            "ntg\n",
            "test-prep\n",
            "1\\/4\n",
            "tissue-transplant\n",
            "beer-belly\n",
            "energy-services\n",
            "old-house\n",
            "integra-a\n",
            "solaia\n",
            "training-wage\n",
            "incentive-bonus\n",
            "cash-rich\n",
            "weisfield\n",
            "trockenbeerenauslesen\n",
            "3057\n",
            "stirlen\n",
            "446.62\n",
            "senate-house\n",
            "test-coaching\n",
            "tiphook\n",
            "sticker-shock\n",
            "rapanelli\n",
            "nekoosa\n",
            "520-lawyer\n",
            "detective-story\n",
            "lower-priority\n",
            "water-authority\n",
            "industrial-production\n",
            "subskills\n",
            "nissho-iwai\n",
            "gingl\n",
            "product-design\n",
            "bellringers\n",
            "low-ball\n",
            "82,389\n",
            "sometimes-exhausting\n",
            "500,004\n",
            "5\\/8\n",
            "hallwood\n",
            "twin-jet\n",
            "non-encapsulating\n",
            "language-housekeeper\n",
            "cop-killer\n",
            "ft-se\n",
            "449.04\n",
            "sport-utility\n",
            "sub-segments\n",
            "direct-investment\n",
            "futures-related\n",
            "we-japanese\n",
            "chinchon\n",
            "alurralde\n",
            "436.01\n",
            "vitulli\n",
            "9,118\n",
            "market-share\n",
            "wfrr\n",
            "3.253\n",
            "replacement-car\n",
            "sino-u.s.\n",
            "nearly-30\n",
            "safe-deposit\n",
            "230-215\n",
            "high-rate\n",
            "sometimes-tawdry\n",
            "test-practice\n",
            "romanee-conti\n",
            "six-packs\n",
            "auto-safety\n",
            "nesb\n",
            "one-upsmanship\n",
            "wtd\n",
            "subskill\n",
            "trettien\n",
            "malizia\n",
            "search-and-seizure\n",
            "-rcb-\n",
            "bald-faced\n",
            "11,762\n",
            "yeargin\n",
            "test-preparation\n",
            "wheeland\n",
            "pianist-comedian\n",
            "drag-down\n",
            "sell-offs\n",
            "rexinger\n",
            "ingersoll-rand\n",
            "1\\/10th\n",
            "asset-sale\n",
            "video-viewing\n",
            "equal-opportunity\n",
            "red-flag\n",
            "143.80\n",
            "creator's\n",
            "rope-sight\n",
            "bell-ringer\n",
            "90-cent-an-hour\n",
            "building-products\n",
            "uzi-model\n",
            "savers\\/investors\n",
            "government-certified\n",
            "forest-product\n",
            "nih-appointed\n",
            "361,376\n",
            "352.7\n",
            "securities-based\n",
            "odd-sounding\n",
            "veselich\n",
            "127.03\n",
            "30,841\n",
            "stock-index\n",
            "life-insurance\n",
            "new-home\n",
            "aslacton\n",
            "church-goers\n",
            "sogo-shosha\n",
            "merger-related\n",
            "7\\/8\n",
            "school-improvement\n",
            "northy\n",
            "family-planning\n",
            "samnick\n",
            "electric-utility\n",
            "c-90\n",
            "fetal-tissue\n",
            "deposits-a\n",
            "small-company\n",
            "security-type\n",
            "collective-bargaining\n",
            "less-serious\n",
            "ctbs\n",
            "preparatives\n",
            "jerritts\n",
            "mouth-up\n",
            "lafite-rothschild\n",
            "besuboru\n",
            "big-ticket\n",
            "low-ability\n",
            "built-from-kit\n",
            "side-crash\n",
            "1.8415\n",
            "143.08\n",
            "limited-partnership\n",
            "achievement-test\n",
            "coche-dury\n",
            "high-balance\n",
            "143.93\n",
            "eight-count\n",
            "norwick\n",
            "69-point\n",
            "page-one\n",
            "corton-charlemagne\n",
            "college-bowl\n",
            "student-test\n",
            "floating-rate\n",
            "sanderoff\n",
            "abortion-related\n",
            "automotive-lighting\n",
            "62%-owned\n",
            "ratners\n",
            "muscolina\n",
            "program-trading\n",
            "synergistics\n",
            "school-district\n",
            "ghkm\n",
            "identity-management\n",
            "142.85\n",
            "705.6\n",
            "nagymaros\n",
            "prize-fighter\n",
            "non-biodegradable\n",
            "84-month\n",
            "sacramento-based\n",
            "year-earlier\n",
            "anti-abortionists\n",
            "savings-and-loan\n",
            "pennview\n",
            "light-truck\n",
            "c.j.b.\n",
            "dust-up\n",
            "chafic\n",
            "chong-sik\n",
            "telephone-information\n",
            "unenticing\n",
            "state-supervised\n",
            "greenmailer\n",
            "intellectual-property\n",
            "236.79\n",
            "six-bottle\n",
            "makato\n",
            "one-country\n",
            "drobnick\n",
            "war-rationed\n",
            "497.34\n",
            "index-options\n",
            "8300s\n",
            "pathlogy\n",
            "school-board\n",
            "anti-takeover\n",
            "5.276\n",
            "index-related\n",
            "erbamont\n",
            "change-ringing\n",
            "when-issued\n",
            "teacher-cadet\n",
            "sub-markets\n",
            "tarwhine\n",
            "computer-driven\n",
            "rate-sensitive\n",
            "morale-damaging\n",
            "yen-denominated\n",
            "macmillan\\/mcgraw\n",
            "thin-lipped\n",
            "machine-gun-toting\n",
            "foreign-led\n",
            "amphobiles\n",
            "236.74\n",
            "micronite\n",
            "62.625\n",
            "anti-china\n",
            "hummerstone\n",
            "16.125\n",
            "co-developers\n",
            "-lrb-\n",
            "iran\\/contra\n",
            "13,056\n",
            "jalaalwalikraam\n",
            "mininum-wage\n",
            "front-seat\n",
            "red-blooded\n",
            "car-safety\n",
            "biondi-santi\n",
            "three-lawyer\n",
            "-lcb-\n",
            "278.7\n",
            "3,288,453\n",
            "univest\n",
            "1.5755\n",
            "polyproplene\n",
            "dead-eyed\n",
            "highest-pitched\n",
            "retin-a\n",
            "money-center\n",
            "shirt-sleeved\n",
            "delwin\n",
            "pre-1917\n",
            "colonsville\n",
            "pre-1933\n",
            "higher-salaried\n",
            "marketing-communications\n",
            "year-ago\n",
            "rubinfien\n",
            "70-a-share\n",
            "boorse\n",
            "purhasing\n",
            "crocidolite\n",
            "junk-bond\n",
            "sharedata\n",
            "subindustry\n",
            "yen-support\n",
            "satrum\n",
            "summer\\/winter\n",
            "one-yen\n",
            "1\\/2\n",
            "food-shop\n",
            "nipponese\n",
            "pro-forma\n",
            "secilia\n",
            "bermuda-based\n",
            "monchecourt\n",
            "14,821\n",
            "18,444\n",
            "vinken\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\".join(OOV1_lowercase))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5RNdNYYHYwQ"
      },
      "source": [
        "# Preprocessing\n",
        "\n",
        "Here we replace bracket value with their symbols: \n",
        "```\n",
        "  -lrb- and -lcb-   -->  ( \n",
        "  -rrb- and -rcb-   -->  )\n",
        "```\n",
        "\n",
        "In addition, all the rational numbers will be replaced with the placeholder #number#, as long as the floating point numbers.\n",
        "Note that rational numbers, instead of being like 3/4, are written as 3\\/4. The cause is that symbol \"/\" is represented using \"\\/\", as this happens also in other words that are notrational ones\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "d9H61yyiHYbT"
      },
      "outputs": [],
      "source": [
        "def preprocessing(content_list: List[str]) -> List[str]:\n",
        "    placeholder = \"#number#\"\n",
        "    re_slashes = re.compile('\\\\\\/')  #pattern \\/ \n",
        "    re_rational = re.compile('\\d+\\/\\d+')  #pattern rational number (e.g. 1/5)\n",
        "    re_number = re.compile('[+-]?(\\d*[.])\\d+')  #pattern decimal number (e.g. 3.14)\n",
        "    re_left_bracket = re.compile('(-lrb-)|(-lcb-)')  #pattern left bracket\n",
        "    re_right_bracket = re.compile('(-rrb-)|(-rcb-)')  #pattern right bracket\n",
        "    re_slashed_words = re.compile(\"(\\w*)\\/(\\w*)\")  #a slash separating words will be replaced with a dash, following the trend of the dataset, where composed words are in the form word-word\n",
        "\n",
        "    content_list_preprocessed = [content.lower() for content in content_list]\n",
        "    content_list_preprocessed = [re_slashes.sub(\"/\", content) for content in content_list_preprocessed]\n",
        "    content_list_preprocessed = [re_left_bracket.sub(\"(\", content) for content in content_list_preprocessed]\n",
        "    content_list_preprocessed = [re_right_bracket.sub(\")\", content) for content in content_list_preprocessed]\n",
        "    content_list_preprocessed = [placeholder if re.match(re_rational, content) else content for content in content_list_preprocessed]\n",
        "    content_list_preprocessed = [placeholder if re.match(re_number, content) else content for content in content_list_preprocessed]\n",
        "    content_list_preprocessed = [content.replace(\"/\", \"-\") if re.match(re_slashed_words, content) else content for content in content_list_preprocessed]\n",
        "\n",
        "    return content_list_preprocessed\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzNl0nSGdEwd"
      },
      "source": [
        "Preprocessing the training dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "GyjnI2JZbADI"
      },
      "outputs": [],
      "source": [
        "x_train_preprocessed = x[\"train\"].apply(preprocessing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-Vw8s63garq"
      },
      "source": [
        "Building the new vocabulary after preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcxlVwQFgaRr",
        "outputId": "617e167c-3248-401b-a2e9-21ef7d8344fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1963/1963 [00:00<00:00, 2256.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Debug] train vocabulary size after preprocessing: 7214\n",
            "Total OOV terms: 318 (4.41%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train_vocabulary_preprocessed = build_vocabulary(x_train_preprocessed)\n",
        "print()\n",
        "print(f'[Debug] train vocabulary size after preprocessing: {len(train_vocabulary_preprocessed)}')\n",
        "\n",
        "OOV1_preprocessed = check_OOV_terms(glove_emb_model.vocab.keys(), train_vocabulary_preprocessed)\n",
        "OOV1_preprocessed_percentage = float(len(OOV1_preprocessed)) * 100 / len(train_vocabulary_preprocessed)\n",
        "print(f\"Total OOV terms: {len(OOV1_preprocessed)} ({OOV1_preprocessed_percentage:.2f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5OLPRGc6svj"
      },
      "source": [
        "It can be seen that the number of OOV words has plummetted with respect to the the non preprocessed data. Similarly to train data, we apply preprocessing to validation and test splits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "MEec69AT_KEw"
      },
      "outputs": [],
      "source": [
        "x_pre = {\"train\": x_train_preprocessed,\n",
        "        \"val\": x[\"val\"].apply(preprocessing),\n",
        "        \"test\": x[\"test\"].apply(preprocessing)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EElOhl9F-x9-"
      },
      "source": [
        "# Vocabulary creation and mapping\n",
        "Since we want to work with numerical data only, we will mapp words and pos (labels) to numbers. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "_j91cRBqAN1x"
      },
      "outputs": [],
      "source": [
        "# Methods to create mapping\n",
        "\n",
        "#adds oov words at the end of vocabulary\n",
        "def extend_vocabulary(word_to_idx_original: Dict[str, int],\n",
        "                      words_to_add) -> Tuple[Dict[str, int],Dict[int, str]]:\n",
        "  \"\"\"\n",
        "    Given mapping between word and indeces, adds new words.\n",
        "\n",
        "    :param word_to_idx_original: dictionary with key=word and value=index to which the word is mapped\n",
        "    :return:\n",
        "      - word_to_idx_extended: word_to_idx with new words\n",
        "      - idx_to_word_extended: swapped version of word_to_idx_extended (keys and values are swapped)\n",
        "  \"\"\"\n",
        "  word_to_idx_extended = copy.deepcopy(word_to_idx_original)  #deep copy is needed, otherwise python does not create a copy but only a reference to the already existing object, thus reflecting changes on both\n",
        "  idx = len(word_to_idx_extended.keys())\n",
        "  if idx == 0: \n",
        "    idx = 1  #position 0 is reserved\n",
        "\n",
        "  for sentence in words_to_add:\n",
        "      for token in sentence:\n",
        "          if token not in word_to_idx_extended:\n",
        "              word_to_idx_extended[token] = idx \n",
        "              idx += 1\n",
        "  idx_to_word_extended = {v: k for k, v in word_to_idx_extended.items()}\n",
        "\n",
        "  return word_to_idx_extended, idx_to_word_extended\n",
        "\n",
        "def encode_into_numbers(sentences: List[str],\n",
        "                        word_to_idx_mapping: Dict[str, int]) -> List[int]:\n",
        "    \"\"\"\n",
        "    Return a list of sequences encoded into integers following the mapping of the vocabulary\n",
        "    \"\"\"\n",
        "    encoded_data = [[word_to_idx_mapping[token] for token in sentence] for sentence in sentences]\n",
        " \n",
        "    return encoded_data\n",
        "\n",
        "def decode_into_words(encoded_sentences: List[str],\n",
        "                        idx_to_word_mapping: Dict[int,str]) -> List[str]:\n",
        "    \"\"\"\n",
        "    Return a list of sequences decoded back to words following the (reverse) mapping of the vocabulary\n",
        "    \"\"\"\n",
        "    decoded_data = [[idx_to_word_mapping[index] for index in sentence] for sentence in encoded_sentences]\n",
        " \n",
        "    return decoded_data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HV32wJ90RamP"
      },
      "source": [
        "Encoding the words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbeQJNAlEzl2",
        "outputId": "87434aed-69c7-4391-87e9-de37f174893a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train vocabulary size:  400318\n",
            "Val vocabulary size:  400475\n",
            "Test vocabulary size:  400571\n"
          ]
        }
      ],
      "source": [
        "#creating vocabulary mapping for the words in the data set\n",
        "#Note that they are incremental, this means that the val vocabulary includes the rain one, and the test one inlcudes train and val ones\n",
        "#This has been made according to the guidelines on the construction of V1, V2, V3, V4. \n",
        "#All in all, the complete vocabulary is the one with _test suffix\n",
        "#In the embedding section the intermediate vocabularies will be used according to what they contain. For example, to compute the embedding matrix on the train set, we will use word_to_idx_train, while for validation word_to_idx_val\n",
        "word_to_idx_train, idx_to_word_train = extend_vocabulary({}, [glove_emb_model.vocab.keys()] + x_pre[\"train\"].tolist())\n",
        "print(\"Train vocabulary size: \", len(word_to_idx_train))\n",
        "word_to_idx_val, idx_to_word_val = extend_vocabulary(word_to_idx_train, x_pre[\"val\"].tolist())\n",
        "print(\"Val vocabulary size: \", len(word_to_idx_val))\n",
        "word_to_idx_test, idx_to_word_test = extend_vocabulary(word_to_idx_val, x_pre[\"test\"].tolist())\n",
        "print(\"Test vocabulary size: \", len(word_to_idx_test))\n",
        "\n",
        "#encoding the data set\n",
        "\n",
        "x_enc = {\"train\": encode_into_numbers(x_pre[\"train\"].tolist(), word_to_idx_train),\n",
        "        \"val\": encode_into_numbers(x_pre[\"val\"].tolist(), word_to_idx_val),\n",
        "        \"test\": encode_into_numbers(x_pre[\"test\"].tolist(), word_to_idx_test)}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGsgMfcmRUIN"
      },
      "source": [
        "Encoding the labels (pos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PzlKA-eHJBr",
        "outputId": "84e42d96-a34f-4402-a60e-f3bfaed48cb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In the dataset there are 45 distinct POS\n"
          ]
        }
      ],
      "source": [
        "#creating vocabulary mapping for the labels in the whole dataset\n",
        "label_to_idx, idx_to_label = extend_vocabulary({},  y[\"train\"].tolist() + y[\"val\"].tolist() + y[\"test\"].tolist())\n",
        "\n",
        "y_enc = {\"train\": encode_into_numbers(y[\"train\"].tolist(), label_to_idx),\n",
        "        \"val\": encode_into_numbers(y[\"val\"].tolist(), label_to_idx),\n",
        "        \"test\": encode_into_numbers(y[\"test\"].tolist(), label_to_idx)}\n",
        "\n",
        "number_pos = len(label_to_idx)\n",
        "print(f\"In the dataset there are {number_pos} distinct POS\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdwaxJlw3AV0",
        "outputId": "2d7b37dc-737d-4a84-8293-7a2cdbe02ec2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5030, 400001, 2, 4979, 83, 168, 2, 44, 1430, 1, 535, 20, 8, 128565, 370, 2344, 1264, 3]\n",
            "[['pierre', 'vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'nov.', '29', '.']]\n",
            "['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.']\n"
          ]
        }
      ],
      "source": [
        "print(x_enc[\"train\"][0])\n",
        "print(decode_into_words([x_enc[\"train\"][0]], idx_to_word_test))\n",
        "print(df_dict[\"train\"][\"sentence\"].iloc[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3G3-Pbx3ZmJ",
        "outputId": "6db368e7-13e6-400b-ed05-e5a3d2a20590"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['NNP', 'NNP', ',', 'CD', 'NNS', 'JJ', ',', 'MD', 'VB', 'DT', 'NN', 'IN', 'DT', 'JJ', 'NN', 'NNP', 'CD', '.']]\n",
            "['NNP', 'NNP', ',', 'CD', 'NNS', 'JJ', ',', 'MD', 'VB', 'DT', 'NN', 'IN', 'DT', 'JJ', 'NN', 'NNP', 'CD', '.']\n",
            "[1, 1, 2, 3, 4, 5, 2, 6, 7, 8, 9, 10, 8, 5, 9, 1, 3, 11]\n"
          ]
        }
      ],
      "source": [
        "print(decode_into_words([y_enc[\"train\"][0]], idx_to_label))\n",
        "print(df_dict[\"train\"][\"labels\"].iloc[0])\n",
        "print(y_enc[\"train\"][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAv5AHB_REM5"
      },
      "source": [
        "# Embedding matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "QGCi8pguRH-5"
      },
      "outputs": [],
      "source": [
        "def get_dashed_embeddings(embedding_model, word):\n",
        "  if \"-\" in word:\n",
        "    words_split = word.split(\"-\")\n",
        "    words_split.sort(key=len)  #getting the encoding of compound words starting from the longest one\n",
        "    for word_piece in words_split:\n",
        "      try:\n",
        "        return embedding_model[word]  #if a word is found, assign its embedding to the matrix element\n",
        "      except:\n",
        "        pass  #if a word is not found, do nothing\n",
        "  return None\n",
        "\n",
        "def build_embedding_matrix(embedding_model: gensim.models.keyedvectors.KeyedVectors,\n",
        "                           embedding_dimension: int,\n",
        "                           word_to_idx: Dict[str, int]) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Builds the embedding matrix of a specific dataset given a pre-trained word embedding model\n",
        "\n",
        "    :param embedding_model: pre-trained word embedding model (gensim wrapper)\n",
        "    :param embedding_dimension: \n",
        "\n",
        "    :return\n",
        "        - embedding matrix that assigns a high dimensional vector to each word in the dataset specific vocabulary (shape |V| x d)\n",
        "    \"\"\"\n",
        "    embedding_matrix = np.zeros((len(word_to_idx)+1, embedding_dimension), dtype=np.float32)\n",
        "    \n",
        "    #adding all GloVe vocabularies embeddings\n",
        "    for word, idx in tqdm(word_to_idx.items()):\n",
        "      if word in embedding_model:\n",
        "          embedding_matrix[idx] = embedding_model[word]\n",
        "      else: \n",
        "          dashed_embedding = get_dashed_embeddings(embedding_model, word)\n",
        "          if dashed_embedding is None: #it means that word has no dash or all its subwords are oov\n",
        "              dashed_embedding = np.random.uniform(low=-0.05, high=0.05, size=embedding_dimension)\n",
        "          embedding_matrix[idx] = dashed_embedding\n",
        " \n",
        "    return embedding_matrix\n",
        "\n",
        "\n",
        "#This functions adds the embedding of OOV words to the embedding matrix. Note tht it directly tries to find an embedding for dashed words and if none is retrieved it uses a uniform random distribution\n",
        "def extend_embedding_matrix(embedding_model: gensim.models.keyedvectors.KeyedVectors,\n",
        "                            embedding_matrix: np.ndarray,\n",
        "                            word_to_idx: Dict[str, int]) -> np.ndarray:\n",
        "\n",
        "    oov_terms = [key for key, idx in word_to_idx.items() if idx >= embedding_matrix.shape[0]] #all the terms with mapped to an index gretaer than the vocabulary size (number of rows) are not in the embedding matrix \n",
        "    oov_embedding_matrix = np.zeros((len(oov_terms), embedding_matrix.shape[1]), dtype=np.float32)\n",
        "    \n",
        "    for idx, oov in enumerate(oov_terms):\n",
        "        dashed_embedding = get_dashed_embeddings(embedding_model, oov)\n",
        "        if dashed_embedding is None: #it means that word has no dash or all its subwords are oov\n",
        "            dashed_embedding = np.random.uniform(low=-0.05, high=0.05, size=embedding_matrix.shape[1])\n",
        "\n",
        "        oov_embedding_matrix[idx] = dashed_embedding\n",
        "\n",
        "    return np.concatenate([embedding_matrix, oov_embedding_matrix], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERNzAqnMELNB",
        "outputId": "12b15c22-d828-4a3b-e529-32df3f231ac6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400318/400318 [00:00<00:00, 418470.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(400319, 50)\n",
            "(400475, 50)\n",
            "(400571, 50)\n"
          ]
        }
      ],
      "source": [
        "embedding_matrix = build_embedding_matrix(glove_emb_model, \n",
        "                                          EMBEDDING_DIMENSION,\n",
        "                                          word_to_idx_train)\n",
        "print(embedding_matrix.shape)\n",
        "\n",
        "embedding_matrix = extend_embedding_matrix(glove_emb_model, \n",
        "                                          embedding_matrix,\n",
        "                                          word_to_idx_val)\n",
        "print(embedding_matrix.shape)\n",
        "\n",
        "embedding_matrix = extend_embedding_matrix(glove_emb_model, \n",
        "                                          embedding_matrix,\n",
        "                                          word_to_idx_test)\n",
        "print(embedding_matrix.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nH2_yE1B5Lc",
        "outputId": "ce558c40-e77e-47c0-f0b1-aedfbb90f37e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vinken\n"
          ]
        }
      ],
      "source": [
        "print(idx_to_word_train[400001])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z88wYmcqBftt",
        "outputId": "ceb0df08-c8ba-4f35-fd0a-56704fb5a1eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.01254599  0.04507143  0.02319939  0.00986585 -0.03439813 -0.03440055\n",
            " -0.04419164  0.03661761  0.0101115   0.02080726 -0.04794155  0.04699099\n",
            "  0.03324426 -0.02876609 -0.0318175  -0.03165955 -0.01957578  0.00247564\n",
            " -0.0068055  -0.02087709  0.01118529 -0.03605061 -0.02078553 -0.01336382\n",
            " -0.004393    0.0285176  -0.03003262  0.00142344  0.00924146 -0.04535496\n",
            "  0.01075449 -0.03294759 -0.04349484  0.04488855  0.0465632   0.03083974\n",
            " -0.01953862 -0.04023279  0.0184233  -0.00598475 -0.03779618 -0.00048231\n",
            " -0.04656115  0.04093204 -0.024122    0.01625223 -0.01882889  0.0020068\n",
            "  0.00467103 -0.03151456]\n"
          ]
        }
      ],
      "source": [
        "print(embedding_matrix[400001])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HIZO1d8SPFq"
      },
      "source": [
        "# Sequence length standardization \n",
        "Every sentence must have the same length, otherwise we would hade different input sizes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "PHtxPN12Xu12"
      },
      "outputs": [],
      "source": [
        "max_length_dict = {\"train\": len(max(x_enc[\"train\"], key=len)),\n",
        "                   \"val\": len(max(x_enc[\"val\"], key=len)),\n",
        "                   \"test\": len(max(x_enc[\"test\"], key=len))}\n",
        "\n",
        "number_pos = len(label_to_idx) + 1 #to add the padding\n",
        "x_st, y_st, y_cat = {}, {}, {}\n",
        "\n",
        "for key in max_length_dict.keys():\n",
        "    x_st[key] = pad_sequences(x_enc[key], maxlen=max_length_dict[key], padding='post')\n",
        "    y_st[key] = pad_sequences(y_enc[key], maxlen=max_length_dict[key], padding='post')\n",
        "    y_cat[key] = to_categorical(y_st[key], num_classes=number_pos)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(max_length_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_Um3hK7IrGm",
        "outputId": "b2732813-6f7a-4f56-8aeb-ae8a0e0ab5ad"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'train': 249, 'val': 81, 'test': 58}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoFjfVeiiN4k"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "51i4hAotnH_s"
      },
      "outputs": [],
      "source": [
        "models = {}\n",
        "history = {}\n",
        "batch_size = 10\n",
        "epochs = 30\n",
        "units = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzdywqEviQla"
      },
      "source": [
        "## Baseline model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJuzjdbijeLU"
      },
      "outputs": [],
      "source": [
        "def build_baseline_model(num_pos, \n",
        "                        embedding_matrix, \n",
        "                        name = 'baseline',\n",
        "                        units=units):\n",
        "  inputs = Input(shape=(None,), dtype=\"int32\")\n",
        "  \n",
        "  m = Embedding(input_dim=embedding_matrix.shape[0], \n",
        "                output_dim=embedding_matrix.shape[1],\n",
        "                mask_zero=True, \n",
        "                weights=[embedding_matrix], \n",
        "                trainable=False)(inputs)\n",
        "\n",
        "  m = Bidirectional(LSTM(units=units, return_sequences=True))(m)\n",
        "\n",
        "  m = Dense(num_pos, activation='softmax')(m)\n",
        "  return Model(inputs, m, name=name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzKme1uQiYRC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3147d18f-4b25-4d02-db5c-2fc44054d1f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"baseline\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, None, 50)          20028550  \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, None, 200)        120800    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense (Dense)               (None, None, 46)          9246      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,158,596\n",
            "Trainable params: 130,046\n",
            "Non-trainable params: 20,028,550\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "models[\"baseline\"] = build_baseline_model(num_pos = number_pos, \n",
        "                                          embedding_matrix = embedding_matrix, \n",
        "                                          name=\"baseline\")\n",
        "models[\"baseline\"].summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models['baseline'].compile(optimizer ='adam', \n",
        "                           loss = 'categorical_crossentropy', \n",
        "                           metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "3BuHK1jl-5D3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E69SDCkmlv1h",
        "outputId": "b26313a0-3766-43b5-9066-dbbe1d1b520b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "197/197 [==============================] - 19s 33ms/step - loss: 0.1985 - accuracy: 0.4652 - val_loss: 0.3785 - val_accuracy: 0.6593\n",
            "Epoch 2/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0963 - accuracy: 0.7353 - val_loss: 0.2644 - val_accuracy: 0.7482\n",
            "Epoch 3/30\n",
            "197/197 [==============================] - 7s 34ms/step - loss: 0.0727 - accuracy: 0.7929 - val_loss: 0.2214 - val_accuracy: 0.7866\n",
            "Epoch 4/30\n",
            "197/197 [==============================] - 8s 39ms/step - loss: 0.0615 - accuracy: 0.8223 - val_loss: 0.1962 - val_accuracy: 0.8103\n",
            "Epoch 5/30\n",
            "197/197 [==============================] - 6s 30ms/step - loss: 0.0541 - accuracy: 0.8409 - val_loss: 0.1807 - val_accuracy: 0.8246\n",
            "Epoch 6/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0484 - accuracy: 0.8572 - val_loss: 0.1680 - val_accuracy: 0.8327\n",
            "Epoch 7/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0437 - accuracy: 0.8700 - val_loss: 0.1583 - val_accuracy: 0.8422\n",
            "Epoch 8/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0398 - accuracy: 0.8826 - val_loss: 0.1520 - val_accuracy: 0.8457\n",
            "Epoch 9/30\n",
            "197/197 [==============================] - 5s 24ms/step - loss: 0.0364 - accuracy: 0.8932 - val_loss: 0.1445 - val_accuracy: 0.8540\n",
            "Epoch 10/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0333 - accuracy: 0.9031 - val_loss: 0.1383 - val_accuracy: 0.8598\n",
            "Epoch 11/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0305 - accuracy: 0.9114 - val_loss: 0.1351 - val_accuracy: 0.8627\n",
            "Epoch 12/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0282 - accuracy: 0.9184 - val_loss: 0.1304 - val_accuracy: 0.8668\n",
            "Epoch 13/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0258 - accuracy: 0.9267 - val_loss: 0.1278 - val_accuracy: 0.8705\n",
            "Epoch 14/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0237 - accuracy: 0.9338 - val_loss: 0.1257 - val_accuracy: 0.8705\n",
            "Epoch 15/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0218 - accuracy: 0.9402 - val_loss: 0.1241 - val_accuracy: 0.8727\n",
            "Epoch 16/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0200 - accuracy: 0.9459 - val_loss: 0.1231 - val_accuracy: 0.8733\n",
            "Epoch 17/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0184 - accuracy: 0.9512 - val_loss: 0.1211 - val_accuracy: 0.8752\n",
            "Epoch 18/30\n",
            "197/197 [==============================] - 5s 24ms/step - loss: 0.0169 - accuracy: 0.9558 - val_loss: 0.1214 - val_accuracy: 0.8753\n",
            "Epoch 19/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0155 - accuracy: 0.9606 - val_loss: 0.1231 - val_accuracy: 0.8730\n",
            "Epoch 20/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0141 - accuracy: 0.9653 - val_loss: 0.1218 - val_accuracy: 0.8751\n",
            "Epoch 21/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0128 - accuracy: 0.9687 - val_loss: 0.1233 - val_accuracy: 0.8745\n",
            "Epoch 22/30\n",
            "197/197 [==============================] - 5s 24ms/step - loss: 0.0115 - accuracy: 0.9742 - val_loss: 0.1236 - val_accuracy: 0.8735\n",
            "Epoch 23/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0104 - accuracy: 0.9781 - val_loss: 0.1256 - val_accuracy: 0.8756\n",
            "Epoch 24/30\n",
            "197/197 [==============================] - 6s 28ms/step - loss: 0.0094 - accuracy: 0.9812 - val_loss: 0.1264 - val_accuracy: 0.8728\n",
            "Epoch 25/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0083 - accuracy: 0.9847 - val_loss: 0.1281 - val_accuracy: 0.8740\n",
            "Epoch 26/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0074 - accuracy: 0.9877 - val_loss: 0.1302 - val_accuracy: 0.8720\n",
            "Epoch 27/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0065 - accuracy: 0.9903 - val_loss: 0.1320 - val_accuracy: 0.8724\n",
            "Epoch 28/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0058 - accuracy: 0.9927 - val_loss: 0.1339 - val_accuracy: 0.8719\n",
            "Epoch 29/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0051 - accuracy: 0.9942 - val_loss: 0.1373 - val_accuracy: 0.8701\n",
            "Epoch 30/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0045 - accuracy: 0.9952 - val_loss: 0.1383 - val_accuracy: 0.8710\n"
          ]
        }
      ],
      "source": [
        "history['baseline'] = models['baseline'].fit(x=x_st[\"train\"], \n",
        "                   y=y_cat[\"train\"], \n",
        "                   batch_size=batch_size, \n",
        "                   epochs=epochs, \n",
        "                   validation_data=(x_st[\"val\"], y_cat[\"val\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline with GRU instead of LSTM"
      ],
      "metadata": {
        "id": "i7frWEJB-OS7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQ8e1t7MzP2O"
      },
      "outputs": [],
      "source": [
        "def build_baseline_model_with_GRU(num_pos, \n",
        "                        embedding_matrix, \n",
        "                        name = 'baseline_with_GRU',\n",
        "                        units=units):\n",
        "  inputs = Input(shape=(None,), dtype=\"int32\")\n",
        "  \n",
        "  m = Embedding(input_dim=embedding_matrix.shape[0], \n",
        "                output_dim=embedding_matrix.shape[1],\n",
        "                mask_zero=True, \n",
        "                weights=[embedding_matrix], \n",
        "                trainable=False)(inputs)\n",
        "\n",
        "  m = Bidirectional(GRU(units=units, return_sequences=True))(m)\n",
        "\n",
        "  m = Dense(num_pos, activation='softmax')(m)\n",
        "  return Model(inputs, m, name=name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models[\"baseline_with_GRU\"] = build_baseline_model_with_GRU(num_pos = number_pos, \n",
        "                                          embedding_matrix = embedding_matrix, \n",
        "                                          name=\"baseline_with_GRU\")\n",
        "models[\"baseline_with_GRU\"].summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPmIObbS-7JN",
        "outputId": "8e6a863f-eb15-43d7-b9d1-2fec8e8bc001"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"baseline_with_GRU\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, None, 50)          20028550  \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, None, 200)        91200     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, None, 46)          9246      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,128,996\n",
            "Trainable params: 100,446\n",
            "Non-trainable params: 20,028,550\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models['baseline_with_GRU'].compile(optimizer ='adam', \n",
        "                           loss = 'categorical_crossentropy', \n",
        "                           metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "PhrXQ3qS_GPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history['baseline_with_GRU'] = models['baseline_with_GRU'].fit(x=x_st[\"train\"], \n",
        "                   y=y_cat[\"train\"], \n",
        "                   batch_size=batch_size, \n",
        "                   epochs=epochs, \n",
        "                   validation_data=(x_st[\"val\"], y_cat[\"val\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDZ1wgbp_GqG",
        "outputId": "e6c51b0a-a99e-4fa9-eb8e-a80e43858a2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "197/197 [==============================] - 15s 36ms/step - loss: 0.1675 - accuracy: 0.5538 - val_loss: 0.2988 - val_accuracy: 0.7235\n",
            "Epoch 2/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0775 - accuracy: 0.7792 - val_loss: 0.2215 - val_accuracy: 0.7822\n",
            "Epoch 3/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0603 - accuracy: 0.8219 - val_loss: 0.1901 - val_accuracy: 0.8099\n",
            "Epoch 4/30\n",
            "197/197 [==============================] - 5s 24ms/step - loss: 0.0511 - accuracy: 0.8470 - val_loss: 0.1673 - val_accuracy: 0.8338\n",
            "Epoch 5/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0446 - accuracy: 0.8641 - val_loss: 0.1547 - val_accuracy: 0.8456\n",
            "Epoch 6/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0393 - accuracy: 0.8820 - val_loss: 0.1441 - val_accuracy: 0.8542\n",
            "Epoch 7/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0351 - accuracy: 0.8957 - val_loss: 0.1358 - val_accuracy: 0.8612\n",
            "Epoch 8/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0315 - accuracy: 0.9067 - val_loss: 0.1311 - val_accuracy: 0.8656\n",
            "Epoch 9/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0284 - accuracy: 0.9156 - val_loss: 0.1267 - val_accuracy: 0.8697\n",
            "Epoch 10/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0255 - accuracy: 0.9244 - val_loss: 0.1228 - val_accuracy: 0.8724\n",
            "Epoch 11/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0231 - accuracy: 0.9335 - val_loss: 0.1215 - val_accuracy: 0.8738\n",
            "Epoch 12/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0207 - accuracy: 0.9406 - val_loss: 0.1182 - val_accuracy: 0.8760\n",
            "Epoch 13/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0187 - accuracy: 0.9481 - val_loss: 0.1186 - val_accuracy: 0.8767\n",
            "Epoch 14/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0167 - accuracy: 0.9546 - val_loss: 0.1176 - val_accuracy: 0.8786\n",
            "Epoch 15/30\n",
            "197/197 [==============================] - 5s 24ms/step - loss: 0.0149 - accuracy: 0.9617 - val_loss: 0.1186 - val_accuracy: 0.8762\n",
            "Epoch 16/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0132 - accuracy: 0.9666 - val_loss: 0.1186 - val_accuracy: 0.8769\n",
            "Epoch 17/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0117 - accuracy: 0.9725 - val_loss: 0.1199 - val_accuracy: 0.8775\n",
            "Epoch 18/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0103 - accuracy: 0.9768 - val_loss: 0.1231 - val_accuracy: 0.8752\n",
            "Epoch 19/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0090 - accuracy: 0.9808 - val_loss: 0.1255 - val_accuracy: 0.8750\n",
            "Epoch 20/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0078 - accuracy: 0.9851 - val_loss: 0.1269 - val_accuracy: 0.8747\n",
            "Epoch 21/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0067 - accuracy: 0.9889 - val_loss: 0.1285 - val_accuracy: 0.8742\n",
            "Epoch 22/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0057 - accuracy: 0.9918 - val_loss: 0.1324 - val_accuracy: 0.8730\n",
            "Epoch 23/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0049 - accuracy: 0.9940 - val_loss: 0.1351 - val_accuracy: 0.8731\n",
            "Epoch 24/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0041 - accuracy: 0.9960 - val_loss: 0.1369 - val_accuracy: 0.8717\n",
            "Epoch 25/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0035 - accuracy: 0.9976 - val_loss: 0.1400 - val_accuracy: 0.8725\n",
            "Epoch 26/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0030 - accuracy: 0.9981 - val_loss: 0.1438 - val_accuracy: 0.8714\n",
            "Epoch 27/30\n",
            "197/197 [==============================] - 5s 24ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 0.1460 - val_accuracy: 0.8711\n",
            "Epoch 28/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 0.1497 - val_accuracy: 0.8702\n",
            "Epoch 29/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.1526 - val_accuracy: 0.8708\n",
            "Epoch 30/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.1558 - val_accuracy: 0.8698\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline with an additional LSTM"
      ],
      "metadata": {
        "id": "RTAMzroP_YH0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zB2ojg28_YH1"
      },
      "outputs": [],
      "source": [
        "def build_baseline_model_with_additional_LSTM(num_pos, \n",
        "                        embedding_matrix, \n",
        "                        name = 'baseline_with_2_LSTM',\n",
        "                        units=units):\n",
        "  inputs = Input(shape=(None,), dtype=\"int32\")\n",
        "  \n",
        "  m = Embedding(input_dim=embedding_matrix.shape[0], \n",
        "                output_dim=embedding_matrix.shape[1],\n",
        "                mask_zero=True, \n",
        "                weights=[embedding_matrix], \n",
        "                trainable=False)(inputs)\n",
        "\n",
        "  m = Bidirectional(LSTM(units=units, return_sequences=True))(m)\n",
        "  m = LSTM(units=units, return_sequences=True)(m)\n",
        "  m = Dense(num_pos, activation='softmax')(m)\n",
        "  return Model(inputs, m, name=name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models[\"baseline_with_2_LSTM\"] = build_baseline_model_with_additional_LSTM(num_pos = number_pos, \n",
        "                                          embedding_matrix = embedding_matrix, \n",
        "                                          name=\"baseline_with_2_LSTM\")\n",
        "models[\"baseline_with_2_LSTM\"].summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7uCYf9u_YH1",
        "outputId": "95cef911-4f1e-4e11-b2bf-05375f3035e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"baseline_with_2_LSTM\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, None, 50)          20028550  \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirectio  (None, None, 200)        120800    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, None, 100)         120400    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, None, 46)          4646      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,274,396\n",
            "Trainable params: 245,846\n",
            "Non-trainable params: 20,028,550\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models['baseline_with_2_LSTM'].compile(optimizer ='adam', \n",
        "                           loss = 'categorical_crossentropy', \n",
        "                           metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "JhGdRZs0_YH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history['baseline_with_2_LSTM'] = models['baseline_with_2_LSTM'].fit(x=x_st[\"train\"], \n",
        "                   y=y_cat[\"train\"], \n",
        "                   batch_size=batch_size, \n",
        "                   epochs=epochs, \n",
        "                   validation_data=(x_st[\"val\"], y_cat[\"val\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TX1BcD8G_YH2",
        "outputId": "4b0790c1-2e2d-44f0-ad7b-71f2f0dfbe0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "197/197 [==============================] - 20s 49ms/step - loss: 0.2188 - accuracy: 0.3795 - val_loss: 0.4224 - val_accuracy: 0.6034\n",
            "Epoch 2/30\n",
            "197/197 [==============================] - 5s 27ms/step - loss: 0.1039 - accuracy: 0.7093 - val_loss: 0.2755 - val_accuracy: 0.7408\n",
            "Epoch 3/30\n",
            "197/197 [==============================] - 6s 32ms/step - loss: 0.0737 - accuracy: 0.7890 - val_loss: 0.2215 - val_accuracy: 0.7883\n",
            "Epoch 4/30\n",
            "197/197 [==============================] - 5s 27ms/step - loss: 0.0594 - accuracy: 0.8273 - val_loss: 0.1909 - val_accuracy: 0.8143\n",
            "Epoch 5/30\n",
            "197/197 [==============================] - 6s 30ms/step - loss: 0.0502 - accuracy: 0.8524 - val_loss: 0.1678 - val_accuracy: 0.8364\n",
            "Epoch 6/30\n",
            "197/197 [==============================] - 6s 30ms/step - loss: 0.0431 - accuracy: 0.8735 - val_loss: 0.1539 - val_accuracy: 0.8479\n",
            "Epoch 7/30\n",
            "197/197 [==============================] - 6s 32ms/step - loss: 0.0376 - accuracy: 0.8889 - val_loss: 0.1423 - val_accuracy: 0.8576\n",
            "Epoch 8/30\n",
            "197/197 [==============================] - 7s 35ms/step - loss: 0.0333 - accuracy: 0.9030 - val_loss: 0.1350 - val_accuracy: 0.8633\n",
            "Epoch 9/30\n",
            "197/197 [==============================] - 6s 33ms/step - loss: 0.0298 - accuracy: 0.9122 - val_loss: 0.1276 - val_accuracy: 0.8720\n",
            "Epoch 10/30\n",
            "197/197 [==============================] - 7s 35ms/step - loss: 0.0264 - accuracy: 0.9239 - val_loss: 0.1251 - val_accuracy: 0.8734\n",
            "Epoch 11/30\n",
            "197/197 [==============================] - 6s 32ms/step - loss: 0.0237 - accuracy: 0.9315 - val_loss: 0.1236 - val_accuracy: 0.8737\n",
            "Epoch 12/30\n",
            "197/197 [==============================] - 5s 27ms/step - loss: 0.0211 - accuracy: 0.9403 - val_loss: 0.1182 - val_accuracy: 0.8823\n",
            "Epoch 13/30\n",
            "197/197 [==============================] - 5s 27ms/step - loss: 0.0186 - accuracy: 0.9480 - val_loss: 0.1184 - val_accuracy: 0.8806\n",
            "Epoch 14/30\n",
            "197/197 [==============================] - 8s 39ms/step - loss: 0.0166 - accuracy: 0.9531 - val_loss: 0.1165 - val_accuracy: 0.8830\n",
            "Epoch 15/30\n",
            "197/197 [==============================] - 6s 30ms/step - loss: 0.0144 - accuracy: 0.9615 - val_loss: 0.1172 - val_accuracy: 0.8832\n",
            "Epoch 16/30\n",
            "197/197 [==============================] - 5s 27ms/step - loss: 0.0126 - accuracy: 0.9665 - val_loss: 0.1194 - val_accuracy: 0.8831\n",
            "Epoch 17/30\n",
            "197/197 [==============================] - 6s 31ms/step - loss: 0.0109 - accuracy: 0.9731 - val_loss: 0.1185 - val_accuracy: 0.8835\n",
            "Epoch 18/30\n",
            "197/197 [==============================] - 9s 46ms/step - loss: 0.0093 - accuracy: 0.9780 - val_loss: 0.1220 - val_accuracy: 0.8822\n",
            "Epoch 19/30\n",
            "197/197 [==============================] - 5s 27ms/step - loss: 0.0079 - accuracy: 0.9827 - val_loss: 0.1251 - val_accuracy: 0.8814\n",
            "Epoch 20/30\n",
            "197/197 [==============================] - 5s 27ms/step - loss: 0.0067 - accuracy: 0.9870 - val_loss: 0.1261 - val_accuracy: 0.8828\n",
            "Epoch 21/30\n",
            "197/197 [==============================] - 5s 27ms/step - loss: 0.0055 - accuracy: 0.9902 - val_loss: 0.1279 - val_accuracy: 0.8837\n",
            "Epoch 22/30\n",
            "197/197 [==============================] - 6s 28ms/step - loss: 0.0046 - accuracy: 0.9932 - val_loss: 0.1310 - val_accuracy: 0.8813\n",
            "Epoch 23/30\n",
            "197/197 [==============================] - 9s 46ms/step - loss: 0.0038 - accuracy: 0.9950 - val_loss: 0.1374 - val_accuracy: 0.8814\n",
            "Epoch 24/30\n",
            "197/197 [==============================] - 7s 37ms/step - loss: 0.0031 - accuracy: 0.9961 - val_loss: 0.1394 - val_accuracy: 0.8799\n",
            "Epoch 25/30\n",
            "197/197 [==============================] - 8s 42ms/step - loss: 0.0025 - accuracy: 0.9976 - val_loss: 0.1400 - val_accuracy: 0.8819\n",
            "Epoch 26/30\n",
            "197/197 [==============================] - 7s 33ms/step - loss: 0.0020 - accuracy: 0.9984 - val_loss: 0.1430 - val_accuracy: 0.8821\n",
            "Epoch 27/30\n",
            "197/197 [==============================] - 7s 38ms/step - loss: 0.0017 - accuracy: 0.9987 - val_loss: 0.1449 - val_accuracy: 0.8810\n",
            "Epoch 28/30\n",
            "197/197 [==============================] - 5s 27ms/step - loss: 0.0014 - accuracy: 0.9992 - val_loss: 0.1499 - val_accuracy: 0.8810\n",
            "Epoch 29/30\n",
            "197/197 [==============================] - 5s 27ms/step - loss: 0.0012 - accuracy: 0.9993 - val_loss: 0.1522 - val_accuracy: 0.8812\n",
            "Epoch 30/30\n",
            "197/197 [==============================] - 5s 27ms/step - loss: 0.0010 - accuracy: 0.9996 - val_loss: 0.1540 - val_accuracy: 0.8808\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline with an additional Dense layer"
      ],
      "metadata": {
        "id": "ZdF3KP3rB7ee"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fgx9xO5xB7em"
      },
      "outputs": [],
      "source": [
        "def build_baseline_model_with_additional_Dense(num_pos, \n",
        "                        embedding_matrix, \n",
        "                        name = 'baseline_with_2_Dense',\n",
        "                        units=units):\n",
        "  inputs = Input(shape=(None,), dtype=\"int32\")\n",
        "  \n",
        "  m = Embedding(input_dim=embedding_matrix.shape[0], \n",
        "                output_dim=embedding_matrix.shape[1],\n",
        "                mask_zero=True, \n",
        "                weights=[embedding_matrix], \n",
        "                trainable=False)(inputs)\n",
        "\n",
        "  m = Bidirectional(LSTM(units=units, return_sequences=True))(m)\n",
        "  m = Dense(100, activation='relu')(m)\n",
        "  m = Dense(num_pos, activation='softmax')(m)\n",
        "  return Model(inputs, m, name=name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models[\"baseline_with_2_Dense\"] = build_baseline_model_with_additional_Dense(num_pos = number_pos, \n",
        "                                          embedding_matrix = embedding_matrix, \n",
        "                                          name=\"baseline_with_2_Dense\")\n",
        "models[\"baseline_with_2_Dense\"].summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d312737d-fbb5-4d1e-a7f5-82dd137579d7",
        "id": "ALHF_0eAB7en"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"baseline_with_2_Dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_3 (Embedding)     (None, None, 50)          20028550  \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirectio  (None, None, 200)        120800    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, None, 100)         20100     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, None, 46)          4646      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,174,096\n",
            "Trainable params: 145,546\n",
            "Non-trainable params: 20,028,550\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models['baseline_with_2_Dense'].compile(optimizer ='adam', \n",
        "                           loss = 'categorical_crossentropy', \n",
        "                           metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "j90F7D1IB7en"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history['baseline_with_2_Dense'] = models['baseline_with_2_Dense'].fit(x=x_st[\"train\"], \n",
        "                   y=y_cat[\"train\"], \n",
        "                   batch_size=batch_size, \n",
        "                   epochs=epochs, \n",
        "                   validation_data=(x_st[\"val\"], y_cat[\"val\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z36602FdB7en",
        "outputId": "127949e6-6009-4332-ee15-111d6ef72f76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "197/197 [==============================] - 15s 36ms/step - loss: 0.1863 - accuracy: 0.4891 - val_loss: 0.3195 - val_accuracy: 0.7011\n",
            "Epoch 2/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0817 - accuracy: 0.7631 - val_loss: 0.2289 - val_accuracy: 0.7727\n",
            "Epoch 3/30\n",
            "197/197 [==============================] - 5s 25ms/step - loss: 0.0614 - accuracy: 0.8156 - val_loss: 0.1938 - val_accuracy: 0.8073\n",
            "Epoch 4/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0509 - accuracy: 0.8452 - val_loss: 0.1680 - val_accuracy: 0.8295\n",
            "Epoch 5/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0438 - accuracy: 0.8649 - val_loss: 0.1510 - val_accuracy: 0.8474\n",
            "Epoch 6/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0380 - accuracy: 0.8845 - val_loss: 0.1406 - val_accuracy: 0.8549\n",
            "Epoch 7/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0335 - accuracy: 0.8990 - val_loss: 0.1350 - val_accuracy: 0.8626\n",
            "Epoch 8/30\n",
            "197/197 [==============================] - 5s 26ms/step - loss: 0.0297 - accuracy: 0.9106 - val_loss: 0.1278 - val_accuracy: 0.8675\n",
            "Epoch 9/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0267 - accuracy: 0.9187 - val_loss: 0.1261 - val_accuracy: 0.8705\n",
            "Epoch 10/30\n",
            "197/197 [==============================] - 4s 21ms/step - loss: 0.0237 - accuracy: 0.9278 - val_loss: 0.1261 - val_accuracy: 0.8705\n",
            "Epoch 11/30\n",
            "197/197 [==============================] - 5s 24ms/step - loss: 0.0214 - accuracy: 0.9348 - val_loss: 0.1171 - val_accuracy: 0.8805\n",
            "Epoch 12/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0187 - accuracy: 0.9448 - val_loss: 0.1172 - val_accuracy: 0.8800\n",
            "Epoch 13/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0166 - accuracy: 0.9515 - val_loss: 0.1187 - val_accuracy: 0.8818\n",
            "Epoch 14/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0148 - accuracy: 0.9557 - val_loss: 0.1196 - val_accuracy: 0.8812\n",
            "Epoch 15/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0127 - accuracy: 0.9634 - val_loss: 0.1215 - val_accuracy: 0.8796\n",
            "Epoch 16/30\n",
            "197/197 [==============================] - 4s 21ms/step - loss: 0.0113 - accuracy: 0.9676 - val_loss: 0.1253 - val_accuracy: 0.8799\n",
            "Epoch 17/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0095 - accuracy: 0.9744 - val_loss: 0.1234 - val_accuracy: 0.8836\n",
            "Epoch 18/30\n",
            "197/197 [==============================] - 6s 32ms/step - loss: 0.0080 - accuracy: 0.9792 - val_loss: 0.1281 - val_accuracy: 0.8821\n",
            "Epoch 19/30\n",
            "197/197 [==============================] - 5s 26ms/step - loss: 0.0067 - accuracy: 0.9846 - val_loss: 0.1357 - val_accuracy: 0.8791\n",
            "Epoch 20/30\n",
            "197/197 [==============================] - 5s 24ms/step - loss: 0.0055 - accuracy: 0.9875 - val_loss: 0.1398 - val_accuracy: 0.8786\n",
            "Epoch 21/30\n",
            "197/197 [==============================] - 6s 28ms/step - loss: 0.0045 - accuracy: 0.9906 - val_loss: 0.1408 - val_accuracy: 0.8817\n",
            "Epoch 22/30\n",
            "197/197 [==============================] - 6s 33ms/step - loss: 0.0036 - accuracy: 0.9932 - val_loss: 0.1493 - val_accuracy: 0.8754\n",
            "Epoch 23/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0030 - accuracy: 0.9952 - val_loss: 0.1545 - val_accuracy: 0.8777\n",
            "Epoch 24/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0023 - accuracy: 0.9971 - val_loss: 0.1584 - val_accuracy: 0.8805\n",
            "Epoch 25/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0018 - accuracy: 0.9981 - val_loss: 0.1636 - val_accuracy: 0.8784\n",
            "Epoch 26/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0014 - accuracy: 0.9988 - val_loss: 0.1724 - val_accuracy: 0.8779\n",
            "Epoch 27/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0011 - accuracy: 0.9991 - val_loss: 0.1749 - val_accuracy: 0.8786\n",
            "Epoch 28/30\n",
            "197/197 [==============================] - 7s 35ms/step - loss: 9.1830e-04 - accuracy: 0.9994 - val_loss: 0.1779 - val_accuracy: 0.8780\n",
            "Epoch 29/30\n",
            "197/197 [==============================] - 6s 28ms/step - loss: 6.8814e-04 - accuracy: 0.9997 - val_loss: 0.1817 - val_accuracy: 0.8785\n",
            "Epoch 30/30\n",
            "197/197 [==============================] - 4s 22ms/step - loss: 5.8306e-04 - accuracy: 0.9997 - val_loss: 0.1889 - val_accuracy: 0.8777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "fytMiTJSFF00"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## F1 score"
      ],
      "metadata": {
        "id": "it4lzbh7Yv-z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To exclude punctuation, we are going to check the content of our label vocabulary. Inside this dictionary we have all the labels used above. Since the goal is to exclude them from f1-score computation, we will create a list of these special pos that will be used at evaluation time."
      ],
      "metadata": {
        "id": "XHlG4HYWKdSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\" \".join(label_to_idx.keys()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6fmPinbHSlL",
        "outputId": "4a164930-301c-4ce8-bd0c-47909a341e8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NNP\n",
            ",\n",
            "CD\n",
            "NNS\n",
            "JJ\n",
            "MD\n",
            "VB\n",
            "DT\n",
            "NN\n",
            "IN\n",
            ".\n",
            "VBZ\n",
            "VBG\n",
            "CC\n",
            "VBD\n",
            "VBN\n",
            "RB\n",
            "TO\n",
            "PRP\n",
            "RBR\n",
            "WDT\n",
            "VBP\n",
            "RP\n",
            "PRP$\n",
            "JJS\n",
            "POS\n",
            "``\n",
            "EX\n",
            "''\n",
            "WP\n",
            ":\n",
            "JJR\n",
            "WRB\n",
            "$\n",
            "NNPS\n",
            "WP$\n",
            "-LRB-\n",
            "-RRB-\n",
            "PDT\n",
            "RBS\n",
            "FW\n",
            "UH\n",
            "SYM\n",
            "LS\n",
            "#\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "punctuation = [\",\", \".\", '``', \"''\", ':', '$', '-LRB-','-RRB-','#']\n",
        "punctuation_enc = encode_into_numbers([punctuation], label_to_idx)[0]\n",
        "punctuation_enc.append(0) #padding symbol\n",
        "print(punctuation_enc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EbB_Q_bUVoy",
        "outputId": "322120e0-811f-4b67-df59-bb5e1f37e2f0"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 11, 27, 29, 31, 34, 37, 38, 45, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_f1(model, x, y_true, punctuation):\n",
        "    y_true = np.argmax(y_true, axis=2).flatten()\n",
        "    y_pred = np.argmax(model.predict(x), axis=2).flatten()\n",
        "    \n",
        "    mask = np.in1d(y_true, punctuation_enc, invert=True)  #mask to exclude punctuation symbols\n",
        "    unique_pos = [pos for pos in np.unique(y_true) if not pos in punctuation_enc]\n",
        "\n",
        "    return f1_score(y_true[mask], \n",
        "                    y_pred[mask], \n",
        "                    average='macro', \n",
        "                    labels=unique_pos, \n",
        "                    zero_division=0)"
      ],
      "metadata": {
        "id": "_3gTiEYHFMyP"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_scores = {key: compute_f1(models[key],x_st[\"val\"],y_cat[\"val\"],punctuation_enc ) for key in models.keys()}\n",
        "f1_scores = {k: v for k, v in sorted(f1_scores.items(), key=lambda item: item[1], reverse=True)}  #sort dictionary by value\n",
        "print()\n",
        "for model, score in f1_scores.items():\n",
        "  print(f\"Model {model} f1-score on validation set: {score:.5f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1_NpLlpXJsJ",
        "outputId": "05042527-8714-4e29-d561-9d4f45905e04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 0s 10ms/step\n",
            "41/41 [==============================] - 0s 6ms/step\n",
            "41/41 [==============================] - 0s 10ms/step\n",
            "41/41 [==============================] - 0s 7ms/step\n",
            "\n",
            "Model baseline f1-score on validation set: 0.74402\n",
            "Model baseline_with_2_LSTM f1-score on validation set: 0.73706\n",
            "Model baseline_with_2_Dense f1-score on validation set: 0.73266\n",
            "Model baseline_with_GRU f1-score on validation set: 0.72795\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = models[list(f1_scores.keys())[0]]\n",
        "best_model.name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "35pcJJlpsLWY",
        "outputId": "5908f286-f53c-4a51-8a7f-aa6b40c3ecdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'baseline'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## History inspection"
      ],
      "metadata": {
        "id": "Qrrm53qAY0lY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_history(history_dict):\n",
        "  fig, axes = plt.subplots(nrows=len(history_dict.keys()), ncols=2, figsize=(4*len(history_dict.keys()), 16))\n",
        "  for idx, model in enumerate(history_dict.keys()):\n",
        "    model_history = history_dict[model].history\n",
        "\n",
        "    loss = pd.DataFrame(np.array([model_history['loss'], model_history['val_loss']]).T, columns=['Train', 'Validation'])\n",
        "    min_loss = loss['Validation'].min()\n",
        "    min_loss_idx = loss['Validation'].idxmin()\n",
        "    accuracy = pd.DataFrame(np.array([model_history['accuracy'], model_history['val_accuracy']]).T, columns=['Train', 'Validation'])\n",
        "    max_acc = accuracy['Validation'].min()\n",
        "    max_acc_idx = accuracy['Validation'].idxmin()\n",
        "\n",
        "    sb.lineplot(data=loss, ax=axes[idx][0])\n",
        "    sb.lineplot(data=accuracy, ax=axes[idx][1])\n",
        "\n",
        "    axes[idx][0].axhline(min_loss, color='lightgray', linestyle='-')\n",
        "    axes[idx][0].axvline(min_loss_idx, color='lightgray', linestyle='-')\n",
        "    axes[idx][1].axhline(max_acc, color='lightgray', linestyle='-')\n",
        "    axes[idx][1].axvline(max_acc_idx, color='lightgray', linestyle='-')\n",
        "\n",
        "    axes[idx][0].set_xlabel('Epochs')\n",
        "    axes[idx][1].set_xlabel('Epochs')\n",
        "    axes[idx][0].set_ylabel('Loss')\n",
        "    axes[idx][1].set_ylabel('Accuracy')\n",
        "    axes[idx][0].set_title(f\"{model} loss\")\n",
        "    axes[idx][1].set_title(f\"{model} accuracy\")\n",
        "\n",
        "  fig.tight_layout()\n",
        "  plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Jb3lUpfiY6pD",
        "outputId": "d7151ac1-bcb0-4eac-e6fa-b103d4842fb2"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-c5a1282a1ff1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0;31m#sb.lineplot(data=accuracy, ax=axes[idx][1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m   \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxhline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lightgray'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinestyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m   \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxvline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_loss_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lightgray'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinestyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxhline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lightgray'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinestyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'AxesSubplot' object is not subscriptable"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x1152 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_history(history)"
      ],
      "metadata": {
        "id": "Vdg1HQiapqA0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ba9b7b46-a237-4fea-b75c-5eb051d16e26"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-a8489d1127d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-54-cf0fb4c755b2>\u001b[0m in \u001b[0;36mplot_history\u001b[0;34m(history_dict)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mmax_acc_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Validation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midxmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0msb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlineplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0msb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlineplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'AxesSubplot' object is not subscriptable"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x1152 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Improve the model\n",
        "The baseline model seems to be the best one up to this point, so we are going to try to improve its performances. \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VFKzK_bApBDY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A straightforward modification is to move to GloVe embedding with size 300, as up to now the one with size 50 has been used. This new embedding is much heavier than the previous one, but is ensures better results.\n",
        "\n",
        "Another similar change consists in increasing LSTM hidden units, which previously were set to 100. \n",
        "\n",
        "Finally, since it is clear that the model starts to overfit, adding dropout might help increasing performances\n"
      ],
      "metadata": {
        "id": "ayLNdjmHp7Np"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "units_bigger = 200\n",
        "dropout_percentage = 0.2"
      ],
      "metadata": {
        "id": "H2cMkpDKHu2I"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIMENSION_BIGGER = 300\n",
        "glove_emb_model_bigger = load_GloVe_embedding(EMBEDDING_DIMENSION_BIGGER)"
      ],
      "metadata": {
        "id": "-Lg6NyPptoJ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8989700-6927-4e70-a0ea-75311a387722"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 376.1/376.1MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix_bigger = build_embedding_matrix(glove_emb_model_bigger, \n",
        "                                                EMBEDDING_DIMENSION_BIGGER,\n",
        "                                                word_to_idx_train)\n",
        "print(embedding_matrix_bigger.shape)\n",
        "\n",
        "embedding_matrix_bigger = extend_embedding_matrix(glove_emb_model_bigger, \n",
        "                                                  embedding_matrix_bigger,\n",
        "                                                  word_to_idx_val)\n",
        "print(embedding_matrix_bigger.shape)\n",
        "\n",
        "embedding_matrix_bigger = extend_embedding_matrix(glove_emb_model_bigger, \n",
        "                                                  embedding_matrix_bigger,\n",
        "                                                  word_to_idx_test)\n",
        "print(embedding_matrix_bigger.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBBMeIgpG5wZ",
        "outputId": "a38b8c84-50df-4353-cf90-fc4c66eddcd7"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400318/400318 [00:01<00:00, 279066.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(400319, 300)\n",
            "(400475, 300)\n",
            "(400571, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_final_model(num_pos, \n",
        "                      embedding_matrix, \n",
        "                      name = 'final',\n",
        "                      units = units_bigger, \n",
        "                      dropout = dropout_percentage):\n",
        "  inputs = Input(shape=(None,), dtype=\"int32\")\n",
        "  \n",
        "  m = Embedding(input_dim=embedding_matrix.shape[0], \n",
        "                output_dim=embedding_matrix.shape[1],\n",
        "                mask_zero=True, \n",
        "                weights=[embedding_matrix], \n",
        "                trainable=False)(inputs)\n",
        "\n",
        "  m = Bidirectional(LSTM(units=units, return_sequences=True, dropout=dropout))(m)\n",
        "\n",
        "  m = Dense(num_pos, activation='softmax')(m)\n",
        "  return Model(inputs, m, name=name)"
      ],
      "metadata": {
        "id": "CSxVArvAHb6M"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models['final'] = build_final_model(num_pos = number_pos, \n",
        "                                embedding_matrix = embedding_matrix_bigger, \n",
        "                                name = \"final\",\n",
        "                                units = units_bigger,\n",
        "                                dropout = dropout_percentage) \n"
      ],
      "metadata": {
        "id": "aKvIE742I7y6"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models['final'].summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxatNV0VKEIM",
        "outputId": "787c5236-b96a-4d27-f2df-460400134352"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"final\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, None, 300)         120171300 \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, None, 400)        801600    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense (Dense)               (None, None, 46)          18446     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 120,991,346\n",
            "Trainable params: 820,046\n",
            "Non-trainable params: 120,171,300\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models['final'].compile(optimizer ='adam', \n",
        "                           loss = 'categorical_crossentropy', \n",
        "                           metrics = ['accuracy'])\n",
        "history['final'] = models['final'].fit(x=x_st[\"train\"], \n",
        "                   y=y_cat[\"train\"], \n",
        "                   batch_size=batch_size, \n",
        "                   epochs=epochs, \n",
        "                   validation_data=(x_st[\"val\"], y_cat[\"val\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcRzUJJ0Jz-l",
        "outputId": "d22ac78e-0a92-47e7-b688-adaa59e4d6a9"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "197/197 [==============================] - 18s 32ms/step - loss: 0.1185 - accuracy: 0.6797 - val_loss: 0.1758 - val_accuracy: 0.8336\n",
            "Epoch 2/30\n",
            "197/197 [==============================] - 4s 18ms/step - loss: 0.0462 - accuracy: 0.8642 - val_loss: 0.1305 - val_accuracy: 0.8726\n",
            "Epoch 3/30\n",
            "197/197 [==============================] - 4s 18ms/step - loss: 0.0350 - accuracy: 0.8928 - val_loss: 0.1137 - val_accuracy: 0.8866\n",
            "Epoch 4/30\n",
            "197/197 [==============================] - 4s 18ms/step - loss: 0.0283 - accuracy: 0.9139 - val_loss: 0.1033 - val_accuracy: 0.8932\n",
            "Epoch 5/30\n",
            "197/197 [==============================] - 4s 18ms/step - loss: 0.0233 - accuracy: 0.9279 - val_loss: 0.0942 - val_accuracy: 0.9049\n",
            "Epoch 6/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0189 - accuracy: 0.9433 - val_loss: 0.0886 - val_accuracy: 0.9064\n",
            "Epoch 7/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0155 - accuracy: 0.9541 - val_loss: 0.0857 - val_accuracy: 0.9109\n",
            "Epoch 8/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0125 - accuracy: 0.9641 - val_loss: 0.0870 - val_accuracy: 0.9114\n",
            "Epoch 9/30\n",
            "197/197 [==============================] - 5s 24ms/step - loss: 0.0100 - accuracy: 0.9727 - val_loss: 0.0830 - val_accuracy: 0.9154\n",
            "Epoch 10/30\n",
            "197/197 [==============================] - 4s 21ms/step - loss: 0.0081 - accuracy: 0.9782 - val_loss: 0.0825 - val_accuracy: 0.9147\n",
            "Epoch 11/30\n",
            "197/197 [==============================] - 5s 26ms/step - loss: 0.0063 - accuracy: 0.9848 - val_loss: 0.0853 - val_accuracy: 0.9155\n",
            "Epoch 12/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0050 - accuracy: 0.9887 - val_loss: 0.0851 - val_accuracy: 0.9150\n",
            "Epoch 13/30\n",
            "197/197 [==============================] - 7s 36ms/step - loss: 0.0039 - accuracy: 0.9923 - val_loss: 0.0874 - val_accuracy: 0.9156\n",
            "Epoch 14/30\n",
            "197/197 [==============================] - 5s 27ms/step - loss: 0.0034 - accuracy: 0.9934 - val_loss: 0.0882 - val_accuracy: 0.9155\n",
            "Epoch 15/30\n",
            "197/197 [==============================] - 5s 26ms/step - loss: 0.0027 - accuracy: 0.9950 - val_loss: 0.0890 - val_accuracy: 0.9149\n",
            "Epoch 16/30\n",
            "197/197 [==============================] - 4s 21ms/step - loss: 0.0023 - accuracy: 0.9963 - val_loss: 0.0892 - val_accuracy: 0.9159\n",
            "Epoch 17/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0019 - accuracy: 0.9971 - val_loss: 0.0903 - val_accuracy: 0.9171\n",
            "Epoch 18/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0016 - accuracy: 0.9978 - val_loss: 0.0946 - val_accuracy: 0.9159\n",
            "Epoch 19/30\n",
            "197/197 [==============================] - 4s 18ms/step - loss: 0.0014 - accuracy: 0.9981 - val_loss: 0.0939 - val_accuracy: 0.9157\n",
            "Epoch 20/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0012 - accuracy: 0.9984 - val_loss: 0.0960 - val_accuracy: 0.9165\n",
            "Epoch 21/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0011 - accuracy: 0.9985 - val_loss: 0.0994 - val_accuracy: 0.9156\n",
            "Epoch 22/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0011 - accuracy: 0.9986 - val_loss: 0.0967 - val_accuracy: 0.9175\n",
            "Epoch 23/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 9.0376e-04 - accuracy: 0.9990 - val_loss: 0.1002 - val_accuracy: 0.9176\n",
            "Epoch 24/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 8.3280e-04 - accuracy: 0.9989 - val_loss: 0.1008 - val_accuracy: 0.9166\n",
            "Epoch 25/30\n",
            "197/197 [==============================] - 4s 18ms/step - loss: 7.4554e-04 - accuracy: 0.9990 - val_loss: 0.1039 - val_accuracy: 0.9156\n",
            "Epoch 26/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 7.7400e-04 - accuracy: 0.9988 - val_loss: 0.1061 - val_accuracy: 0.9150\n",
            "Epoch 27/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 7.9824e-04 - accuracy: 0.9988 - val_loss: 0.1056 - val_accuracy: 0.9164\n",
            "Epoch 28/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 8.9275e-04 - accuracy: 0.9984 - val_loss: 0.1028 - val_accuracy: 0.9170\n",
            "Epoch 29/30\n",
            "197/197 [==============================] - 4s 18ms/step - loss: 6.5608e-04 - accuracy: 0.9992 - val_loss: 0.1087 - val_accuracy: 0.9160\n",
            "Epoch 30/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 5.8837e-04 - accuracy: 0.9992 - val_loss: 0.1053 - val_accuracy: 0.9178\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1_scores[\"final\"] = compute_f1(models[\"final\"],x_st[\"val\"],y_cat[\"val\"],punctuation_enc)\n",
        "f1_scores[\"final\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RdYmRq_Kbb6",
        "outputId": "366944e9-6ed4-4ea6-9662-4348297c895d"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 0s 8ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8011831453145386"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1_scores_test = {}"
      ],
      "metadata": {
        "id": "aX2G4moTQXBd"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_scores_test[\"final\"] = compute_f1(models[\"final\"],x_st[\"test\"],y_cat[\"test\"],punctuation_enc)\n",
        "f1_scores_test[\"final\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "528p21iwQPL6",
        "outputId": "bb80006d-44f5-44fc-abec-876e95680602"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21/21 [==============================] - 0s 8ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8515409177582665"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "jXlE3OHGzaYq",
        "MQ0PSVGsWZBW",
        "sI97CALV0C34",
        "_0Xhe6fjWvqv",
        "qZUuz-bW_BO3",
        "mzQ6qRPF_86z",
        "b5RNdNYYHYwQ",
        "EElOhl9F-x9-",
        "mAv5AHB_REM5",
        "2HIZO1d8SPFq",
        "RTAMzroP_YH0",
        "ZdF3KP3rB7ee"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}