{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iE-OJaA7wap3"
      },
      "outputs": [],
      "source": [
        "#General imports\n",
        "import copy\n",
        "import gensim\n",
        "import gensim.downloader as gloader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np  \n",
        "import os  \n",
        "import pandas as pd  \n",
        "import re\n",
        "import seaborn as sb\n",
        "import sys \n",
        "from tqdm import tqdm\n",
        "from typing import Iterable, List, Dict, Tuple, Set\n",
        "import urllib.request  \n",
        "import zipfile  \n",
        "\n",
        "#sklearn and tensorflow imports\n",
        "from sklearn.metrics import f1_score\n",
        "from tensorflow.keras.layers import Bidirectional, Dense, Dropout, Embedding, GRU, Input, LSTM\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.random import set_seed"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#fixed seeds to get reproducible results\n",
        "np.random.seed(42)\n",
        "set_seed(42)"
      ],
      "metadata": {
        "id": "OwtabSzSZIBd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXlE3OHGzaYq"
      },
      "source": [
        "#Bulding the dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQ0PSVGsWZBW"
      },
      "source": [
        "## Dataset download and extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIj22FhCyKoA",
        "outputId": "df7699d0-dd43-4dd2-fa87-94173680975f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current working directory: /content\n",
            "Successful download\n",
            "Successful extraction\n"
          ]
        }
      ],
      "source": [
        "DATASET_NAME = \"dataset.zip\"\n",
        "DATASET_FOLDERNAME = \"Dataset\"\n",
        "DATASET_SUBFOLDER = \"dependency_treebank/\"\n",
        "SPLIT_DISTRIBUTION = [100, 150, 199]  #indeces to split in train, validation and test. \n",
        "\n",
        "working_folder = os.getcwd()\n",
        "\n",
        "print(\"Current working directory: \" + str(working_folder))\n",
        "\n",
        "dataset_folder = os.path.join(os.getcwd(), DATASET_FOLDERNAME)\n",
        "\n",
        "if not os.path.exists(dataset_folder):\n",
        "    os.makedirs(dataset_folder)\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/dependency_treebank.zip'\n",
        "\n",
        "dataset_path = os.path.join(dataset_folder, \"dataset.zip\")\n",
        "\n",
        "if not os.path.exists(dataset_path):\n",
        "    urllib.request.urlretrieve(url, dataset_path)\n",
        "    print(\"Successful download\")\n",
        "\n",
        "with zipfile.ZipFile(dataset_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(dataset_folder)\n",
        "    print(\"Successful extraction\")\n",
        "\n",
        "dataset_folder = os.path.join(dataset_folder, DATASET_SUBFOLDER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekoJOGSg7CDd",
        "outputId": "cc7c9379-6c36-47b7-86da-4c403ea9a309"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Dataset/dependency_treebank/\n"
          ]
        }
      ],
      "source": [
        "print(dataset_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sI97CALV0C34"
      },
      "source": [
        "## Dataframe construction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JpNObbHg0HqV"
      },
      "outputs": [],
      "source": [
        "def encode_dataset(dataset_folder: str, \n",
        "                   split_dist: list(), ) -> Dict[str,pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Encode the dataset into three dataframes, returned in a dict.\n",
        "\n",
        "    :param \n",
        "        - dataset_folder: folder of the extracted dataset\n",
        "        - split_dist: list of indeces to be used to split in train, validation and test\n",
        "\n",
        "    :return\n",
        "        - df_dict: dictionary of train, validation and test dataframes\n",
        "    \"\"\"\n",
        "    \n",
        "    #dictionary of dataframes to return\n",
        "    df_dict = {\"train\": pd.DataFrame(columns=['sentence', 'labels']),\n",
        "                \"val\": pd.DataFrame(columns=['sentence', 'labels']),\n",
        "                \"test\":pd.DataFrame(columns=['sentence', 'labels'])}\n",
        "    split = \"\"\n",
        "\n",
        "    for filename in sorted(os.listdir(dataset_folder)): #files are read following the order\n",
        "        file_path = os.path.join(dataset_folder, filename)\n",
        "        try:\n",
        "            if os.path.isfile(file_path):\n",
        "                with open(file_path, mode='r', encoding='utf-8') as text_file:\n",
        "                    # read it and extract \n",
        "                    document_number = filename.split(\"_\")[1].split(\".\")[0]\n",
        "\n",
        "                    if int(document_number) <= split_dist[0]:  #find the split the file belongs to\n",
        "                        split = \"train\"\n",
        "                    elif split_dist[0] < int(document_number) <= split_dist[1]:\n",
        "                        split = \"val\"\n",
        "                    else:\n",
        "                        split = \"test\"\n",
        "\n",
        "                    df_file = pd.read_table(\n",
        "                        file_path, \n",
        "                        delimiter='\\t', \n",
        "                        names=['word', 'label'], \n",
        "                        usecols=[0,1],\n",
        "                        skip_blank_lines=False)\n",
        "                    \n",
        "                    #splitting file content in sentences\n",
        "                    idx = list(df_file.loc[df_file.isnull()['word']].index) #sentences are divided by a blank line, interpreted as a null value. \n",
        "                    idx.append(len(df_file))\n",
        "                    prev = 0\n",
        "                    for sep in idx:    #to split in sentences, word are read from idx \"prev\" to \"sep\", which is why we add len(df_file) to the list of indeces\n",
        "                        df_sentence = pd.DataFrame({\n",
        "                            'sentence': [df_file['word'][prev:sep].to_list()],  #sentence column contains the list of words forming the sentence \n",
        "                            'labels': [df_file['label'][prev:sep].to_list()]})  #labels column contains the list of labels associated with the words forming the sentence \n",
        "                        df_dict[split] = pd.concat([df_dict[split], df_sentence], ignore_index=True)  #adding the row to the appropriate dataframe (according to the split)\n",
        "                        prev = sep + 1\n",
        "                    \n",
        "        except Exception as e:\n",
        "            print('Failed to process %s. Reason: %s' % (file_path, e))\n",
        "            sys.exit(0)\n",
        "\n",
        "    return df_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ocXNiUzD5bOv"
      },
      "outputs": [],
      "source": [
        "df_dict = encode_dataset(dataset_folder, SPLIT_DISTRIBUTION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "FW074bfD54DK",
        "outputId": "3e8f1372-1ba6-4ec8-919f-087b67a49a3d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            sentence  \\\n",
              "0  [Pierre, Vinken, ,, 61, years, old, ,, will, j...   \n",
              "1  [Mr., Vinken, is, chairman, of, Elsevier, N.V....   \n",
              "2  [Rudolph, Agnew, ,, 55, years, old, and, forme...   \n",
              "3  [A, form, of, asbestos, once, used, to, make, ...   \n",
              "4  [The, asbestos, fiber, ,, crocidolite, ,, is, ...   \n",
              "\n",
              "                                              labels  \n",
              "0  [NNP, NNP, ,, CD, NNS, JJ, ,, MD, VB, DT, NN, ...  \n",
              "1  [NNP, NNP, VBZ, NN, IN, NNP, NNP, ,, DT, NNP, ...  \n",
              "2  [NNP, NNP, ,, CD, NNS, JJ, CC, JJ, NN, IN, NNP...  \n",
              "3  [DT, NN, IN, NN, RB, VBN, TO, VB, NNP, NN, NNS...  \n",
              "4  [DT, NN, NN, ,, NN, ,, VBZ, RB, JJ, IN, PRP, V...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c94383ec-d364-4c66-9f0c-9514845ec8ed\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Pierre, Vinken, ,, 61, years, old, ,, will, j...</td>\n",
              "      <td>[NNP, NNP, ,, CD, NNS, JJ, ,, MD, VB, DT, NN, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Mr., Vinken, is, chairman, of, Elsevier, N.V....</td>\n",
              "      <td>[NNP, NNP, VBZ, NN, IN, NNP, NNP, ,, DT, NNP, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[Rudolph, Agnew, ,, 55, years, old, and, forme...</td>\n",
              "      <td>[NNP, NNP, ,, CD, NNS, JJ, CC, JJ, NN, IN, NNP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[A, form, of, asbestos, once, used, to, make, ...</td>\n",
              "      <td>[DT, NN, IN, NN, RB, VBN, TO, VB, NNP, NN, NNS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[The, asbestos, fiber, ,, crocidolite, ,, is, ...</td>\n",
              "      <td>[DT, NN, NN, ,, NN, ,, VBZ, RB, JJ, IN, PRP, V...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c94383ec-d364-4c66-9f0c-9514845ec8ed')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c94383ec-d364-4c66-9f0c-9514845ec8ed button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c94383ec-d364-4c66-9f0c-9514845ec8ed');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df_dict[\"train\"].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "kinbChSf56cz",
        "outputId": "28bba83f-85ad-4136-d61c-b3f1c17cdbc9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            sentence  \\\n",
              "0  [A, House-Senate, conference, approved, major,...   \n",
              "1  [For, the, Agency, for, International, Develop...   \n",
              "2  [The, conference, approved, at, least, $, 55, ...   \n",
              "3  [The, agreement, on, Poland, contrasts, with, ...   \n",
              "4  [These, fiscal, pressures, are, also, a, facto...   \n",
              "\n",
              "                                              labels  \n",
              "0  [DT, NNP, NN, VBD, JJ, NNS, IN, DT, NN, IN, JJ...  \n",
              "1  [IN, DT, NNP, IN, NNP, NNP, ,, NNS, VBD, $, CD...  \n",
              "2  [DT, NN, VBD, IN, JJS, $, CD, CD, IN, JJ, NN, ...  \n",
              "3  [DT, NN, IN, NNP, VBZ, IN, DT, JJ, NNS, VBG, I...  \n",
              "4  [DT, JJ, NNS, VBP, RB, DT, NN, IN, VBG, DT, NN...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3af1b716-3e81-4d5c-9c9b-e7ab6d6049b9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[A, House-Senate, conference, approved, major,...</td>\n",
              "      <td>[DT, NNP, NN, VBD, JJ, NNS, IN, DT, NN, IN, JJ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[For, the, Agency, for, International, Develop...</td>\n",
              "      <td>[IN, DT, NNP, IN, NNP, NNP, ,, NNS, VBD, $, CD...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[The, conference, approved, at, least, $, 55, ...</td>\n",
              "      <td>[DT, NN, VBD, IN, JJS, $, CD, CD, IN, JJ, NN, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[The, agreement, on, Poland, contrasts, with, ...</td>\n",
              "      <td>[DT, NN, IN, NNP, VBZ, IN, DT, JJ, NNS, VBG, I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[These, fiscal, pressures, are, also, a, facto...</td>\n",
              "      <td>[DT, JJ, NNS, VBP, RB, DT, NN, IN, VBG, DT, NN...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3af1b716-3e81-4d5c-9c9b-e7ab6d6049b9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3af1b716-3e81-4d5c-9c9b-e7ab6d6049b9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3af1b716-3e81-4d5c-9c9b-e7ab6d6049b9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df_dict[\"val\"].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "D7U5NfKo57x6",
        "outputId": "8458601f-62ac-4bae-c055-9772159a1dd7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            sentence  \\\n",
              "0  [Intelogic, Trace, Inc., ,, San, Antonio, ,, T...   \n",
              "1  [The, move, boosts, Intelogic, Chairman, Asher...   \n",
              "2  [Mr., Ackerman, already, is, seeking, to, oust...   \n",
              "3  [The, action, followed, by, one, day, an, Inte...   \n",
              "4  [In, New, York, Stock, Exchange, composite, tr...   \n",
              "\n",
              "                                              labels  \n",
              "0  [NNP, NNP, NNP, ,, NNP, NNP, ,, NNP, ,, VBD, P...  \n",
              "1  [DT, NN, VBZ, NNP, NNP, NNP, NNP, POS, NN, TO,...  \n",
              "2  [NNP, NNP, RB, VBZ, VBG, TO, VB, NNP, NNP, IN,...  \n",
              "3  [DT, NN, VBN, IN, CD, NN, DT, NNP, NN, IN, PRP...  \n",
              "4  [IN, NNP, NNP, NNP, NNP, JJ, NN, NN, ,, NNP, N...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1e6b3c3a-7014-4e78-b536-d6534cdb0ead\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Intelogic, Trace, Inc., ,, San, Antonio, ,, T...</td>\n",
              "      <td>[NNP, NNP, NNP, ,, NNP, NNP, ,, NNP, ,, VBD, P...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[The, move, boosts, Intelogic, Chairman, Asher...</td>\n",
              "      <td>[DT, NN, VBZ, NNP, NNP, NNP, NNP, POS, NN, TO,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[Mr., Ackerman, already, is, seeking, to, oust...</td>\n",
              "      <td>[NNP, NNP, RB, VBZ, VBG, TO, VB, NNP, NNP, IN,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[The, action, followed, by, one, day, an, Inte...</td>\n",
              "      <td>[DT, NN, VBN, IN, CD, NN, DT, NNP, NN, IN, PRP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[In, New, York, Stock, Exchange, composite, tr...</td>\n",
              "      <td>[IN, NNP, NNP, NNP, NNP, JJ, NN, NN, ,, NNP, N...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e6b3c3a-7014-4e78-b536-d6534cdb0ead')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1e6b3c3a-7014-4e78-b536-d6534cdb0ead button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1e6b3c3a-7014-4e78-b536-d6534cdb0ead');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df_dict[\"test\"].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "e2i-qWdRdjV-"
      },
      "outputs": [],
      "source": [
        "#Creating x and y starting from dataframe just built\n",
        "\n",
        "x = {\"train\": df_dict['train']['sentence'],\n",
        "     \"val\": df_dict['val']['sentence'],\n",
        "     \"test\": df_dict['test']['sentence']}\n",
        "\n",
        "y = {\"train\": df_dict['train']['labels'],\n",
        "     \"val\": df_dict['val']['labels'],\n",
        "     \"test\": df_dict['test']['labels']}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vf1URJEz-ADo"
      },
      "source": [
        "# Glove Embedding model, vocabulary and OOV detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0Xhe6fjWvqv"
      },
      "source": [
        "## Load Glove embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will start using embedding_dimension=50 to speed up the process. Anyway, at the end of this notebook we will move to embedding_dimension=300 to improve results"
      ],
      "metadata": {
        "id": "kNUzbs63pDpX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "S5nCta0f9_X0"
      },
      "outputs": [],
      "source": [
        "def load_GloVe_embedding(embedding_dimension: int = 50) -> gensim.models.keyedvectors.KeyedVectors:\n",
        "    \"\"\"\n",
        "    Loads a pre-trained word embedding model via gensim library.\n",
        "\n",
        "    :param embedding_dimension: size of the embedding space to consider\n",
        "\n",
        "    :return\n",
        "        - pre-trained word embedding model (gensim KeyedVectors object)\n",
        "    \"\"\"\n",
        "    download_path = \"glove-wiki-gigaword-{}\".format(embedding_dimension)\n",
        "    try:\n",
        "        emb_model = gloader.load(download_path)\n",
        "    except ValueError as e:\n",
        "        print(\"Invalid embedding model name! Check the embedding dimension:\")\n",
        "        print(\"Glove: 50, 100, 200, 300\")\n",
        "        raise e\n",
        "\n",
        "    return emb_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afdQh5i8CDsh",
        "outputId": "c7623976-ea5b-42a6-e70a-e48e69bef361"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 66.0/66.0MB downloaded\n"
          ]
        }
      ],
      "source": [
        "EMBEDDING_DIMENSION = 50\n",
        "glove_emb_model = load_GloVe_embedding(EMBEDDING_DIMENSION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZUuz-bW_BO3"
      },
      "source": [
        "##Creating initial vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "l98tkgAW_DGT"
      },
      "outputs": [],
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "def build_vocabulary(sr: pd.Series) -> List[str]:\n",
        "    \"\"\"\n",
        "    Given a series of sentences, so a series of list of words, builds the corresponding vocabulary.\n",
        "\n",
        "    :param sr: series of sentences, so a a series of list of words (pandas.Series)\n",
        "    :return:\n",
        "      - vocabulary: set of unique terms that build up the vocabulary (list)\n",
        "    \"\"\"\n",
        "    vocabulary = []\n",
        "    for sentence in sr:\n",
        "        for token in sentence:\n",
        "            if token not in vocabulary:\n",
        "                vocabulary.append(token)\n",
        "\n",
        "    return vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9D37IdA4AeHo",
        "outputId": "89acfe9f-4618-476e-ac67-74f35f37c5f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Debug] train vocabulary size: 8009\n",
            "[Debug] val vocabulary size: 5892\n",
            "[Debug] test vocabulary size: 3623\n"
          ]
        }
      ],
      "source": [
        "vocabulary_dict = {}  #dict containing the vocabulary of every split (train, validation, test)\n",
        "for split in df_dict.keys():\n",
        "    vocabulary_dict[split] = build_vocabulary(x[split])\n",
        "    print(f'[Debug] {split} vocabulary size: {len(vocabulary_dict[split])}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzQ6qRPF_86z"
      },
      "source": [
        "## OOV detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "hvm7cbv1BYtq"
      },
      "outputs": [],
      "source": [
        "def check_OOV_terms(vocabulary: Iterable[str],\n",
        "                    word_listing: List[str])  -> List[str]:\n",
        "    \"\"\"\n",
        "    Checks differences between two vocabularies\n",
        "\n",
        "    :param \n",
        "        - vocabulary: vocabulary to which the second one must be compared against \n",
        "        - word_listing: dataset specific vocabulary (list)\n",
        "\n",
        "    :return\n",
        "        - oov: list of unique OOV terms (terms in word_listing that are not in vocabulary)\n",
        "    \"\"\"\n",
        "    embedding_vocabulary = set(vocabulary)\n",
        "    oov = set(word_listing).difference(embedding_vocabulary)\n",
        "    return list(oov)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2MnS5ilADqv",
        "outputId": "9dfe83f9-fc1a-488f-c040-42d79a463f01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total OOV terms: 2346 (29.29%)\n"
          ]
        }
      ],
      "source": [
        "OOV1 = check_OOV_terms(glove_emb_model.vocab.keys(), vocabulary_dict[\"train\"])  #initial vocabulary is the GloVe one, the other is the train one\n",
        "OOV1_percentage = float(len(OOV1)) * 100 / len(vocabulary_dict[\"train\"])\n",
        "print(f\"Total OOV terms: {len(OOV1)} ({OOV1_percentage:.2f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPySrACEC5D3"
      },
      "source": [
        "There are many OOV terms, but we have not done any pre-processing yet. Indeed, a straight forward one is to adopt the same case as Glove. Indeed, we have changed every word to lowercase and looked again for OOV."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CB364Xx_C2vo",
        "outputId": "adc7ed1b-c861-4e71-9511-41c4cfe7468e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total OOV terms: 359 (4.48%)\n"
          ]
        }
      ],
      "source": [
        "OOV1_lowercase = check_OOV_terms(glove_emb_model.vocab.keys(), [v.lower() for v in vocabulary_dict[\"train\"]])\n",
        "OOV1_lowercase_percentage = float(len(OOV1_lowercase)) * 100 / len(vocabulary_dict[\"train\"])\n",
        "print(f\"Total OOV terms: {len(OOV1_lowercase)} ({OOV1_lowercase_percentage:.2f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Indeed, just moving to lowercase we have dramatically decreased the number of OOV of train vocabulary versus GloVe vocabulary. \n",
        "\n",
        "Now, we have to inspect the remaining OOV words to see which further preprocessing can be useful."
      ],
      "metadata": {
        "id": "VTXrd8_BsocH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWzR_D1dGI-u",
        "outputId": "90b34f8f-8c23-456e-882e-074420906136"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\\/4\n",
            "vitulli\n",
            "ratners\n",
            "electric-utility\n",
            "retin-a\n",
            "savers\\/investors\n",
            "bellringers\n",
            "achievement-test\n",
            "ntg\n",
            "chilver\n",
            "456.64\n",
            "3057\n",
            "520-lawyer\n",
            "415.8\n",
            "asset-sale\n",
            "705.6\n",
            "11,762\n",
            "3,288,453\n",
            "cop-killer\n",
            "142.85\n",
            "1\\/10th\n",
            "micronite\n",
            "chong-sik\n",
            "macheski\n",
            "three-lawyer\n",
            "8300s\n",
            "-lcb-\n",
            "creator's\n",
            "chemplus\n",
            "circuit-breaker\n",
            "coche-dury\n",
            "stirlen\n",
            "446.62\n",
            "water-authority\n",
            "prize-fighter\n",
            "-rrb-\n",
            "merger-related\n",
            "beer-belly\n",
            "13,056\n",
            "revenue-desperate\n",
            "language-housekeeper\n",
            "352.7\n",
            "greenmailer\n",
            "pattenden\n",
            "sub-markets\n",
            "234.4\n",
            "4,393,237\n",
            "social-studies\n",
            "test-coaching\n",
            "drobnick\n",
            "nearly-30\n",
            "143.93\n",
            "anti-china\n",
            "30,841\n",
            "futures-related\n",
            "4.898\n",
            "change-ringing\n",
            "polyproplene\n",
            "143.80\n",
            "odd-sounding\n",
            "security-type\n",
            "school-district\n",
            "index-arbitrage\n",
            "malizia\n",
            "thin-lipped\n",
            "shirt-sleeved\n",
            "100,980\n",
            "iran\\/contra\n",
            "anti-takeover\n",
            "pathlogy\n",
            "82,389\n",
            "search-and-seizure\n",
            "1.8415\n",
            "sometimes-tawdry\n",
            "preparatives\n",
            "16,072\n",
            "90-cent-an-hour\n",
            "computer-system-design\n",
            "derel\n",
            "1.457\n",
            "38.375\n",
            "bermuda-based\n",
            "machine-gun-toting\n",
            "light-truck\n",
            "rubinfien\n",
            "low-ball\n",
            "unfair-trade\n",
            "six-bottle\n",
            "building-products\n",
            "school-board\n",
            "direct-investment\n",
            "3.253\n",
            "cash-rich\n",
            "capital-gains\n",
            "incentive-bonus\n",
            "high-balance\n",
            "test-preparation\n",
            "summer\\/winter\n",
            "integra-a\n",
            "sport-utility\n",
            "yeargin\n",
            "wfrr\n",
            "low-ability\n",
            "forest-products\n",
            "nih-appointed\n",
            "trettien\n",
            "re-thought\n",
            "mouth-up\n",
            "mininum-wage\n",
            "when-issued\n",
            "high-rate\n",
            "pianist-comedian\n",
            "front-seat\n",
            "index-options\n",
            "morale-damaging\n",
            "energy-services\n",
            "six-packs\n",
            "life-insurance\n",
            "recession-inspired\n",
            "marketing-communications\n",
            "co-developers\n",
            "unenticing\n",
            "tiphook\n",
            "meinders\n",
            "red-flag\n",
            "home-market\n",
            "70-a-share\n",
            "makato\n",
            "sacramento-based\n",
            "stock-manipulation\n",
            "synergistics\n",
            "subindustry\n",
            "wheeland\n",
            "built-from-kit\n",
            "test-practice\n",
            "higher-salaried\n",
            "non-biodegradable\n",
            "teacher-cadet\n",
            "foreign-led\n",
            "three-sevenths\n",
            "-rcb-\n",
            "samnick\n",
            "equal-opportunity\n",
            "corton-charlemagne\n",
            "rapanelli\n",
            "mehrens\n",
            "erbamont\n",
            "37-a-share\n",
            "361,376\n",
            "nipponese\n",
            "veselich\n",
            "macmillan\\/mcgraw\n",
            "c.j.b.\n",
            "new-home\n",
            "church-goers\n",
            "yen-denominated\n",
            "twindam\n",
            "one-yen\n",
            "secilia\n",
            "jerritts\n",
            "old-house\n",
            "374.19\n",
            "detective-story\n",
            "durable-goods\n",
            "drag-down\n",
            "436.01\n",
            "test-prep\n",
            "biondi-santi\n",
            "dollar-yen\n",
            "hallwood\n",
            "solaia\n",
            "sometimes-exhausting\n",
            "buttoned-down\n",
            "roof-crush\n",
            "training-wage\n",
            "computer-driven\n",
            "romanee-conti\n",
            "rexinger\n",
            "highest-pitched\n",
            "pre-1917\n",
            "moleculon\n",
            "nekoosa\n",
            "one-country\n",
            "sharedata\n",
            "nesb\n",
            "glenham\n",
            "subskill\n",
            "69-point\n",
            "money-fund\n",
            "school-improvement\n",
            "449.04\n",
            "school-research\n",
            "foreign-stock\n",
            "year-ago\n",
            "ariail\n",
            "1.5755\n",
            "delwin\n",
            "trockenbeerenauslesen\n",
            "anti-abortionists\n",
            "muscolina\n",
            "univest\n",
            "lap-shoulder\n",
            "pro-forma\n",
            "junk-bond\n",
            "side-crash\n",
            "forest-product\n",
            "senate-house\n",
            "lower-priority\n",
            "18,444\n",
            "red-blooded\n",
            "war-rationed\n",
            "money-market\n",
            "top-yielding\n",
            "5\\/8\n",
            "program-trading\n",
            "food-shop\n",
            "northy\n",
            "wheel-loader\n",
            "278.7\n",
            "monchecourt\n",
            "telephone-information\n",
            "tarwhine\n",
            "boorse\n",
            "ac-130u\n",
            "nissho-iwai\n",
            "subskills\n",
            "automotive-parts\n",
            "trading-company\n",
            "norwick\n",
            "5.276\n",
            "2645.90\n",
            "one-upsmanship\n",
            "wine-buying\n",
            "ctbs\n",
            "alurralde\n",
            "dust-up\n",
            "deposits-a\n",
            "big-ticket\n",
            "wtd\n",
            "eight-count\n",
            "lezovich\n",
            "3\\/4\n",
            "ingersoll-rand\n",
            "-lrb-\n",
            "year-earlier\n",
            "purhasing\n",
            "pre-1933\n",
            "sanderoff\n",
            "374.20\n",
            "84-month\n",
            "230-215\n",
            "money-center\n",
            "product-design\n",
            "hummerstone\n",
            "twin-jet\n",
            "127.03\n",
            "bridgestone\\/firestone\n",
            "amphobiles\n",
            "c-90\n",
            "replacement-car\n",
            "bell-ringer\n",
            "yen-support\n",
            "index-related\n",
            "weisfield\n",
            "fetal-tissue\n",
            "ghkm\n",
            "securities-based\n",
            "chinchon\n",
            "1\\/2\n",
            "times-stock\n",
            "pramual\n",
            "bumkins\n",
            "sogo-shosha\n",
            "more-efficient\n",
            "lafite-rothschild\n",
            "state-supervised\n",
            "62.625\n",
            "2,303,328\n",
            "236.79\n",
            "colonsville\n",
            "satrum\n",
            "industrial-production\n",
            "dead-eyed\n",
            "centerbank\n",
            "rate-sensitive\n",
            "cray-3\n",
            "small-company\n",
            "antitrust-law\n",
            "497.34\n",
            "95,142\n",
            "271,124\n",
            "car-safety\n",
            "pennview\n",
            "kalipharma\n",
            "16.125\n",
            "7\\/8\n",
            "737.5\n",
            "9,118\n",
            "besuboru\n",
            "government-certified\n",
            "sub-segments\n",
            "autions\n",
            "collective-bargaining\n",
            "sticker-shock\n",
            "limited-partnership\n",
            "two-sevenths\n",
            "aslacton\n",
            "savings-and-loan\n",
            "mortgage-based\n",
            "crocidolite\n",
            "landonne\n",
            "intellectual-property\n",
            "automotive-lighting\n",
            "custom-chip\n",
            "identity-management\n",
            "flightiness\n",
            "stock-index\n",
            "tissue-transplant\n",
            "vinken\n",
            "superpremiums\n",
            "subminimum\n",
            "236.74\n",
            "video-viewing\n",
            "415.6\n",
            "ensrud\n",
            "gingl\n",
            "62%-owned\n",
            "investor-relations\n",
            "floating-rate\n",
            "cotran\n",
            "safe-deposit\n",
            "14,821\n",
            "ft-se\n",
            "we-japanese\n",
            "family-planning\n",
            "12,252\n",
            "college-bowl\n",
            "rope-sight\n",
            "chafic\n",
            "143.08\n",
            "uzi-model\n",
            "macmillan\\/mcgraw-hill\n",
            "less-serious\n",
            "382-37\n",
            "page-one\n",
            "purepac\n",
            "sell-offs\n",
            "abortion-related\n",
            "500,004\n",
            "akerfeldt\n",
            "sino-u.s.\n",
            "jalaalwalikraam\n",
            "market-share\n",
            "post-hearing\n",
            "auto-safety\n",
            "bald-faced\n",
            "nagymaros\n",
            "student-test\n",
            "non-encapsulating\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\".join(OOV1_lowercase))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Printing the whole list of OOV words, we have the following types of OOV words:\n",
        "\n",
        "*   **Compound words**: in most of the cases they are composed by words that are in the vocabulary\n",
        "*   **Decimal numbers**: they need to be defined as class, simply because it is not realistic to encode all decimal numbers (they are too many)\n",
        "*   **Rational numbers**: e.g. 1\\/4 , they are similar to decimal numbers. Note that they have a backslash that will be removed to bring them to the standard form of rational numbers. Similarly for compound words separated by \"\\/\" instead of \"-\" we will perform a replacement\n",
        "*   **Brackets**: instead of being represented with their symbols like the rest of punctuation, their acronym is use (e.g. -lcb- stands for \"left curly bracket\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DVE0aMK3tLDM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5RNdNYYHYwQ"
      },
      "source": [
        "# Preprocessing\n",
        "To further reduce the number of OOV words, we will perform the following preprocessing steps:\n",
        "\n",
        "\n",
        "\n",
        "1.   Change all the words to lowercase\n",
        "2.   Replace \\\\/ with /\n",
        "3.   Replace left bracket symbols\n",
        "4.   Replace right bracket symbols\n",
        "5.   Replace rational numbers with \"#number#\" placeholder\n",
        "6.   Replace decimal numbers with \"#number#\" placeholder\n",
        "7.   Replace compound words' separator: compound words previously separated by \"\\\\/\" are separated by \"/\" after performing step 2., so now we will replace \"/\" with \"-\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "d9H61yyiHYbT"
      },
      "outputs": [],
      "source": [
        "def preprocessing(content_list: List[str]) -> List[str]:\n",
        "    \"\"\"\n",
        "    Preprocess a list a strings: applied to every sentence (a sentence is a list of words) \n",
        "\n",
        "    :param \n",
        "        - content_list: list of string to be preprocessed \n",
        "\n",
        "    :return\n",
        "        - content_list_preprocessed: preprocessed list\n",
        "    \"\"\"\n",
        "\n",
        "    placeholder = \"#number#\"\n",
        "    re_slashes = re.compile('\\\\\\/')  #pattern \\/ \n",
        "    re_rational = re.compile('\\d+\\/\\d+')  #pattern rational number (e.g. 1/5)\n",
        "    re_number = re.compile('[+-]?(\\d*[.])\\d+')  #pattern decimal number (e.g. 3.14)\n",
        "    re_left_bracket = re.compile('(-lrb-)|(-lcb-)')  #pattern left bracket\n",
        "    re_right_bracket = re.compile('(-rrb-)|(-rcb-)')  #pattern right bracket\n",
        "    re_slashed_words = re.compile(\"(\\w*)\\/(\\w*)\")  #a slash separating words will be replaced with a dash, following the trend of the dataset, where composed words are in the form word-word\n",
        "\n",
        "    content_list_preprocessed = [content.lower() for content in content_list]  #change to lowercase\n",
        "    content_list_preprocessed = [re_slashes.sub(\"/\", content) for content in content_list_preprocessed] #replace \\/ with /\n",
        "    content_list_preprocessed = [re_left_bracket.sub(\"(\", content) for content in content_list_preprocessed]  #replace left bracket symbols\n",
        "    content_list_preprocessed = [re_right_bracket.sub(\")\", content) for content in content_list_preprocessed]  #replace right bracket symbols\n",
        "    content_list_preprocessed = [placeholder if re.match(re_rational, content) else content for content in content_list_preprocessed]  #replace rational numbers with a placeholder\n",
        "    content_list_preprocessed = [placeholder if re.match(re_number, content) else content for content in content_list_preprocessed]  #replace decimal numbers with a placeholder\n",
        "    content_list_preprocessed = [content.replace(\"/\", \"-\") if re.match(re_slashed_words, content) else content for content in content_list_preprocessed]  #replace compound words' separator \n",
        "\n",
        "    return content_list_preprocessed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzNl0nSGdEwd"
      },
      "source": [
        "Preprocessing the training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "GyjnI2JZbADI"
      },
      "outputs": [],
      "source": [
        "x_train_preprocessed = x[\"train\"].apply(preprocessing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-Vw8s63garq"
      },
      "source": [
        "Building the new vocabulary after preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcxlVwQFgaRr",
        "outputId": "39bd814b-586e-47d3-f777-ef85f63f95b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Debug] train vocabulary size after preprocessing: 7214\n",
            "Total OOV terms after preprocessing: 318 (4.41%)\n"
          ]
        }
      ],
      "source": [
        "train_vocabulary_preprocessed = build_vocabulary(x_train_preprocessed)\n",
        "print(f'[Debug] train vocabulary size after preprocessing: {len(train_vocabulary_preprocessed)}')\n",
        "\n",
        "OOV1_preprocessed = check_OOV_terms(glove_emb_model.vocab.keys(), train_vocabulary_preprocessed)\n",
        "OOV1_preprocessed_percentage = float(len(OOV1_preprocessed)) * 100 / len(train_vocabulary_preprocessed)\n",
        "print(f\"Total OOV terms after preprocessing: {len(OOV1_preprocessed)} ({OOV1_preprocessed_percentage:.2f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5OLPRGc6svj"
      },
      "source": [
        "It can be seen that the number of OOV words has decreased with respect to the the non preprocessed data. Also note that many oov words are compound ones, for which a specific embedding will be created (see Embedding Matrix section).\n",
        "\n",
        "Similarly to train data, we apply preprocessing to validation and test splits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "MEec69AT_KEw"
      },
      "outputs": [],
      "source": [
        "x_pre = {\"train\": x_train_preprocessed,\n",
        "        \"val\": x[\"val\"].apply(preprocessing),\n",
        "        \"test\": x[\"test\"].apply(preprocessing)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EElOhl9F-x9-"
      },
      "source": [
        "# Vocabulary creation and mapping\n",
        "We will create the complete vocabulary starting from an empty one, then adding sequencially GloVe, train, validation and test vocabularies.  \n",
        "\n",
        "Then, since we want to work with numerical data only, we will map words and labels (part of speech) to numbers, following the mapping built with the vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "_j91cRBqAN1x"
      },
      "outputs": [],
      "source": [
        "def extend_vocabulary(word_to_idx_original: Dict[str, int],\n",
        "                      words_to_add: List[str]) -> Tuple[Dict[str, int],Dict[int, str]]:\n",
        "  \"\"\"\n",
        "    Given a mapping between word and indeces, it adds oov words at the end of the dictionary.\n",
        "    Note that this method can be used also to create a word_to_id vocabulary mapping from scratches: word_to_idx_original will be an empty dict, words_to_add the list of the starting words (for us GloVe vocabulary)\n",
        "\n",
        "    :param \n",
        "        - word_to_idx_original: dictionary with key=word and value=index to which the word is mapped\n",
        "        - words_to_add: list of words to compare with word_to_idx_original. If a word is not found, then it must be inserted in the dictionary\n",
        "    :return:\n",
        "        - word_to_idx_extended: word_to_idx with new words\n",
        "        - idx_to_word_extended: swapped version of word_to_idx_extended (keys and values are swapped)\n",
        "  \"\"\"\n",
        "  word_to_idx_extended = copy.deepcopy(word_to_idx_original)  #deep copy is needed, otherwise python does not create a copy but only a reference to the already existing object, thus reflecting changes on both\n",
        "  idx = len(word_to_idx_extended.keys())\n",
        "  if idx == 0: \n",
        "    idx = 1  #position 0 is reserved\n",
        "\n",
        "  for sentence in words_to_add:\n",
        "      for token in sentence:\n",
        "          if token not in word_to_idx_extended:\n",
        "              word_to_idx_extended[token] = idx \n",
        "              idx += 1\n",
        "  idx_to_word_extended = {v: k for k, v in word_to_idx_extended.items()}\n",
        "\n",
        "  return word_to_idx_extended, idx_to_word_extended\n",
        "\n",
        "def encode_into_numbers(sentences: List[List[str]],\n",
        "                        word_to_idx_mapping: Dict[str, int]) -> List[List[int]]:\n",
        "    \"\"\"\n",
        "    Encode every word of every sentence into an integer following the word mapping\n",
        "\n",
        "    :param \n",
        "        - sentences: sentences whose words have to be encoded into numbers following word_to_idx_mapping (list of list of strings)\n",
        "        - word_to_idx_mapping: dictionary with key=word and value=index to which the word is mapped\n",
        "    :return:\n",
        "        - encoded_data: sentences'encoding (list of list of integers)\n",
        "    \"\"\"\n",
        "    encoded_data = [[word_to_idx_mapping[token] for token in sentence] for sentence in sentences]\n",
        " \n",
        "    return encoded_data\n",
        "\n",
        "def decode_into_words(encoded_sentences: List[List[int]],\n",
        "                        idx_to_word_mapping: Dict[int,str]) -> List[List[str]]:\n",
        "    \"\"\"\n",
        "    Reverse the encoding, replacing numbers encodings with the corresponding word\n",
        "\n",
        "    :param \n",
        "        - encoded_sentences: sentences to decode following idx_to_word_mapping (list of list of integers)\n",
        "        - idx_to_word_mapping: dictionary with key=index and value=word\n",
        "    :return:\n",
        "        - decoded_data: sentences'encoding (list of list of strings)\n",
        "    \"\"\"\n",
        "    decoded_data = [[idx_to_word_mapping[index] for index in sentence] for sentence in encoded_sentences]\n",
        " \n",
        "    return decoded_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HV32wJ90RamP"
      },
      "source": [
        "Encoding the words.\n",
        "\n",
        "Note that word_to_idx and idx_to_word mappings are incremental, this means that the validation vocabulary includes the train one, and the test one includes train and validation ones. This has been made according to the guidelines on the construction of V1, V2, V3, V4. All in all, the complete vocabulary is the one with _test suffix.\n",
        "\n",
        "Furthermore, in the embedding section the intermediate vocabularies will be used according to what they contain. For example, to compute the embedding matrix on the train set, we will use word_to_idx_train, while for validation word_to_idx_val, always proceeding in an incremental way."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbeQJNAlEzl2",
        "outputId": "d71018a5-5f4f-4a14-bc33-7905924346c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train vocabulary size:  400318\n",
            "Validation vocabulary size:  400475\n",
            "Test vocabulary size:  400571\n"
          ]
        }
      ],
      "source": [
        "# Train mappings\n",
        "word_to_idx_train, idx_to_word_train = extend_vocabulary({}, [glove_emb_model.vocab.keys()] + x_pre[\"train\"].tolist())\n",
        "print(\"Train vocabulary size: \", len(word_to_idx_train))\n",
        "\n",
        "# Validation mappings\n",
        "word_to_idx_val, idx_to_word_val = extend_vocabulary(word_to_idx_train, x_pre[\"val\"].tolist())\n",
        "print(\"Validation vocabulary size: \", len(word_to_idx_val))\n",
        "\n",
        "# Test mappings\n",
        "word_to_idx_test, idx_to_word_test = extend_vocabulary(word_to_idx_val, x_pre[\"test\"].tolist())\n",
        "print(\"Test vocabulary size: \", len(word_to_idx_test))\n",
        "\n",
        "# x_enc is the dictionary containing preprocessed data which have been encoded\n",
        "# In the end, for evry split we will move from a list of list of words to a list of list of numbers\n",
        "x_enc = {\"train\": encode_into_numbers(x_pre[\"train\"].tolist(), word_to_idx_train),\n",
        "        \"val\": encode_into_numbers(x_pre[\"val\"].tolist(), word_to_idx_val),\n",
        "        \"test\": encode_into_numbers(x_pre[\"test\"].tolist(), word_to_idx_test)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGsgMfcmRUIN"
      },
      "source": [
        "Encoding parts of speech. Clearly, pos' mappings are different from words' ones and must be kept separated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PzlKA-eHJBr",
        "outputId": "726ac34e-0075-41d0-8cf1-f9fe195cd995"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In the dataset there are 45 distinct POS\n"
          ]
        }
      ],
      "source": [
        "# creating vocabulary mapping for the labels in the whole dataset\n",
        "label_to_idx, idx_to_label = extend_vocabulary({},  y[\"train\"].tolist() + y[\"val\"].tolist() + y[\"test\"].tolist())\n",
        "\n",
        "number_pos = len(label_to_idx)\n",
        "print(f\"In the dataset there are {number_pos} distinct POS\")\n",
        "\n",
        "y_enc = {\"train\": encode_into_numbers(y[\"train\"].tolist(), label_to_idx),\n",
        "        \"val\": encode_into_numbers(y[\"val\"].tolist(), label_to_idx),\n",
        "        \"test\": encode_into_numbers(y[\"test\"].tolist(), label_to_idx)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdwaxJlw3AV0",
        "outputId": "ba890267-d64f-4c0e-a06c-53eeb2797a34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original sentence\n",
            "['The', 'controversy', 'began', 'in', '1987', 'when', 'the', 'National', 'Institutes', 'of', 'Health', ',', 'aware', 'of', 'the', 'policy', 'implications', 'of', 'its', 'research', ',', 'asked', 'for', 'an', 'HHS', 'review', 'of', 'its', 'plan', 'to', 'implant', 'fetal', 'tissue', 'into', 'the', 'brain', 'of', 'a', 'patient', 'suffering', 'from', 'Parkinson', \"'s\", 'disease', '.']\n",
            "\n",
            "Preprocessed sentence\n",
            "['the', 'controversy', 'began', 'in', '1987', 'when', 'the', 'national', 'institutes', 'of', 'health', ',', 'aware', 'of', 'the', 'policy', 'implications', 'of', 'its', 'research', ',', 'asked', 'for', 'an', 'hhs', 'review', 'of', 'its', 'plan', 'to', 'implant', 'fetal', 'tissue', 'into', 'the', 'brain', 'of', 'a', 'patient', 'suffering', 'from', 'parkinson', \"'s\", 'disease', '.']\n",
            "\n",
            "Encoded sentence\n",
            "[1, 3188, 310, 7, 2329, 62, 1, 122, 9218, 4, 361, 2, 3198, 4, 1, 528, 7474, 4, 48, 521, 2, 477, 11, 30, 37435, 1288, 4, 48, 395, 5, 21789, 23294, 7160, 76, 1, 2956, 4, 8, 3223, 2650, 26, 13716, 10, 1290, 3]\n",
            "\n",
            "Decoded sentence\n",
            "['the', 'controversy', 'began', 'in', '1987', 'when', 'the', 'national', 'institutes', 'of', 'health', ',', 'aware', 'of', 'the', 'policy', 'implications', 'of', 'its', 'research', ',', 'asked', 'for', 'an', 'hhs', 'review', 'of', 'its', 'plan', 'to', 'implant', 'fetal', 'tissue', 'into', 'the', 'brain', 'of', 'a', 'patient', 'suffering', 'from', 'parkinson', \"'s\", 'disease', '.']\n"
          ]
        }
      ],
      "source": [
        "example = np.random.randint(0, len(x_enc[\"train\"]))\n",
        "print(f\"Original sentence\")\n",
        "print(x[\"train\"][example])\n",
        "print(\"\\nPreprocessed sentence\")\n",
        "print([x_pre[\"train\"][example]][0])\n",
        "print(\"\\nEncoded sentence\")\n",
        "print([x_enc[\"train\"][example]][0])\n",
        "print(\"\\nDecoded sentence\")\n",
        "print(decode_into_words([x_enc[\"train\"][example]], idx_to_word_train)[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3G3-Pbx3ZmJ",
        "outputId": "14a6befc-d0bd-4ede-b0d0-411dc9f7e059"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original labels\n",
            "['PRP', 'VBZ', 'RB', 'DT', 'NN', 'IN', 'NN', ':', 'CD', 'CD', 'NNP', 'VBZ', 'DT', 'JJ', 'NN', ',', 'CC', ',', 'IN', 'NNP', 'NNP', 'VBD', ',', 'NNS', 'VBP', 'PRP$', 'JJ', 'NNS', 'IN', 'NN', '.']\n",
            "\n",
            "Encoded labels\n",
            "[19, 12, 17, 8, 9, 10, 9, 31, 3, 3, 1, 12, 8, 5, 9, 2, 14, 2, 10, 1, 1, 15, 2, 4, 22, 24, 5, 4, 10, 9, 11]\n",
            "\n",
            "Decoded labels\n",
            "['PRP', 'VBZ', 'RB', 'DT', 'NN', 'IN', 'NN', ':', 'CD', 'CD', 'NNP', 'VBZ', 'DT', 'JJ', 'NN', ',', 'CC', ',', 'IN', 'NNP', 'NNP', 'VBD', ',', 'NNS', 'VBP', 'PRP$', 'JJ', 'NNS', 'IN', 'NN', '.']\n"
          ]
        }
      ],
      "source": [
        "example = np.random.randint(0, len(y_enc[\"train\"]))\n",
        "print(f\"Original labels\")\n",
        "print(y[\"train\"][example])\n",
        "print(\"\\nEncoded labels\")\n",
        "print([y_enc[\"train\"][example]][0])\n",
        "print(\"\\nDecoded labels\")\n",
        "print(decode_into_words([y_enc[\"train\"][example]], idx_to_label)[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAv5AHB_REM5"
      },
      "source": [
        "# Embedding matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to create the embdedding matrix we decided to handle compound words' embeddings in the following way: splitting on the dash (\"-\") we order the obtained words by length and try to get their embeddings starting from the longest word. When an embedding is found, then it will become the compound word's embedding too. Otherwise, if all the words are not contained in the embedding model, we assign a random embedding to the word. The same happens for non-dashed words."
      ],
      "metadata": {
        "id": "jC5pPEa1IkS1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "QGCi8pguRH-5"
      },
      "outputs": [],
      "source": [
        "def get_dashed_embeddings(embedding_model: gensim.models.keyedvectors.KeyedVectors, \n",
        "                          word: str) -> float:\n",
        "  \"\"\"\n",
        "    Given an embedding_model and a word it returns its \"dashed embedding\" if the word contains a dash, None otherwise.\n",
        "    We defined dashed embeddings as the embedding of the longest word found in the embedding model.\n",
        "\n",
        "    :param \n",
        "        - embedding_model: embedding_model to be used\n",
        "        - words_to_add: list of words to compare with word_to_idx_original. If a word is not found, then it must be inserted in the dictionary\n",
        "    :return:\n",
        "        - embedding of the longest word in the compound one if it contains a dash and an embedding is ounf. Else, return None\n",
        "  \"\"\"\n",
        "  if \"-\" in word:\n",
        "    words_split = word.split(\"-\")\n",
        "    words_split.sort(key=len)  #getting the encoding of compound words starting from the longest one\n",
        "    for word_piece in words_split:\n",
        "      try:\n",
        "        return embedding_model[word]  #if a word is found, assign its embedding to the matrix element\n",
        "      except:\n",
        "        pass  #if the current word is not found, do nothing and try the next one\n",
        "  return None  # None is returned if the word does not contain a dash or if all the words in the compound one are not contained in the embedding model\n",
        "\n",
        "def build_embedding_matrix(embedding_model: gensim.models.keyedvectors.KeyedVectors,\n",
        "                           embedding_dimension: int,\n",
        "                           word_to_idx: Dict[str, int]) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Builds the embedding matrix starting from a pre-trained word embedding model\n",
        "\n",
        "    :param \n",
        "        - embedding_model: pre-trained word embedding model (gensim wrapper)\n",
        "        - embedding_dimension: dimension of the embedding\n",
        "        - word_to_idx: dictionary with key=word and value=index to which the word is mapped\n",
        "\n",
        "    :return\n",
        "        - embedding matrix\n",
        "    \"\"\"\n",
        "    embedding_matrix = np.zeros((len(word_to_idx)+1, embedding_dimension), dtype=np.float32)\n",
        "    \n",
        "    #adding all GloVe vocabularies embeddings\n",
        "    for word, idx in tqdm(word_to_idx.items()):\n",
        "      if word in embedding_model:\n",
        "          embedding_matrix[idx] = embedding_model[word]\n",
        "      else: \n",
        "          dashed_embedding = get_dashed_embeddings(embedding_model, word)\n",
        "          if dashed_embedding is None: #it means that word has no dash or all its subwords are oov\n",
        "              dashed_embedding = np.random.uniform(low=-0.05, high=0.05, size=embedding_dimension)\n",
        "          embedding_matrix[idx] = dashed_embedding\n",
        " \n",
        "    return embedding_matrix\n",
        "\n",
        "\n",
        "#This functions adds the embedding of OOV words to the embedding matrix. Note that it directly tries to find an embedding for dashed words and if none is retrieved it uses a uniform random distribution\n",
        "def extend_embedding_matrix(embedding_model: gensim.models.keyedvectors.KeyedVectors,\n",
        "                            embedding_matrix: np.ndarray,\n",
        "                            word_to_idx: Dict[str, int]) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Extend an embedding matrix adding words in word_to_idx that are oov\n",
        "\n",
        "    :param \n",
        "        - embedding_model: pre-trained word embedding model (gensim wrapper)\n",
        "        - embedding_matrix: starting embedding matrix\n",
        "        - word_to_idx: word mapping from which oov words must be retrieved\n",
        "\n",
        "    :return\n",
        "        - new embedding matrix: concatenation of the previous embedding matrix with the one of oov terms\n",
        "    \"\"\"\n",
        "\n",
        "    oov_terms = [key for key, idx in word_to_idx.items() if idx >= embedding_matrix.shape[0]] #all the terms mapped to an index greater than the vocabulary size (number of rows) are not in the embedding matrix \n",
        "    oov_embedding_matrix = np.zeros((len(oov_terms), embedding_matrix.shape[1]), dtype=np.float32)\n",
        "    \n",
        "    for idx, oov in enumerate(oov_terms):\n",
        "        dashed_embedding = get_dashed_embeddings(embedding_model, oov)\n",
        "        if dashed_embedding is None: #it means that word has no dash or all its subwords are oov\n",
        "            dashed_embedding = np.random.uniform(low=-0.05, high=0.05, size=embedding_matrix.shape[1])\n",
        "\n",
        "        oov_embedding_matrix[idx] = dashed_embedding\n",
        "\n",
        "    return np.concatenate([embedding_matrix, oov_embedding_matrix], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERNzAqnMELNB",
        "outputId": "bb5e642e-cfae-41aa-a75d-c40bbfd6c8cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400318/400318 [00:01<00:00, 389856.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(400319, 50)\n",
            "(400475, 50)\n",
            "(400571, 50)\n"
          ]
        }
      ],
      "source": [
        "embedding_matrix = build_embedding_matrix(glove_emb_model, \n",
        "                                          EMBEDDING_DIMENSION,\n",
        "                                          word_to_idx_train)\n",
        "print(f\"Embedding matrix with GloVe and train vocabulary has shape: {embedding_matrix.shape}\")\n",
        "\n",
        "embedding_matrix = extend_embedding_matrix(glove_emb_model, \n",
        "                                          embedding_matrix,\n",
        "                                          word_to_idx_val)\n",
        "print(f\"Embedding matrix after the extension with validation oov words has shape: {embedding_matrix.shape}\")\n",
        "\n",
        "embedding_matrix = extend_embedding_matrix(glove_emb_model, \n",
        "                                          embedding_matrix,\n",
        "                                          word_to_idx_test)\n",
        "print(f\"Embedding matrix after the extension with test oov words has shape: {embedding_matrix.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HIZO1d8SPFq"
      },
      "source": [
        "# Sequence length standardization \n",
        "Every sentence must have the same length, otherwise we would hade different input sizes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "PHtxPN12Xu12"
      },
      "outputs": [],
      "source": [
        "max_length_dict = {\"train\": len(max(x_enc[\"train\"], key=len)),\n",
        "                   \"val\": len(max(x_enc[\"val\"], key=len)),\n",
        "                   \"test\": len(max(x_enc[\"test\"], key=len))}\n",
        "\n",
        "number_pos = len(label_to_idx) + 1 #to add the padding\n",
        "x_st, y_st, y_cat = {}, {}, {}\n",
        "\n",
        "for key in max_length_dict.keys():\n",
        "    x_st[key] = pad_sequences(x_enc[key], maxlen=max_length_dict[key], padding='post')  #add 0s at the end to reach max_length\n",
        "    y_st[key] = pad_sequences(y_enc[key], maxlen=max_length_dict[key], padding='post')  #add 0s at the end to reach max_length\n",
        "    y_cat[key] = to_categorical(y_st[key], num_classes=number_pos)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(max_length_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_Um3hK7IrGm",
        "outputId": "c5df21e7-1386-4786-b705-3ba34c76e916"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'train': 249, 'val': 81, 'test': 58}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoFjfVeiiN4k"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "51i4hAotnH_s"
      },
      "outputs": [],
      "source": [
        "models = {}\n",
        "history = {}\n",
        "batch_size = 10\n",
        "epochs = 30\n",
        "units = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzdywqEviQla"
      },
      "source": [
        "## Baseline model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJuzjdbijeLU"
      },
      "outputs": [],
      "source": [
        "def build_baseline_model(num_pos, \n",
        "                        embedding_matrix, \n",
        "                        name = 'baseline',\n",
        "                        units=units):\n",
        "  inputs = Input(shape=(None,), dtype=\"int32\")\n",
        "  \n",
        "  m = Embedding(input_dim=embedding_matrix.shape[0], \n",
        "                output_dim=embedding_matrix.shape[1],\n",
        "                mask_zero=True, \n",
        "                weights=[embedding_matrix], \n",
        "                trainable=False)(inputs)\n",
        "\n",
        "  m = Bidirectional(LSTM(units=units, return_sequences=True))(m)\n",
        "\n",
        "  m = Dense(num_pos, activation='softmax')(m)\n",
        "  return Model(inputs, m, name=name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzKme1uQiYRC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3147d18f-4b25-4d02-db5c-2fc44054d1f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"baseline\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, None, 50)          20028550  \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, None, 200)        120800    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense (Dense)               (None, None, 46)          9246      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,158,596\n",
            "Trainable params: 130,046\n",
            "Non-trainable params: 20,028,550\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "models[\"baseline\"] = build_baseline_model(num_pos = number_pos, \n",
        "                                          embedding_matrix = embedding_matrix, \n",
        "                                          name=\"baseline\")\n",
        "models[\"baseline\"].summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models['baseline'].compile(optimizer ='adam', \n",
        "                           loss = 'categorical_crossentropy', \n",
        "                           metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "3BuHK1jl-5D3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E69SDCkmlv1h",
        "outputId": "b26313a0-3766-43b5-9066-dbbe1d1b520b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "197/197 [==============================] - 19s 33ms/step - loss: 0.1985 - accuracy: 0.4652 - val_loss: 0.3785 - val_accuracy: 0.6593\n",
            "Epoch 2/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0963 - accuracy: 0.7353 - val_loss: 0.2644 - val_accuracy: 0.7482\n",
            "Epoch 3/30\n",
            "197/197 [==============================] - 7s 34ms/step - loss: 0.0727 - accuracy: 0.7929 - val_loss: 0.2214 - val_accuracy: 0.7866\n",
            "Epoch 4/30\n",
            "197/197 [==============================] - 8s 39ms/step - loss: 0.0615 - accuracy: 0.8223 - val_loss: 0.1962 - val_accuracy: 0.8103\n",
            "Epoch 5/30\n",
            "197/197 [==============================] - 6s 30ms/step - loss: 0.0541 - accuracy: 0.8409 - val_loss: 0.1807 - val_accuracy: 0.8246\n",
            "Epoch 6/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0484 - accuracy: 0.8572 - val_loss: 0.1680 - val_accuracy: 0.8327\n",
            "Epoch 7/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0437 - accuracy: 0.8700 - val_loss: 0.1583 - val_accuracy: 0.8422\n",
            "Epoch 8/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0398 - accuracy: 0.8826 - val_loss: 0.1520 - val_accuracy: 0.8457\n",
            "Epoch 9/30\n",
            "197/197 [==============================] - 5s 24ms/step - loss: 0.0364 - accuracy: 0.8932 - val_loss: 0.1445 - val_accuracy: 0.8540\n",
            "Epoch 10/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0333 - accuracy: 0.9031 - val_loss: 0.1383 - val_accuracy: 0.8598\n",
            "Epoch 11/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0305 - accuracy: 0.9114 - val_loss: 0.1351 - val_accuracy: 0.8627\n",
            "Epoch 12/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0282 - accuracy: 0.9184 - val_loss: 0.1304 - val_accuracy: 0.8668\n",
            "Epoch 13/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0258 - accuracy: 0.9267 - val_loss: 0.1278 - val_accuracy: 0.8705\n",
            "Epoch 14/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0237 - accuracy: 0.9338 - val_loss: 0.1257 - val_accuracy: 0.8705\n",
            "Epoch 15/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0218 - accuracy: 0.9402 - val_loss: 0.1241 - val_accuracy: 0.8727\n",
            "Epoch 16/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0200 - accuracy: 0.9459 - val_loss: 0.1231 - val_accuracy: 0.8733\n",
            "Epoch 17/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0184 - accuracy: 0.9512 - val_loss: 0.1211 - val_accuracy: 0.8752\n",
            "Epoch 18/30\n",
            "197/197 [==============================] - 5s 24ms/step - loss: 0.0169 - accuracy: 0.9558 - val_loss: 0.1214 - val_accuracy: 0.8753\n",
            "Epoch 19/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0155 - accuracy: 0.9606 - val_loss: 0.1231 - val_accuracy: 0.8730\n",
            "Epoch 20/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0141 - accuracy: 0.9653 - val_loss: 0.1218 - val_accuracy: 0.8751\n",
            "Epoch 21/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0128 - accuracy: 0.9687 - val_loss: 0.1233 - val_accuracy: 0.8745\n",
            "Epoch 22/30\n",
            "197/197 [==============================] - 5s 24ms/step - loss: 0.0115 - accuracy: 0.9742 - val_loss: 0.1236 - val_accuracy: 0.8735\n",
            "Epoch 23/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0104 - accuracy: 0.9781 - val_loss: 0.1256 - val_accuracy: 0.8756\n",
            "Epoch 24/30\n",
            "197/197 [==============================] - 6s 28ms/step - loss: 0.0094 - accuracy: 0.9812 - val_loss: 0.1264 - val_accuracy: 0.8728\n",
            "Epoch 25/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0083 - accuracy: 0.9847 - val_loss: 0.1281 - val_accuracy: 0.8740\n",
            "Epoch 26/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0074 - accuracy: 0.9877 - val_loss: 0.1302 - val_accuracy: 0.8720\n",
            "Epoch 27/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0065 - accuracy: 0.9903 - val_loss: 0.1320 - val_accuracy: 0.8724\n",
            "Epoch 28/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0058 - accuracy: 0.9927 - val_loss: 0.1339 - val_accuracy: 0.8719\n",
            "Epoch 29/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0051 - accuracy: 0.9942 - val_loss: 0.1373 - val_accuracy: 0.8701\n",
            "Epoch 30/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0045 - accuracy: 0.9952 - val_loss: 0.1383 - val_accuracy: 0.8710\n"
          ]
        }
      ],
      "source": [
        "history['baseline'] = models['baseline'].fit(x=x_st[\"train\"], \n",
        "                   y=y_cat[\"train\"], \n",
        "                   batch_size=batch_size, \n",
        "                   epochs=epochs, \n",
        "                   validation_data=(x_st[\"val\"], y_cat[\"val\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline with GRU instead of LSTM"
      ],
      "metadata": {
        "id": "i7frWEJB-OS7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQ8e1t7MzP2O"
      },
      "outputs": [],
      "source": [
        "def build_baseline_model_with_GRU(num_pos, \n",
        "                        embedding_matrix, \n",
        "                        name = 'baseline_with_GRU',\n",
        "                        units=units):\n",
        "  inputs = Input(shape=(None,), dtype=\"int32\")\n",
        "  \n",
        "  m = Embedding(input_dim=embedding_matrix.shape[0], \n",
        "                output_dim=embedding_matrix.shape[1],\n",
        "                mask_zero=True, \n",
        "                weights=[embedding_matrix], \n",
        "                trainable=False)(inputs)\n",
        "\n",
        "  m = Bidirectional(GRU(units=units, return_sequences=True))(m)\n",
        "\n",
        "  m = Dense(num_pos, activation='softmax')(m)\n",
        "  return Model(inputs, m, name=name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models[\"baseline_with_GRU\"] = build_baseline_model_with_GRU(num_pos = number_pos, \n",
        "                                          embedding_matrix = embedding_matrix, \n",
        "                                          name=\"baseline_with_GRU\")\n",
        "models[\"baseline_with_GRU\"].summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPmIObbS-7JN",
        "outputId": "8e6a863f-eb15-43d7-b9d1-2fec8e8bc001"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"baseline_with_GRU\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, None, 50)          20028550  \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, None, 200)        91200     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, None, 46)          9246      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,128,996\n",
            "Trainable params: 100,446\n",
            "Non-trainable params: 20,028,550\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models['baseline_with_GRU'].compile(optimizer ='adam', \n",
        "                           loss = 'categorical_crossentropy', \n",
        "                           metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "PhrXQ3qS_GPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history['baseline_with_GRU'] = models['baseline_with_GRU'].fit(x=x_st[\"train\"], \n",
        "                   y=y_cat[\"train\"], \n",
        "                   batch_size=batch_size, \n",
        "                   epochs=epochs, \n",
        "                   validation_data=(x_st[\"val\"], y_cat[\"val\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDZ1wgbp_GqG",
        "outputId": "e6c51b0a-a99e-4fa9-eb8e-a80e43858a2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "197/197 [==============================] - 15s 36ms/step - loss: 0.1675 - accuracy: 0.5538 - val_loss: 0.2988 - val_accuracy: 0.7235\n",
            "Epoch 2/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0775 - accuracy: 0.7792 - val_loss: 0.2215 - val_accuracy: 0.7822\n",
            "Epoch 3/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0603 - accuracy: 0.8219 - val_loss: 0.1901 - val_accuracy: 0.8099\n",
            "Epoch 4/30\n",
            "197/197 [==============================] - 5s 24ms/step - loss: 0.0511 - accuracy: 0.8470 - val_loss: 0.1673 - val_accuracy: 0.8338\n",
            "Epoch 5/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0446 - accuracy: 0.8641 - val_loss: 0.1547 - val_accuracy: 0.8456\n",
            "Epoch 6/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0393 - accuracy: 0.8820 - val_loss: 0.1441 - val_accuracy: 0.8542\n",
            "Epoch 7/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0351 - accuracy: 0.8957 - val_loss: 0.1358 - val_accuracy: 0.8612\n",
            "Epoch 8/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0315 - accuracy: 0.9067 - val_loss: 0.1311 - val_accuracy: 0.8656\n",
            "Epoch 9/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0284 - accuracy: 0.9156 - val_loss: 0.1267 - val_accuracy: 0.8697\n",
            "Epoch 10/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0255 - accuracy: 0.9244 - val_loss: 0.1228 - val_accuracy: 0.8724\n",
            "Epoch 11/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0231 - accuracy: 0.9335 - val_loss: 0.1215 - val_accuracy: 0.8738\n",
            "Epoch 12/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0207 - accuracy: 0.9406 - val_loss: 0.1182 - val_accuracy: 0.8760\n",
            "Epoch 13/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0187 - accuracy: 0.9481 - val_loss: 0.1186 - val_accuracy: 0.8767\n",
            "Epoch 14/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0167 - accuracy: 0.9546 - val_loss: 0.1176 - val_accuracy: 0.8786\n",
            "Epoch 15/30\n",
            "197/197 [==============================] - 5s 24ms/step - loss: 0.0149 - accuracy: 0.9617 - val_loss: 0.1186 - val_accuracy: 0.8762\n",
            "Epoch 16/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0132 - accuracy: 0.9666 - val_loss: 0.1186 - val_accuracy: 0.8769\n",
            "Epoch 17/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0117 - accuracy: 0.9725 - val_loss: 0.1199 - val_accuracy: 0.8775\n",
            "Epoch 18/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0103 - accuracy: 0.9768 - val_loss: 0.1231 - val_accuracy: 0.8752\n",
            "Epoch 19/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0090 - accuracy: 0.9808 - val_loss: 0.1255 - val_accuracy: 0.8750\n",
            "Epoch 20/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0078 - accuracy: 0.9851 - val_loss: 0.1269 - val_accuracy: 0.8747\n",
            "Epoch 21/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0067 - accuracy: 0.9889 - val_loss: 0.1285 - val_accuracy: 0.8742\n",
            "Epoch 22/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0057 - accuracy: 0.9918 - val_loss: 0.1324 - val_accuracy: 0.8730\n",
            "Epoch 23/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0049 - accuracy: 0.9940 - val_loss: 0.1351 - val_accuracy: 0.8731\n",
            "Epoch 24/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0041 - accuracy: 0.9960 - val_loss: 0.1369 - val_accuracy: 0.8717\n",
            "Epoch 25/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0035 - accuracy: 0.9976 - val_loss: 0.1400 - val_accuracy: 0.8725\n",
            "Epoch 26/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0030 - accuracy: 0.9981 - val_loss: 0.1438 - val_accuracy: 0.8714\n",
            "Epoch 27/30\n",
            "197/197 [==============================] - 5s 24ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 0.1460 - val_accuracy: 0.8711\n",
            "Epoch 28/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 0.1497 - val_accuracy: 0.8702\n",
            "Epoch 29/30\n",
            "197/197 [==============================] - 4s 19ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.1526 - val_accuracy: 0.8708\n",
            "Epoch 30/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.1558 - val_accuracy: 0.8698\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline with an additional LSTM"
      ],
      "metadata": {
        "id": "RTAMzroP_YH0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zB2ojg28_YH1"
      },
      "outputs": [],
      "source": [
        "def build_baseline_model_with_additional_LSTM(num_pos, \n",
        "                        embedding_matrix, \n",
        "                        name = 'baseline_with_2_LSTM',\n",
        "                        units=units):\n",
        "  inputs = Input(shape=(None,), dtype=\"int32\")\n",
        "  \n",
        "  m = Embedding(input_dim=embedding_matrix.shape[0], \n",
        "                output_dim=embedding_matrix.shape[1],\n",
        "                mask_zero=True, \n",
        "                weights=[embedding_matrix], \n",
        "                trainable=False)(inputs)\n",
        "\n",
        "  m = Bidirectional(LSTM(units=units, return_sequences=True))(m)\n",
        "  m = LSTM(units=units, return_sequences=True)(m)\n",
        "  m = Dense(num_pos, activation='softmax')(m)\n",
        "  return Model(inputs, m, name=name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models[\"baseline_with_2_LSTM\"] = build_baseline_model_with_additional_LSTM(num_pos = number_pos, \n",
        "                                          embedding_matrix = embedding_matrix, \n",
        "                                          name=\"baseline_with_2_LSTM\")\n",
        "models[\"baseline_with_2_LSTM\"].summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7uCYf9u_YH1",
        "outputId": "95cef911-4f1e-4e11-b2bf-05375f3035e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"baseline_with_2_LSTM\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, None, 50)          20028550  \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirectio  (None, None, 200)        120800    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, None, 100)         120400    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, None, 46)          4646      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,274,396\n",
            "Trainable params: 245,846\n",
            "Non-trainable params: 20,028,550\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models['baseline_with_2_LSTM'].compile(optimizer ='adam', \n",
        "                           loss = 'categorical_crossentropy', \n",
        "                           metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "JhGdRZs0_YH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history['baseline_with_2_LSTM'] = models['baseline_with_2_LSTM'].fit(x=x_st[\"train\"], \n",
        "                   y=y_cat[\"train\"], \n",
        "                   batch_size=batch_size, \n",
        "                   epochs=epochs, \n",
        "                   validation_data=(x_st[\"val\"], y_cat[\"val\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TX1BcD8G_YH2",
        "outputId": "4b0790c1-2e2d-44f0-ad7b-71f2f0dfbe0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "197/197 [==============================] - 20s 49ms/step - loss: 0.2188 - accuracy: 0.3795 - val_loss: 0.4224 - val_accuracy: 0.6034\n",
            "Epoch 2/30\n",
            "197/197 [==============================] - 5s 27ms/step - loss: 0.1039 - accuracy: 0.7093 - val_loss: 0.2755 - val_accuracy: 0.7408\n",
            "Epoch 3/30\n",
            "197/197 [==============================] - 6s 32ms/step - loss: 0.0737 - accuracy: 0.7890 - val_loss: 0.2215 - val_accuracy: 0.7883\n",
            "Epoch 4/30\n",
            "197/197 [==============================] - 5s 27ms/step - loss: 0.0594 - accuracy: 0.8273 - val_loss: 0.1909 - val_accuracy: 0.8143\n",
            "Epoch 5/30\n",
            "197/197 [==============================] - 6s 30ms/step - loss: 0.0502 - accuracy: 0.8524 - val_loss: 0.1678 - val_accuracy: 0.8364\n",
            "Epoch 6/30\n",
            "197/197 [==============================] - 6s 30ms/step - loss: 0.0431 - accuracy: 0.8735 - val_loss: 0.1539 - val_accuracy: 0.8479\n",
            "Epoch 7/30\n",
            "197/197 [==============================] - 6s 32ms/step - loss: 0.0376 - accuracy: 0.8889 - val_loss: 0.1423 - val_accuracy: 0.8576\n",
            "Epoch 8/30\n",
            "197/197 [==============================] - 7s 35ms/step - loss: 0.0333 - accuracy: 0.9030 - val_loss: 0.1350 - val_accuracy: 0.8633\n",
            "Epoch 9/30\n",
            "197/197 [==============================] - 6s 33ms/step - loss: 0.0298 - accuracy: 0.9122 - val_loss: 0.1276 - val_accuracy: 0.8720\n",
            "Epoch 10/30\n",
            "197/197 [==============================] - 7s 35ms/step - loss: 0.0264 - accuracy: 0.9239 - val_loss: 0.1251 - val_accuracy: 0.8734\n",
            "Epoch 11/30\n",
            "197/197 [==============================] - 6s 32ms/step - loss: 0.0237 - accuracy: 0.9315 - val_loss: 0.1236 - val_accuracy: 0.8737\n",
            "Epoch 12/30\n",
            "197/197 [==============================] - 5s 27ms/step - loss: 0.0211 - accuracy: 0.9403 - val_loss: 0.1182 - val_accuracy: 0.8823\n",
            "Epoch 13/30\n",
            "197/197 [==============================] - 5s 27ms/step - loss: 0.0186 - accuracy: 0.9480 - val_loss: 0.1184 - val_accuracy: 0.8806\n",
            "Epoch 14/30\n",
            "197/197 [==============================] - 8s 39ms/step - loss: 0.0166 - accuracy: 0.9531 - val_loss: 0.1165 - val_accuracy: 0.8830\n",
            "Epoch 15/30\n",
            "197/197 [==============================] - 6s 30ms/step - loss: 0.0144 - accuracy: 0.9615 - val_loss: 0.1172 - val_accuracy: 0.8832\n",
            "Epoch 16/30\n",
            "197/197 [==============================] - 5s 27ms/step - loss: 0.0126 - accuracy: 0.9665 - val_loss: 0.1194 - val_accuracy: 0.8831\n",
            "Epoch 17/30\n",
            "197/197 [==============================] - 6s 31ms/step - loss: 0.0109 - accuracy: 0.9731 - val_loss: 0.1185 - val_accuracy: 0.8835\n",
            "Epoch 18/30\n",
            "197/197 [==============================] - 9s 46ms/step - loss: 0.0093 - accuracy: 0.9780 - val_loss: 0.1220 - val_accuracy: 0.8822\n",
            "Epoch 19/30\n",
            "197/197 [==============================] - 5s 27ms/step - loss: 0.0079 - accuracy: 0.9827 - val_loss: 0.1251 - val_accuracy: 0.8814\n",
            "Epoch 20/30\n",
            "197/197 [==============================] - 5s 27ms/step - loss: 0.0067 - accuracy: 0.9870 - val_loss: 0.1261 - val_accuracy: 0.8828\n",
            "Epoch 21/30\n",
            "197/197 [==============================] - 5s 27ms/step - loss: 0.0055 - accuracy: 0.9902 - val_loss: 0.1279 - val_accuracy: 0.8837\n",
            "Epoch 22/30\n",
            "197/197 [==============================] - 6s 28ms/step - loss: 0.0046 - accuracy: 0.9932 - val_loss: 0.1310 - val_accuracy: 0.8813\n",
            "Epoch 23/30\n",
            "197/197 [==============================] - 9s 46ms/step - loss: 0.0038 - accuracy: 0.9950 - val_loss: 0.1374 - val_accuracy: 0.8814\n",
            "Epoch 24/30\n",
            "197/197 [==============================] - 7s 37ms/step - loss: 0.0031 - accuracy: 0.9961 - val_loss: 0.1394 - val_accuracy: 0.8799\n",
            "Epoch 25/30\n",
            "197/197 [==============================] - 8s 42ms/step - loss: 0.0025 - accuracy: 0.9976 - val_loss: 0.1400 - val_accuracy: 0.8819\n",
            "Epoch 26/30\n",
            "197/197 [==============================] - 7s 33ms/step - loss: 0.0020 - accuracy: 0.9984 - val_loss: 0.1430 - val_accuracy: 0.8821\n",
            "Epoch 27/30\n",
            "197/197 [==============================] - 7s 38ms/step - loss: 0.0017 - accuracy: 0.9987 - val_loss: 0.1449 - val_accuracy: 0.8810\n",
            "Epoch 28/30\n",
            "197/197 [==============================] - 5s 27ms/step - loss: 0.0014 - accuracy: 0.9992 - val_loss: 0.1499 - val_accuracy: 0.8810\n",
            "Epoch 29/30\n",
            "197/197 [==============================] - 5s 27ms/step - loss: 0.0012 - accuracy: 0.9993 - val_loss: 0.1522 - val_accuracy: 0.8812\n",
            "Epoch 30/30\n",
            "197/197 [==============================] - 5s 27ms/step - loss: 0.0010 - accuracy: 0.9996 - val_loss: 0.1540 - val_accuracy: 0.8808\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline with an additional Dense layer"
      ],
      "metadata": {
        "id": "ZdF3KP3rB7ee"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fgx9xO5xB7em"
      },
      "outputs": [],
      "source": [
        "def build_baseline_model_with_additional_Dense(num_pos, \n",
        "                        embedding_matrix, \n",
        "                        name = 'baseline_with_2_Dense',\n",
        "                        units=units):\n",
        "  inputs = Input(shape=(None,), dtype=\"int32\")\n",
        "  \n",
        "  m = Embedding(input_dim=embedding_matrix.shape[0], \n",
        "                output_dim=embedding_matrix.shape[1],\n",
        "                mask_zero=True, \n",
        "                weights=[embedding_matrix], \n",
        "                trainable=False)(inputs)\n",
        "\n",
        "  m = Bidirectional(LSTM(units=units, return_sequences=True))(m)\n",
        "  m = Dense(100, activation='relu')(m)\n",
        "  m = Dense(num_pos, activation='softmax')(m)\n",
        "  return Model(inputs, m, name=name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models[\"baseline_with_2_Dense\"] = build_baseline_model_with_additional_Dense(num_pos = number_pos, \n",
        "                                          embedding_matrix = embedding_matrix, \n",
        "                                          name=\"baseline_with_2_Dense\")\n",
        "models[\"baseline_with_2_Dense\"].summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d312737d-fbb5-4d1e-a7f5-82dd137579d7",
        "id": "ALHF_0eAB7en"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"baseline_with_2_Dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_3 (Embedding)     (None, None, 50)          20028550  \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirectio  (None, None, 200)        120800    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, None, 100)         20100     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, None, 46)          4646      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,174,096\n",
            "Trainable params: 145,546\n",
            "Non-trainable params: 20,028,550\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models['baseline_with_2_Dense'].compile(optimizer ='adam', \n",
        "                           loss = 'categorical_crossentropy', \n",
        "                           metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "j90F7D1IB7en"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history['baseline_with_2_Dense'] = models['baseline_with_2_Dense'].fit(x=x_st[\"train\"], \n",
        "                   y=y_cat[\"train\"], \n",
        "                   batch_size=batch_size, \n",
        "                   epochs=epochs, \n",
        "                   validation_data=(x_st[\"val\"], y_cat[\"val\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z36602FdB7en",
        "outputId": "127949e6-6009-4332-ee15-111d6ef72f76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "197/197 [==============================] - 15s 36ms/step - loss: 0.1863 - accuracy: 0.4891 - val_loss: 0.3195 - val_accuracy: 0.7011\n",
            "Epoch 2/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0817 - accuracy: 0.7631 - val_loss: 0.2289 - val_accuracy: 0.7727\n",
            "Epoch 3/30\n",
            "197/197 [==============================] - 5s 25ms/step - loss: 0.0614 - accuracy: 0.8156 - val_loss: 0.1938 - val_accuracy: 0.8073\n",
            "Epoch 4/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0509 - accuracy: 0.8452 - val_loss: 0.1680 - val_accuracy: 0.8295\n",
            "Epoch 5/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0438 - accuracy: 0.8649 - val_loss: 0.1510 - val_accuracy: 0.8474\n",
            "Epoch 6/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0380 - accuracy: 0.8845 - val_loss: 0.1406 - val_accuracy: 0.8549\n",
            "Epoch 7/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0335 - accuracy: 0.8990 - val_loss: 0.1350 - val_accuracy: 0.8626\n",
            "Epoch 8/30\n",
            "197/197 [==============================] - 5s 26ms/step - loss: 0.0297 - accuracy: 0.9106 - val_loss: 0.1278 - val_accuracy: 0.8675\n",
            "Epoch 9/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0267 - accuracy: 0.9187 - val_loss: 0.1261 - val_accuracy: 0.8705\n",
            "Epoch 10/30\n",
            "197/197 [==============================] - 4s 21ms/step - loss: 0.0237 - accuracy: 0.9278 - val_loss: 0.1261 - val_accuracy: 0.8705\n",
            "Epoch 11/30\n",
            "197/197 [==============================] - 5s 24ms/step - loss: 0.0214 - accuracy: 0.9348 - val_loss: 0.1171 - val_accuracy: 0.8805\n",
            "Epoch 12/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0187 - accuracy: 0.9448 - val_loss: 0.1172 - val_accuracy: 0.8800\n",
            "Epoch 13/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0166 - accuracy: 0.9515 - val_loss: 0.1187 - val_accuracy: 0.8818\n",
            "Epoch 14/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0148 - accuracy: 0.9557 - val_loss: 0.1196 - val_accuracy: 0.8812\n",
            "Epoch 15/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0127 - accuracy: 0.9634 - val_loss: 0.1215 - val_accuracy: 0.8796\n",
            "Epoch 16/30\n",
            "197/197 [==============================] - 4s 21ms/step - loss: 0.0113 - accuracy: 0.9676 - val_loss: 0.1253 - val_accuracy: 0.8799\n",
            "Epoch 17/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0095 - accuracy: 0.9744 - val_loss: 0.1234 - val_accuracy: 0.8836\n",
            "Epoch 18/30\n",
            "197/197 [==============================] - 6s 32ms/step - loss: 0.0080 - accuracy: 0.9792 - val_loss: 0.1281 - val_accuracy: 0.8821\n",
            "Epoch 19/30\n",
            "197/197 [==============================] - 5s 26ms/step - loss: 0.0067 - accuracy: 0.9846 - val_loss: 0.1357 - val_accuracy: 0.8791\n",
            "Epoch 20/30\n",
            "197/197 [==============================] - 5s 24ms/step - loss: 0.0055 - accuracy: 0.9875 - val_loss: 0.1398 - val_accuracy: 0.8786\n",
            "Epoch 21/30\n",
            "197/197 [==============================] - 6s 28ms/step - loss: 0.0045 - accuracy: 0.9906 - val_loss: 0.1408 - val_accuracy: 0.8817\n",
            "Epoch 22/30\n",
            "197/197 [==============================] - 6s 33ms/step - loss: 0.0036 - accuracy: 0.9932 - val_loss: 0.1493 - val_accuracy: 0.8754\n",
            "Epoch 23/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0030 - accuracy: 0.9952 - val_loss: 0.1545 - val_accuracy: 0.8777\n",
            "Epoch 24/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0023 - accuracy: 0.9971 - val_loss: 0.1584 - val_accuracy: 0.8805\n",
            "Epoch 25/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0018 - accuracy: 0.9981 - val_loss: 0.1636 - val_accuracy: 0.8784\n",
            "Epoch 26/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0014 - accuracy: 0.9988 - val_loss: 0.1724 - val_accuracy: 0.8779\n",
            "Epoch 27/30\n",
            "197/197 [==============================] - 4s 20ms/step - loss: 0.0011 - accuracy: 0.9991 - val_loss: 0.1749 - val_accuracy: 0.8786\n",
            "Epoch 28/30\n",
            "197/197 [==============================] - 7s 35ms/step - loss: 9.1830e-04 - accuracy: 0.9994 - val_loss: 0.1779 - val_accuracy: 0.8780\n",
            "Epoch 29/30\n",
            "197/197 [==============================] - 6s 28ms/step - loss: 6.8814e-04 - accuracy: 0.9997 - val_loss: 0.1817 - val_accuracy: 0.8785\n",
            "Epoch 30/30\n",
            "197/197 [==============================] - 4s 22ms/step - loss: 5.8306e-04 - accuracy: 0.9997 - val_loss: 0.1889 - val_accuracy: 0.8777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "fytMiTJSFF00"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## F1 score"
      ],
      "metadata": {
        "id": "it4lzbh7Yv-z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To exclude punctuation, we are going to check the content of our label vocabulary. Inside this dictionary we have all the labels used above. Since the goal is to exclude them from f1-score computation, we will create a list of these special pos that will be used at evaluation time."
      ],
      "metadata": {
        "id": "XHlG4HYWKdSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\" \".join(label_to_idx.keys()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6fmPinbHSlL",
        "outputId": "4a164930-301c-4ce8-bd0c-47909a341e8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NNP\n",
            ",\n",
            "CD\n",
            "NNS\n",
            "JJ\n",
            "MD\n",
            "VB\n",
            "DT\n",
            "NN\n",
            "IN\n",
            ".\n",
            "VBZ\n",
            "VBG\n",
            "CC\n",
            "VBD\n",
            "VBN\n",
            "RB\n",
            "TO\n",
            "PRP\n",
            "RBR\n",
            "WDT\n",
            "VBP\n",
            "RP\n",
            "PRP$\n",
            "JJS\n",
            "POS\n",
            "``\n",
            "EX\n",
            "''\n",
            "WP\n",
            ":\n",
            "JJR\n",
            "WRB\n",
            "$\n",
            "NNPS\n",
            "WP$\n",
            "-LRB-\n",
            "-RRB-\n",
            "PDT\n",
            "RBS\n",
            "FW\n",
            "UH\n",
            "SYM\n",
            "LS\n",
            "#\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "punctuation = [\",\", \".\", '``', \"''\", ':', '$', '-LRB-','-RRB-','#']\n",
        "punctuation_enc = encode_into_numbers([punctuation], label_to_idx)[0]\n",
        "punctuation_enc.append(0) #padding symbol\n",
        "print(punctuation_enc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EbB_Q_bUVoy",
        "outputId": "7cf4cef3-ddcb-4544-f50a-149f0ed8b14d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 11, 27, 29, 31, 34, 37, 38, 45, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_f1(model, x, y_true, punctuation):\n",
        "    y_true = np.argmax(y_true, axis=2).flatten()\n",
        "    y_pred = np.argmax(model.predict(x), axis=2).flatten()\n",
        "    \n",
        "    mask = np.in1d(y_true, punctuation_enc, invert=True)  #mask to exclude punctuation symbols\n",
        "    unique_pos = [pos for pos in np.unique(y_true) if not pos in punctuation_enc]\n",
        "\n",
        "    return f1_score(y_true[mask], \n",
        "                    y_pred[mask], \n",
        "                    average='macro', \n",
        "                    labels=unique_pos, \n",
        "                    zero_division=0)"
      ],
      "metadata": {
        "id": "_3gTiEYHFMyP"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_scores = {key: compute_f1(models[key],x_st[\"val\"],y_cat[\"val\"],punctuation_enc ) for key in models.keys()}\n",
        "f1_scores = {k: v for k, v in sorted(f1_scores.items(), key=lambda item: item[1], reverse=True)}  #sort dictionary by f1-score values\n",
        "print()\n",
        "for model, score in f1_scores.items():\n",
        "  print(f\"Model {model} f1-score on validation set: {score:.5f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1_NpLlpXJsJ",
        "outputId": "05042527-8714-4e29-d561-9d4f45905e04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 0s 10ms/step\n",
            "41/41 [==============================] - 0s 6ms/step\n",
            "41/41 [==============================] - 0s 10ms/step\n",
            "41/41 [==============================] - 0s 7ms/step\n",
            "\n",
            "Model baseline f1-score on validation set: 0.74402\n",
            "Model baseline_with_2_LSTM f1-score on validation set: 0.73706\n",
            "Model baseline_with_2_Dense f1-score on validation set: 0.73266\n",
            "Model baseline_with_GRU f1-score on validation set: 0.72795\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = models[list(f1_scores.keys())[0]]\n",
        "best_model.name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "35pcJJlpsLWY",
        "outputId": "5908f286-f53c-4a51-8a7f-aa6b40c3ecdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'baseline'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## History inspection"
      ],
      "metadata": {
        "id": "Qrrm53qAY0lY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_history(history_dict):\n",
        "  fig, axes = plt.subplots(nrows=len(history_dict.keys()), ncols=2, figsize=(4*len(history_dict.keys()), 16))\n",
        "  for idx, model in enumerate(history_dict.keys()):\n",
        "    model_history = history_dict[model].history\n",
        "\n",
        "    loss = pd.DataFrame(np.array([model_history['loss'], model_history['val_loss']]).T, columns=['Train', 'Validation'])\n",
        "    min_loss = loss['Validation'].min()\n",
        "    min_loss_idx = loss['Validation'].idxmin()\n",
        "    accuracy = pd.DataFrame(np.array([model_history['accuracy'], model_history['val_accuracy']]).T, columns=['Train', 'Validation'])\n",
        "    max_acc = accuracy['Validation'].min()\n",
        "    max_acc_idx = accuracy['Validation'].idxmin()\n",
        "\n",
        "    sb.lineplot(data=loss, ax=axes[idx][0])\n",
        "    sb.lineplot(data=accuracy, ax=axes[idx][1])\n",
        "\n",
        "    axes[idx][0].axhline(min_loss, color='lightgray', linestyle='-')\n",
        "    axes[idx][0].axvline(min_loss_idx, color='lightgray', linestyle='-')\n",
        "    axes[idx][1].axhline(max_acc, color='lightgray', linestyle='-')\n",
        "    axes[idx][1].axvline(max_acc_idx, color='lightgray', linestyle='-')\n",
        "\n",
        "    axes[idx][0].set_xlabel('Epochs')\n",
        "    axes[idx][1].set_xlabel('Epochs')\n",
        "    axes[idx][0].set_ylabel('Loss')\n",
        "    axes[idx][1].set_ylabel('Accuracy')\n",
        "    axes[idx][0].set_title(f\"{model} loss\")\n",
        "    axes[idx][1].set_title(f\"{model} accuracy\")\n",
        "\n",
        "  fig.tight_layout()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "Jb3lUpfiY6pD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_history(history)"
      ],
      "metadata": {
        "id": "Vdg1HQiapqA0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ba9b7b46-a237-4fea-b75c-5eb051d16e26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-a8489d1127d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-54-cf0fb4c755b2>\u001b[0m in \u001b[0;36mplot_history\u001b[0;34m(history_dict)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mmax_acc_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Validation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midxmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0msb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlineplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0msb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlineplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'AxesSubplot' object is not subscriptable"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x1152 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Improve the model\n",
        "The baseline model seems to be the best one up to this point, so we are going to try to improve its performances. \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VFKzK_bApBDY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A straightforward modification is to move to GloVe embedding with size 300, as up to now the one with size 50 has been used. This new embedding is much heavier than the previous one, but is ensures better results. Considering these, all the following models will use this the embedding matrix built with this embedding size.\n",
        "\n",
        "Then we are going to test what happens if we increase to 200 the number of LSTM hidden units, which previously were set to 100. \n",
        "\n",
        "Finally, as already pointed out, it is clear that the model starts to overfit, so we willl introduce a dropout layer and droput on the LSTM layer to check if it is goinf to reduce overfitting."
      ],
      "metadata": {
        "id": "ayLNdjmHp7Np"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIMENSION_BIGGER = 300\n",
        "units_bigger = 200\n",
        "dropout_percentage = 0.2"
      ],
      "metadata": {
        "id": "H2cMkpDKHu2I"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove_emb_model_bigger = load_GloVe_embedding(EMBEDDING_DIMENSION_BIGGER)"
      ],
      "metadata": {
        "id": "-Lg6NyPptoJ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1c36b64-8743-4c8a-c7c7-7d04ba99788e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 376.1/376.1MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix_bigger = build_embedding_matrix(glove_emb_model_bigger, \n",
        "                                                EMBEDDING_DIMENSION_BIGGER,\n",
        "                                                word_to_idx_train)\n",
        "print(embedding_matrix_bigger.shape)\n",
        "\n",
        "embedding_matrix_bigger = extend_embedding_matrix(glove_emb_model_bigger, \n",
        "                                                  embedding_matrix_bigger,\n",
        "                                                  word_to_idx_val)\n",
        "print(embedding_matrix_bigger.shape)\n",
        "\n",
        "embedding_matrix_bigger = extend_embedding_matrix(glove_emb_model_bigger, \n",
        "                                                  embedding_matrix_bigger,\n",
        "                                                  word_to_idx_test)\n",
        "print(embedding_matrix_bigger.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBBMeIgpG5wZ",
        "outputId": "59ba610f-c0ce-407a-fa5b-d2f85382b487"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400318/400318 [00:01<00:00, 342715.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(400319, 300)\n",
            "(400475, 300)\n",
            "(400571, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_final_model(num_pos, \n",
        "                      embedding_matrix, \n",
        "                      name = 'final',\n",
        "                      units = units_bigger, \n",
        "                      dropout_layer = True,\n",
        "                      dropout_LSTM = True,\n",
        "                      dropout_percentage = dropout_percentage):\n",
        "  inputs = Input(shape=(None,), dtype=\"int32\")\n",
        "\n",
        "  \n",
        "  m = Embedding(input_dim=embedding_matrix.shape[0], \n",
        "                output_dim=embedding_matrix.shape[1],\n",
        "                mask_zero=True, \n",
        "                weights=[embedding_matrix], \n",
        "                trainable=False)(inputs)\n",
        "\n",
        "  if dropout_layer:\n",
        "    m = Dropout(dropout_percentage)(m)\n",
        "\n",
        "  if dropout_LSTM:\n",
        "    m = Bidirectional(LSTM(units=units, return_sequences=True, dropout=dropout_percentage))(m)\n",
        "  else:\n",
        "    m = Bidirectional(LSTM(units=units, return_sequences=True))(m)\n",
        "\n",
        "  m = Dense(num_pos, activation='softmax')(m)\n",
        "\n",
        "  return Model(inputs, m, name=name)"
      ],
      "metadata": {
        "id": "CSxVArvAHb6M"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_models = {}\n",
        "final_models_history = {}\n",
        "final_models_f1_scores = {}"
      ],
      "metadata": {
        "id": "qI30HhVYbP3D"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Final model with more LSTM hidden units, a dropout layer and dropout on LSTM"
      ],
      "metadata": {
        "id": "lTV8gJPwYWBc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_models['units_bigger-dropout_layer-dropout_LSTM'] = build_final_model(num_pos = number_pos, \n",
        "                                embedding_matrix = embedding_matrix_bigger, \n",
        "                                name = \"units_bigger-dropout_layer-dropout_LSTM\",\n",
        "                                units = units_bigger,\n",
        "                                dropout_layer = True,\n",
        "                                dropout_LSTM = True,\n",
        "                                dropout_percentage = dropout_percentage) "
      ],
      "metadata": {
        "id": "aKvIE742I7y6"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_models['units_bigger-dropout_layer-dropout_LSTM'].summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxatNV0VKEIM",
        "outputId": "47235f6e-3c5a-424d-a6b9-ec9bdc31c933"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"units_bigger-dropout_layer-dropout_LSTM\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, None, 300)         120171300 \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, None, 300)         0         \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirectio  (None, None, 400)        801600    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, None, 46)          18446     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 120,991,346\n",
            "Trainable params: 820,046\n",
            "Non-trainable params: 120,171,300\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_models['units_bigger-dropout_layer-dropout_LSTM'].compile(optimizer ='adam', \n",
        "                           loss = 'categorical_crossentropy', \n",
        "                           metrics = ['accuracy'])\n",
        "final_models_history['units_bigger-dropout_layer-dropout_LSTM'] = final_models['units_bigger-dropout_layer-dropout_LSTM'].fit(x=x_st[\"train\"], \n",
        "                   y=y_cat[\"train\"], \n",
        "                   batch_size=batch_size, \n",
        "                   epochs=epochs, \n",
        "                   validation_data=(x_st[\"val\"], y_cat[\"val\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcRzUJJ0Jz-l",
        "outputId": "b76543c0-4b32-4c1c-c2fe-5488084717a2"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "197/197 [==============================] - 15s 37ms/step - loss: 0.1244 - accuracy: 0.6614 - val_loss: 0.1861 - val_accuracy: 0.8196\n",
            "Epoch 2/30\n",
            "197/197 [==============================] - 4s 22ms/step - loss: 0.0527 - accuracy: 0.8421 - val_loss: 0.1384 - val_accuracy: 0.8629\n",
            "Epoch 3/30\n",
            "197/197 [==============================] - 4s 22ms/step - loss: 0.0416 - accuracy: 0.8715 - val_loss: 0.1184 - val_accuracy: 0.8820\n",
            "Epoch 4/30\n",
            "197/197 [==============================] - 5s 26ms/step - loss: 0.0346 - accuracy: 0.8919 - val_loss: 0.1075 - val_accuracy: 0.8903\n",
            "Epoch 5/30\n",
            "197/197 [==============================] - 6s 32ms/step - loss: 0.0295 - accuracy: 0.9076 - val_loss: 0.0973 - val_accuracy: 0.9008\n",
            "Epoch 6/30\n",
            "197/197 [==============================] - 5s 23ms/step - loss: 0.0253 - accuracy: 0.9196 - val_loss: 0.0902 - val_accuracy: 0.9060\n",
            "Epoch 7/30\n",
            "197/197 [==============================] - 5s 26ms/step - loss: 0.0217 - accuracy: 0.9323 - val_loss: 0.0874 - val_accuracy: 0.9087\n",
            "Epoch 8/30\n",
            "197/197 [==============================] - 4s 23ms/step - loss: 0.0189 - accuracy: 0.9422 - val_loss: 0.0850 - val_accuracy: 0.9121\n",
            "Epoch 9/30\n",
            "197/197 [==============================] - 4s 22ms/step - loss: 0.0162 - accuracy: 0.9504 - val_loss: 0.0819 - val_accuracy: 0.9149\n",
            "Epoch 10/30\n",
            "197/197 [==============================] - 4s 23ms/step - loss: 0.0140 - accuracy: 0.9581 - val_loss: 0.0803 - val_accuracy: 0.9171\n",
            "Epoch 11/30\n",
            "197/197 [==============================] - 4s 22ms/step - loss: 0.0119 - accuracy: 0.9653 - val_loss: 0.0796 - val_accuracy: 0.9177\n",
            "Epoch 12/30\n",
            "197/197 [==============================] - 4s 22ms/step - loss: 0.0103 - accuracy: 0.9697 - val_loss: 0.0805 - val_accuracy: 0.9184\n",
            "Epoch 13/30\n",
            "197/197 [==============================] - 5s 23ms/step - loss: 0.0088 - accuracy: 0.9750 - val_loss: 0.0785 - val_accuracy: 0.9217\n",
            "Epoch 14/30\n",
            "197/197 [==============================] - 6s 30ms/step - loss: 0.0078 - accuracy: 0.9781 - val_loss: 0.0810 - val_accuracy: 0.9191\n",
            "Epoch 15/30\n",
            "197/197 [==============================] - 6s 33ms/step - loss: 0.0067 - accuracy: 0.9807 - val_loss: 0.0800 - val_accuracy: 0.9213\n",
            "Epoch 16/30\n",
            "197/197 [==============================] - 6s 28ms/step - loss: 0.0057 - accuracy: 0.9852 - val_loss: 0.0815 - val_accuracy: 0.9201\n",
            "Epoch 17/30\n",
            "197/197 [==============================] - 4s 22ms/step - loss: 0.0053 - accuracy: 0.9855 - val_loss: 0.0807 - val_accuracy: 0.9210\n",
            "Epoch 18/30\n",
            "197/197 [==============================] - 5s 25ms/step - loss: 0.0046 - accuracy: 0.9876 - val_loss: 0.0847 - val_accuracy: 0.9202\n",
            "Epoch 19/30\n",
            "197/197 [==============================] - 5s 25ms/step - loss: 0.0040 - accuracy: 0.9901 - val_loss: 0.0864 - val_accuracy: 0.9200\n",
            "Epoch 20/30\n",
            "197/197 [==============================] - 6s 29ms/step - loss: 0.0035 - accuracy: 0.9917 - val_loss: 0.0831 - val_accuracy: 0.9226\n",
            "Epoch 21/30\n",
            "197/197 [==============================] - 4s 22ms/step - loss: 0.0032 - accuracy: 0.9916 - val_loss: 0.0843 - val_accuracy: 0.9227\n",
            "Epoch 22/30\n",
            "197/197 [==============================] - 4s 23ms/step - loss: 0.0031 - accuracy: 0.9920 - val_loss: 0.0861 - val_accuracy: 0.9223\n",
            "Epoch 23/30\n",
            "197/197 [==============================] - 4s 23ms/step - loss: 0.0029 - accuracy: 0.9932 - val_loss: 0.0896 - val_accuracy: 0.9204\n",
            "Epoch 24/30\n",
            "197/197 [==============================] - 4s 22ms/step - loss: 0.0026 - accuracy: 0.9932 - val_loss: 0.0900 - val_accuracy: 0.9217\n",
            "Epoch 25/30\n",
            "197/197 [==============================] - 4s 22ms/step - loss: 0.0025 - accuracy: 0.9942 - val_loss: 0.0909 - val_accuracy: 0.9218\n",
            "Epoch 26/30\n",
            "197/197 [==============================] - 4s 22ms/step - loss: 0.0022 - accuracy: 0.9945 - val_loss: 0.0915 - val_accuracy: 0.9214\n",
            "Epoch 27/30\n",
            "197/197 [==============================] - 5s 25ms/step - loss: 0.0020 - accuracy: 0.9954 - val_loss: 0.0929 - val_accuracy: 0.9215\n",
            "Epoch 28/30\n",
            "197/197 [==============================] - 5s 24ms/step - loss: 0.0020 - accuracy: 0.9951 - val_loss: 0.0897 - val_accuracy: 0.9242\n",
            "Epoch 29/30\n",
            "197/197 [==============================] - 7s 33ms/step - loss: 0.0017 - accuracy: 0.9961 - val_loss: 0.0926 - val_accuracy: 0.9214\n",
            "Epoch 30/30\n",
            "197/197 [==============================] - 5s 24ms/step - loss: 0.0016 - accuracy: 0.9962 - val_loss: 0.0939 - val_accuracy: 0.9225\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_models[\"units_bigger-dropout_layer-dropout_LSTM\"].save_weights('./units_bigger-dropout_layer-dropout_LSTM.h5')"
      ],
      "metadata": {
        "id": "TFUml6V-daxH"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_models_f1_scores[\"units_bigger-dropout_layer-dropout_LSTM\"] = compute_f1(final_models[\"units_bigger-dropout_layer-dropout_LSTM\"],x_st[\"val\"],y_cat[\"val\"],punctuation_enc)\n",
        "final_models_f1_scores[\"units_bigger-dropout_layer-dropout_LSTM\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RdYmRq_Kbb6",
        "outputId": "3dbb8de1-a9c5-417f-fc8e-685a9755a9bc"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 3s 9ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8070168630965344"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Final model with smaller number of LSTM hidden units, dropout layer and dropout on LSTM"
      ],
      "metadata": {
        "id": "RsT_nmVpeG4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_models['dropout_layer-dropout_LSTM'] = build_final_model(num_pos = number_pos, \n",
        "                                embedding_matrix = embedding_matrix_bigger, \n",
        "                                name = \"dropout_layer-dropout_LSTM\",\n",
        "                                units = units,\n",
        "                                dropout_layer = True,\n",
        "                                dropout_LSTM = True,\n",
        "                                dropout_percentage = dropout_percentage) "
      ],
      "metadata": {
        "id": "gmqSuoHTeG4h"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_models['dropout_layer-dropout_LSTM'].summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82749ad3-cf0b-4a96-d406-8585d1977ce8",
        "id": "sAzkcQgbeG4h"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"dropout_layer-dropout_LSTM\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_3 (Embedding)     (None, None, 300)         120171300 \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, None, 300)         0         \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirectio  (None, None, 200)        320800    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, None, 46)          9246      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 120,501,346\n",
            "Trainable params: 330,046\n",
            "Non-trainable params: 120,171,300\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_models['dropout_layer-dropout_LSTM'].compile(optimizer ='adam', \n",
        "                           loss = 'categorical_crossentropy', \n",
        "                           metrics = ['accuracy'])\n",
        "\n",
        "final_models_history['dropout_layer-dropout_LSTM'] = final_models['dropout_layer-dropout_LSTM'].fit(x=x_st[\"train\"], \n",
        "                   y=y_cat[\"train\"], \n",
        "                   batch_size=batch_size, \n",
        "                   epochs=epochs, \n",
        "                   validation_data=(x_st[\"val\"], y_cat[\"val\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d5c9b29-77c2-4daf-be2b-6f1daf60d47d",
        "id": "TV1E6j2qeG4i"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "197/197 [==============================] - 15s 37ms/step - loss: 0.1496 - accuracy: 0.6069 - val_loss: 0.2307 - val_accuracy: 0.7864\n",
            "Epoch 2/30\n",
            "197/197 [==============================] - 5s 24ms/step - loss: 0.0634 - accuracy: 0.8180 - val_loss: 0.1594 - val_accuracy: 0.8478\n",
            "Epoch 3/30\n",
            "197/197 [==============================] - 5s 23ms/step - loss: 0.0484 - accuracy: 0.8545 - val_loss: 0.1347 - val_accuracy: 0.8693\n",
            "Epoch 4/30\n",
            "197/197 [==============================] - 5s 23ms/step - loss: 0.0408 - accuracy: 0.8780 - val_loss: 0.1182 - val_accuracy: 0.8834\n",
            "Epoch 5/30\n",
            "197/197 [==============================] - 5s 23ms/step - loss: 0.0358 - accuracy: 0.8903 - val_loss: 0.1082 - val_accuracy: 0.8905\n",
            "Epoch 6/30\n",
            "197/197 [==============================] - 5s 23ms/step - loss: 0.0317 - accuracy: 0.9027 - val_loss: 0.1001 - val_accuracy: 0.8969\n",
            "Epoch 7/30\n",
            "197/197 [==============================] - 5s 23ms/step - loss: 0.0285 - accuracy: 0.9120 - val_loss: 0.0946 - val_accuracy: 0.9020\n",
            "Epoch 8/30\n",
            "197/197 [==============================] - 5s 23ms/step - loss: 0.0255 - accuracy: 0.9214 - val_loss: 0.0904 - val_accuracy: 0.9067\n",
            "Epoch 9/30\n",
            "197/197 [==============================] - 5s 23ms/step - loss: 0.0230 - accuracy: 0.9291 - val_loss: 0.0861 - val_accuracy: 0.9111\n",
            "Epoch 10/30\n",
            "197/197 [==============================] - 6s 31ms/step - loss: 0.0207 - accuracy: 0.9364 - val_loss: 0.0833 - val_accuracy: 0.9137\n",
            "Epoch 11/30\n",
            "197/197 [==============================] - 5s 26ms/step - loss: 0.0190 - accuracy: 0.9424 - val_loss: 0.0801 - val_accuracy: 0.9172\n",
            "Epoch 12/30\n",
            "197/197 [==============================] - 5s 23ms/step - loss: 0.0172 - accuracy: 0.9481 - val_loss: 0.0792 - val_accuracy: 0.9180\n",
            "Epoch 13/30\n",
            "197/197 [==============================] - 5s 23ms/step - loss: 0.0156 - accuracy: 0.9519 - val_loss: 0.0769 - val_accuracy: 0.9208\n",
            "Epoch 14/30\n",
            "197/197 [==============================] - 5s 23ms/step - loss: 0.0145 - accuracy: 0.9564 - val_loss: 0.0771 - val_accuracy: 0.9207\n",
            "Epoch 15/30\n",
            "197/197 [==============================] - 5s 23ms/step - loss: 0.0134 - accuracy: 0.9607 - val_loss: 0.0753 - val_accuracy: 0.9231\n",
            "Epoch 16/30\n",
            "197/197 [==============================] - 5s 23ms/step - loss: 0.0121 - accuracy: 0.9631 - val_loss: 0.0749 - val_accuracy: 0.9234\n",
            "Epoch 17/30\n",
            "197/197 [==============================] - 5s 23ms/step - loss: 0.0116 - accuracy: 0.9649 - val_loss: 0.0741 - val_accuracy: 0.9251\n",
            "Epoch 18/30\n",
            "197/197 [==============================] - 5s 25ms/step - loss: 0.0106 - accuracy: 0.9690 - val_loss: 0.0767 - val_accuracy: 0.9217\n",
            "Epoch 19/30\n",
            "197/197 [==============================] - 5s 23ms/step - loss: 0.0097 - accuracy: 0.9717 - val_loss: 0.0756 - val_accuracy: 0.9243\n",
            "Epoch 20/30\n",
            "197/197 [==============================] - 5s 23ms/step - loss: 0.0090 - accuracy: 0.9733 - val_loss: 0.0752 - val_accuracy: 0.9251\n",
            "Epoch 21/30\n",
            "197/197 [==============================] - 5s 24ms/step - loss: 0.0086 - accuracy: 0.9740 - val_loss: 0.0747 - val_accuracy: 0.9254\n",
            "Epoch 22/30\n",
            "197/197 [==============================] - 5s 23ms/step - loss: 0.0081 - accuracy: 0.9756 - val_loss: 0.0738 - val_accuracy: 0.9271\n",
            "Epoch 23/30\n",
            "197/197 [==============================] - 5s 23ms/step - loss: 0.0073 - accuracy: 0.9783 - val_loss: 0.0774 - val_accuracy: 0.9256\n",
            "Epoch 24/30\n",
            "197/197 [==============================] - 5s 23ms/step - loss: 0.0069 - accuracy: 0.9797 - val_loss: 0.0773 - val_accuracy: 0.9252\n",
            "Epoch 25/30\n",
            "197/197 [==============================] - 5s 23ms/step - loss: 0.0064 - accuracy: 0.9812 - val_loss: 0.0798 - val_accuracy: 0.9255\n",
            "Epoch 26/30\n",
            "197/197 [==============================] - 5s 23ms/step - loss: 0.0063 - accuracy: 0.9810 - val_loss: 0.0772 - val_accuracy: 0.9265\n",
            "Epoch 27/30\n",
            "197/197 [==============================] - 5s 23ms/step - loss: 0.0058 - accuracy: 0.9832 - val_loss: 0.0794 - val_accuracy: 0.9265\n",
            "Epoch 28/30\n",
            "197/197 [==============================] - 5s 24ms/step - loss: 0.0055 - accuracy: 0.9845 - val_loss: 0.0780 - val_accuracy: 0.9271\n",
            "Epoch 29/30\n",
            "197/197 [==============================] - 6s 30ms/step - loss: 0.0053 - accuracy: 0.9845 - val_loss: 0.0803 - val_accuracy: 0.9249\n",
            "Epoch 30/30\n",
            "197/197 [==============================] - 5s 24ms/step - loss: 0.0050 - accuracy: 0.9855 - val_loss: 0.0809 - val_accuracy: 0.9268\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_models[\"dropout_layer-dropout_LSTM\"].save_weights('./dropout_layer-dropout_LSTM.h5')"
      ],
      "metadata": {
        "id": "PinvhU5LeG4i"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_models_f1_scores[\"dropout_layer-dropout_LSTM\"] = compute_f1(final_models[\"dropout_layer-dropout_LSTM\"],x_st[\"val\"],y_cat[\"val\"],punctuation_enc)\n",
        "final_models_f1_scores[\"dropout_layer-dropout_LSTM\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5bYtoY5eG4j",
        "outputId": "455bdc56-494a-448f-9bf1-1a8026f2137f"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 4s 8ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8059982154811096"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Final model with more LSTM hidden units and a dropout layer"
      ],
      "metadata": {
        "id": "FG04_USsfRrb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_models['units_bigger-dropout_layer'] = build_final_model(num_pos = number_pos, \n",
        "                                embedding_matrix = embedding_matrix_bigger, \n",
        "                                name = \"units_bigger-dropout_layer\",\n",
        "                                units = units_bigger,\n",
        "                                dropout_layer = True,\n",
        "                                dropout_LSTM = False,\n",
        "                                dropout_percentage = dropout_percentage) "
      ],
      "metadata": {
        "id": "Uo3Hq0EpfRrc"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_models['units_bigger-dropout_layer'].summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c2868f5-1761-4615-88a8-97ebd7bf00e2",
        "id": "hVkgLZ-9fRrc"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"units_bigger-dropout_layer\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_7 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_6 (Embedding)     (None, None, 300)         120171300 \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, None, 300)         0         \n",
            "                                                                 \n",
            " bidirectional_6 (Bidirectio  (None, None, 400)        801600    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, None, 46)          18446     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 120,991,346\n",
            "Trainable params: 820,046\n",
            "Non-trainable params: 120,171,300\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_models['units_bigger-dropout_layer'].compile(optimizer ='adam', \n",
        "                           loss = 'categorical_crossentropy', \n",
        "                           metrics = ['accuracy'])\n",
        "\n",
        "final_models_history['units_bigger-dropout_layer'] = final_models['units_bigger-dropout_layer'].fit(x=x_st[\"train\"], \n",
        "                   y=y_cat[\"train\"], \n",
        "                   batch_size=batch_size, \n",
        "                   epochs=epochs, \n",
        "                   validation_data=(x_st[\"val\"], y_cat[\"val\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d30fd08-3b29-47dc-a329-fa498a84ffd2",
        "id": "RNChkSYCfRrd"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "197/197 [==============================] - 15s 36ms/step - loss: 0.1182 - accuracy: 0.6836 - val_loss: 0.1769 - val_accuracy: 0.8302\n",
            "Epoch 2/30\n",
            "197/197 [==============================] - 4s 23ms/step - loss: 0.0473 - accuracy: 0.8599 - val_loss: 0.1315 - val_accuracy: 0.8703\n",
            "Epoch 3/30\n",
            "197/197 [==============================] - 4s 22ms/step - loss: 0.0360 - accuracy: 0.8910 - val_loss: 0.1124 - val_accuracy: 0.8877\n",
            "Epoch 4/30\n",
            "197/197 [==============================] - 4s 22ms/step - loss: 0.0290 - accuracy: 0.9105 - val_loss: 0.1022 - val_accuracy: 0.8951\n",
            "Epoch 5/30\n",
            "197/197 [==============================] - 4s 23ms/step - loss: 0.0239 - accuracy: 0.9262 - val_loss: 0.0929 - val_accuracy: 0.9039\n",
            "Epoch 6/30\n",
            "197/197 [==============================] - 5s 26ms/step - loss: 0.0196 - accuracy: 0.9413 - val_loss: 0.0867 - val_accuracy: 0.9093\n",
            "Epoch 7/30\n",
            "197/197 [==============================] - 6s 30ms/step - loss: 0.0161 - accuracy: 0.9520 - val_loss: 0.0839 - val_accuracy: 0.9137\n",
            "Epoch 8/30\n",
            "197/197 [==============================] - 6s 29ms/step - loss: 0.0131 - accuracy: 0.9620 - val_loss: 0.0868 - val_accuracy: 0.9105\n",
            "Epoch 9/30\n",
            "197/197 [==============================] - 4s 22ms/step - loss: 0.0106 - accuracy: 0.9705 - val_loss: 0.0804 - val_accuracy: 0.9181\n",
            "Epoch 10/30\n",
            "197/197 [==============================] - 5s 26ms/step - loss: 0.0083 - accuracy: 0.9774 - val_loss: 0.0823 - val_accuracy: 0.9182\n",
            "Epoch 11/30\n",
            "197/197 [==============================] - 6s 31ms/step - loss: 0.0068 - accuracy: 0.9826 - val_loss: 0.0828 - val_accuracy: 0.9167\n",
            "Epoch 12/30\n",
            "197/197 [==============================] - 6s 31ms/step - loss: 0.0055 - accuracy: 0.9871 - val_loss: 0.0828 - val_accuracy: 0.9171\n",
            "Epoch 13/30\n",
            "197/197 [==============================] - 6s 32ms/step - loss: 0.0043 - accuracy: 0.9909 - val_loss: 0.0841 - val_accuracy: 0.9179\n",
            "Epoch 14/30\n",
            "197/197 [==============================] - 6s 31ms/step - loss: 0.0037 - accuracy: 0.9921 - val_loss: 0.0851 - val_accuracy: 0.9171\n",
            "Epoch 15/30\n",
            "197/197 [==============================] - 5s 27ms/step - loss: 0.0030 - accuracy: 0.9939 - val_loss: 0.0862 - val_accuracy: 0.9177\n",
            "Epoch 16/30\n",
            "197/197 [==============================] - 6s 28ms/step - loss: 0.0025 - accuracy: 0.9958 - val_loss: 0.0873 - val_accuracy: 0.9172\n",
            "Epoch 17/30\n",
            "197/197 [==============================] - 5s 24ms/step - loss: 0.0023 - accuracy: 0.9957 - val_loss: 0.0878 - val_accuracy: 0.9189\n",
            "Epoch 18/30\n",
            "197/197 [==============================] - 4s 22ms/step - loss: 0.0019 - accuracy: 0.9969 - val_loss: 0.0907 - val_accuracy: 0.9173\n",
            "Epoch 19/30\n",
            "197/197 [==============================] - 4s 23ms/step - loss: 0.0015 - accuracy: 0.9979 - val_loss: 0.0924 - val_accuracy: 0.9179\n",
            "Epoch 20/30\n",
            "197/197 [==============================] - 4s 23ms/step - loss: 0.0014 - accuracy: 0.9979 - val_loss: 0.0921 - val_accuracy: 0.9187\n",
            "Epoch 21/30\n",
            "197/197 [==============================] - 5s 26ms/step - loss: 0.0013 - accuracy: 0.9982 - val_loss: 0.0920 - val_accuracy: 0.9195\n",
            "Epoch 22/30\n",
            "197/197 [==============================] - 6s 31ms/step - loss: 0.0012 - accuracy: 0.9980 - val_loss: 0.0923 - val_accuracy: 0.9208\n",
            "Epoch 23/30\n",
            "197/197 [==============================] - 4s 23ms/step - loss: 0.0012 - accuracy: 0.9979 - val_loss: 0.0947 - val_accuracy: 0.9209\n",
            "Epoch 24/30\n",
            "197/197 [==============================] - 5s 27ms/step - loss: 0.0010 - accuracy: 0.9986 - val_loss: 0.0940 - val_accuracy: 0.9203\n",
            "Epoch 25/30\n",
            "197/197 [==============================] - 5s 26ms/step - loss: 9.2283e-04 - accuracy: 0.9984 - val_loss: 0.0990 - val_accuracy: 0.9195\n",
            "Epoch 26/30\n",
            "197/197 [==============================] - 6s 29ms/step - loss: 9.3515e-04 - accuracy: 0.9983 - val_loss: 0.0973 - val_accuracy: 0.9199\n",
            "Epoch 27/30\n",
            "197/197 [==============================] - 4s 22ms/step - loss: 8.9073e-04 - accuracy: 0.9984 - val_loss: 0.0998 - val_accuracy: 0.9194\n",
            "Epoch 28/30\n",
            "197/197 [==============================] - 5s 23ms/step - loss: 8.2394e-04 - accuracy: 0.9989 - val_loss: 0.0987 - val_accuracy: 0.9184\n",
            "Epoch 29/30\n",
            "197/197 [==============================] - 6s 29ms/step - loss: 0.0011 - accuracy: 0.9975 - val_loss: 0.0953 - val_accuracy: 0.9203\n",
            "Epoch 30/30\n",
            "197/197 [==============================] - 4s 22ms/step - loss: 7.7746e-04 - accuracy: 0.9988 - val_loss: 0.1036 - val_accuracy: 0.9178\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_models[\"units_bigger-dropout_layer\"].save_weights('./units_bigger-dropout_layer.h5')"
      ],
      "metadata": {
        "id": "sM8IjjunfRrd"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_models_f1_scores[\"units_bigger-dropout_layer\"] = compute_f1(final_models[\"units_bigger-dropout_layer\"],x_st[\"val\"],y_cat[\"val\"],punctuation_enc)\n",
        "final_models_f1_scores[\"units_bigger-dropout_layer\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89M3YeQ-fRrd",
        "outputId": "bec884d2-087a-445c-d5ce-92c34720d9ff"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 4s 11ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7976888497376766"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Final model with more LSTM hidden units and dropout on LSTM"
      ],
      "metadata": {
        "id": "nhmqyuEAhOzv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_models['units_bigger-dropout_LSTM'] = build_final_model(num_pos = number_pos, \n",
        "                                embedding_matrix = embedding_matrix_bigger, \n",
        "                                name = \"units_bigger-dropout_LSTM\",\n",
        "                                units = units_bigger,\n",
        "                                dropout_layer = False,\n",
        "                                dropout_LSTM = True,\n",
        "                                dropout_percentage = dropout_percentage) "
      ],
      "metadata": {
        "id": "_cX6TMUthOzw"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_models['units_bigger-dropout_LSTM'].summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b3a2dc1-3f2a-43b5-bfe5-5dbbbd160feb",
        "id": "uFB-npJKhOzw"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"units_bigger-dropout_LSTM\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_8 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_7 (Embedding)     (None, None, 300)         120171300 \n",
            "                                                                 \n",
            " bidirectional_7 (Bidirectio  (None, None, 400)        801600    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, None, 46)          18446     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 120,991,346\n",
            "Trainable params: 820,046\n",
            "Non-trainable params: 120,171,300\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_models['units_bigger-dropout_LSTM'].compile(optimizer ='adam', \n",
        "                           loss = 'categorical_crossentropy', \n",
        "                           metrics = ['accuracy'])\n",
        "\n",
        "final_models_history['units_bigger-dropout_LSTM'] = final_models['units_bigger-dropout_LSTM'].fit(x=x_st[\"train\"], \n",
        "                   y=y_cat[\"train\"], \n",
        "                   batch_size=batch_size, \n",
        "                   epochs=epochs, \n",
        "                   validation_data=(x_st[\"val\"], y_cat[\"val\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e8cc5c9-e7f4-41cd-c33f-d34085303e51",
        "id": "BxcgnKUVhOzx"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "197/197 [==============================] - 15s 37ms/step - loss: 0.1178 - accuracy: 0.6837 - val_loss: 0.1764 - val_accuracy: 0.8311\n",
            "Epoch 2/30\n",
            "197/197 [==============================] - 6s 28ms/step - loss: 0.0462 - accuracy: 0.8646 - val_loss: 0.1310 - val_accuracy: 0.8702\n",
            "Epoch 3/30\n",
            "197/197 [==============================] - 6s 31ms/step - loss: 0.0347 - accuracy: 0.8938 - val_loss: 0.1131 - val_accuracy: 0.8867\n",
            "Epoch 4/30\n",
            "197/197 [==============================] - 5s 26ms/step - loss: 0.0279 - accuracy: 0.9146 - val_loss: 0.1027 - val_accuracy: 0.8936\n",
            "Epoch 5/30\n",
            "197/197 [==============================] - 6s 31ms/step - loss: 0.0229 - accuracy: 0.9296 - val_loss: 0.0947 - val_accuracy: 0.9033\n",
            "Epoch 6/30\n",
            "197/197 [==============================] - 6s 31ms/step - loss: 0.0184 - accuracy: 0.9449 - val_loss: 0.0875 - val_accuracy: 0.9085\n",
            "Epoch 7/30\n",
            "197/197 [==============================] - 5s 25ms/step - loss: 0.0151 - accuracy: 0.9553 - val_loss: 0.0861 - val_accuracy: 0.9117\n",
            "Epoch 8/30\n",
            "197/197 [==============================] - 7s 35ms/step - loss: 0.0120 - accuracy: 0.9648 - val_loss: 0.0878 - val_accuracy: 0.9103\n",
            "Epoch 9/30\n",
            "197/197 [==============================] - 5s 25ms/step - loss: 0.0097 - accuracy: 0.9739 - val_loss: 0.0838 - val_accuracy: 0.9134\n",
            "Epoch 10/30\n",
            "197/197 [==============================] - 6s 30ms/step - loss: 0.0076 - accuracy: 0.9802 - val_loss: 0.0837 - val_accuracy: 0.9164\n",
            "Epoch 11/30\n",
            "197/197 [==============================] - 6s 32ms/step - loss: 0.0060 - accuracy: 0.9855 - val_loss: 0.0841 - val_accuracy: 0.9165\n",
            "Epoch 12/30\n",
            "197/197 [==============================] - 7s 37ms/step - loss: 0.0048 - accuracy: 0.9894 - val_loss: 0.0858 - val_accuracy: 0.9150\n",
            "Epoch 13/30\n",
            "197/197 [==============================] - 5s 23ms/step - loss: 0.0038 - accuracy: 0.9927 - val_loss: 0.0881 - val_accuracy: 0.9164\n",
            "Epoch 14/30\n",
            "197/197 [==============================] - 4s 23ms/step - loss: 0.0031 - accuracy: 0.9943 - val_loss: 0.0888 - val_accuracy: 0.9167\n",
            "Epoch 15/30\n",
            "197/197 [==============================] - 4s 23ms/step - loss: 0.0025 - accuracy: 0.9959 - val_loss: 0.0904 - val_accuracy: 0.9147\n",
            "Epoch 16/30\n",
            "197/197 [==============================] - 4s 23ms/step - loss: 0.0022 - accuracy: 0.9965 - val_loss: 0.0906 - val_accuracy: 0.9173\n",
            "Epoch 17/30\n",
            "197/197 [==============================] - 4s 23ms/step - loss: 0.0018 - accuracy: 0.9977 - val_loss: 0.0920 - val_accuracy: 0.9180\n",
            "Epoch 18/30\n",
            "197/197 [==============================] - 4s 22ms/step - loss: 0.0015 - accuracy: 0.9980 - val_loss: 0.0942 - val_accuracy: 0.9163\n",
            "Epoch 19/30\n",
            "197/197 [==============================] - 4s 22ms/step - loss: 0.0013 - accuracy: 0.9984 - val_loss: 0.0959 - val_accuracy: 0.9164\n",
            "Epoch 20/30\n",
            "197/197 [==============================] - 4s 23ms/step - loss: 0.0012 - accuracy: 0.9985 - val_loss: 0.0990 - val_accuracy: 0.9159\n",
            "Epoch 21/30\n",
            "197/197 [==============================] - 4s 23ms/step - loss: 0.0011 - accuracy: 0.9986 - val_loss: 0.0964 - val_accuracy: 0.9188\n",
            "Epoch 22/30\n",
            "197/197 [==============================] - 5s 23ms/step - loss: 0.0011 - accuracy: 0.9986 - val_loss: 0.0981 - val_accuracy: 0.9179\n",
            "Epoch 23/30\n",
            "197/197 [==============================] - 4s 22ms/step - loss: 9.3622e-04 - accuracy: 0.9988 - val_loss: 0.1013 - val_accuracy: 0.9164\n",
            "Epoch 24/30\n",
            "197/197 [==============================] - 4s 22ms/step - loss: 8.4066e-04 - accuracy: 0.9989 - val_loss: 0.1004 - val_accuracy: 0.9182\n",
            "Epoch 25/30\n",
            "197/197 [==============================] - 4s 23ms/step - loss: 7.5008e-04 - accuracy: 0.9990 - val_loss: 0.1040 - val_accuracy: 0.9162\n",
            "Epoch 26/30\n",
            "197/197 [==============================] - 4s 23ms/step - loss: 6.6828e-04 - accuracy: 0.9992 - val_loss: 0.1053 - val_accuracy: 0.9176\n",
            "Epoch 27/30\n",
            "197/197 [==============================] - 4s 23ms/step - loss: 6.3588e-04 - accuracy: 0.9993 - val_loss: 0.1055 - val_accuracy: 0.9176\n",
            "Epoch 28/30\n",
            "197/197 [==============================] - 5s 23ms/step - loss: 6.6259e-04 - accuracy: 0.9991 - val_loss: 0.1041 - val_accuracy: 0.9178\n",
            "Epoch 29/30\n",
            "197/197 [==============================] - 4s 23ms/step - loss: 7.9356e-04 - accuracy: 0.9986 - val_loss: 0.1112 - val_accuracy: 0.9139\n",
            "Epoch 30/30\n",
            "197/197 [==============================] - 5s 27ms/step - loss: 7.0205e-04 - accuracy: 0.9986 - val_loss: 0.1067 - val_accuracy: 0.9183\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_models[\"units_bigger-dropout_LSTM\"].save_weights('./units_bigger-dropout_LSTM.h5')"
      ],
      "metadata": {
        "id": "hEjy8-iohOzx"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_models_f1_scores[\"units_bigger-dropout_LSTM\"] = compute_f1(final_models[\"units_bigger-dropout_LSTM\"],x_st[\"val\"],y_cat[\"val\"],punctuation_enc)\n",
        "final_models_f1_scores[\"units_bigger-dropout_LSTM\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jesaInWlhOzy",
        "outputId": "cfb629a9-eef7-41a8-a169-3769d9654498"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 4s 12ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8010435556741525"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Final model with only bigger embedding size"
      ],
      "metadata": {
        "id": "1LOJJ7FSjn2C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_models['bigger_embedding_size'] = build_final_model(num_pos = number_pos, \n",
        "                                embedding_matrix = embedding_matrix_bigger, \n",
        "                                name = \"bigger_embedding_size\",\n",
        "                                units = units,\n",
        "                                dropout_layer = False,\n",
        "                                dropout_LSTM = False) "
      ],
      "metadata": {
        "id": "xfqTZCTajn2D"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_models['bigger_embedding_size'].summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ece4bf4e-4470-4cce-be13-ea1ad5668405",
        "id": "biZToKa9jn2E"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"bigger_embedding_size\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_9 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_8 (Embedding)     (None, None, 300)         120171300 \n",
            "                                                                 \n",
            " bidirectional_8 (Bidirectio  (None, None, 200)        320800    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, None, 46)          9246      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 120,501,346\n",
            "Trainable params: 330,046\n",
            "Non-trainable params: 120,171,300\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_models['bigger_embedding_size'].compile(optimizer ='adam', \n",
        "                           loss = 'categorical_crossentropy', \n",
        "                           metrics = ['accuracy'])\n",
        "\n",
        "final_models_history['bigger_embedding_size'] = final_models['bigger_embedding_size'].fit(x=x_st[\"train\"], \n",
        "                   y=y_cat[\"train\"], \n",
        "                   batch_size=batch_size, \n",
        "                   epochs=epochs, \n",
        "                   validation_data=(x_st[\"val\"], y_cat[\"val\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bef27934-3a69-4cf3-9354-a9e4244e5a16",
        "id": "dHPjiTTmjn2F"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "197/197 [==============================] - 15s 38ms/step - loss: 0.1387 - accuracy: 0.6435 - val_loss: 0.2126 - val_accuracy: 0.8074\n",
            "Epoch 2/30\n",
            "197/197 [==============================] - 5s 24ms/step - loss: 0.0512 - accuracy: 0.8584 - val_loss: 0.1457 - val_accuracy: 0.8627\n",
            "Epoch 3/30\n",
            "197/197 [==============================] - 5s 24ms/step - loss: 0.0360 - accuracy: 0.8992 - val_loss: 0.1228 - val_accuracy: 0.8838\n",
            "Epoch 4/30\n",
            "197/197 [==============================] - 5s 24ms/step - loss: 0.0282 - accuracy: 0.9201 - val_loss: 0.1081 - val_accuracy: 0.8932\n",
            "Epoch 5/30\n",
            "197/197 [==============================] - 5s 24ms/step - loss: 0.0227 - accuracy: 0.9354 - val_loss: 0.0991 - val_accuracy: 0.9013\n",
            "Epoch 6/30\n",
            "197/197 [==============================] - 5s 24ms/step - loss: 0.0183 - accuracy: 0.9495 - val_loss: 0.0916 - val_accuracy: 0.9074\n",
            "Epoch 7/30\n",
            "197/197 [==============================] - 5s 24ms/step - loss: 0.0149 - accuracy: 0.9608 - val_loss: 0.0891 - val_accuracy: 0.9097\n",
            "Epoch 8/30\n",
            "197/197 [==============================] - 5s 24ms/step - loss: 0.0119 - accuracy: 0.9704 - val_loss: 0.0881 - val_accuracy: 0.9109\n",
            "Epoch 9/30\n",
            "197/197 [==============================] - 5s 24ms/step - loss: 0.0096 - accuracy: 0.9780 - val_loss: 0.0854 - val_accuracy: 0.9137\n",
            "Epoch 10/30\n",
            "197/197 [==============================] - 5s 27ms/step - loss: 0.0076 - accuracy: 0.9848 - val_loss: 0.0846 - val_accuracy: 0.9140\n",
            "Epoch 11/30\n",
            "197/197 [==============================] - 6s 33ms/step - loss: 0.0059 - accuracy: 0.9898 - val_loss: 0.0857 - val_accuracy: 0.9151\n",
            "Epoch 12/30\n",
            "197/197 [==============================] - 6s 29ms/step - loss: 0.0046 - accuracy: 0.9930 - val_loss: 0.0869 - val_accuracy: 0.9135\n",
            "Epoch 13/30\n",
            "197/197 [==============================] - 6s 31ms/step - loss: 0.0036 - accuracy: 0.9957 - val_loss: 0.0898 - val_accuracy: 0.9133\n",
            "Epoch 14/30\n",
            "197/197 [==============================] - 5s 28ms/step - loss: 0.0028 - accuracy: 0.9973 - val_loss: 0.0894 - val_accuracy: 0.9144\n",
            "Epoch 15/30\n",
            "197/197 [==============================] - 7s 37ms/step - loss: 0.0022 - accuracy: 0.9983 - val_loss: 0.0912 - val_accuracy: 0.9130\n",
            "Epoch 16/30\n",
            "197/197 [==============================] - 5s 26ms/step - loss: 0.0017 - accuracy: 0.9989 - val_loss: 0.0917 - val_accuracy: 0.9144\n",
            "Epoch 17/30\n",
            "197/197 [==============================] - 5s 24ms/step - loss: 0.0014 - accuracy: 0.9993 - val_loss: 0.0953 - val_accuracy: 0.9130\n",
            "Epoch 18/30\n",
            "197/197 [==============================] - 5s 24ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0970 - val_accuracy: 0.9134\n",
            "Epoch 19/30\n",
            "197/197 [==============================] - 5s 24ms/step - loss: 8.6595e-04 - accuracy: 0.9998 - val_loss: 0.0997 - val_accuracy: 0.9122\n",
            "Epoch 20/30\n",
            "197/197 [==============================] - 5s 24ms/step - loss: 7.4109e-04 - accuracy: 0.9998 - val_loss: 0.0990 - val_accuracy: 0.9131\n",
            "Epoch 21/30\n",
            "197/197 [==============================] - 5s 24ms/step - loss: 6.4723e-04 - accuracy: 0.9997 - val_loss: 0.1009 - val_accuracy: 0.9130\n",
            "Epoch 22/30\n",
            "197/197 [==============================] - 5s 24ms/step - loss: 5.3380e-04 - accuracy: 0.9998 - val_loss: 0.1023 - val_accuracy: 0.9130\n",
            "Epoch 23/30\n",
            "197/197 [==============================] - 5s 24ms/step - loss: 4.2174e-04 - accuracy: 0.9999 - val_loss: 0.1045 - val_accuracy: 0.9122\n",
            "Epoch 24/30\n",
            "197/197 [==============================] - 5s 24ms/step - loss: 3.5368e-04 - accuracy: 1.0000 - val_loss: 0.1050 - val_accuracy: 0.9123\n",
            "Epoch 25/30\n",
            "197/197 [==============================] - 5s 24ms/step - loss: 3.0493e-04 - accuracy: 1.0000 - val_loss: 0.1070 - val_accuracy: 0.9131\n",
            "Epoch 26/30\n",
            "197/197 [==============================] - 5s 24ms/step - loss: 2.6587e-04 - accuracy: 1.0000 - val_loss: 0.1086 - val_accuracy: 0.9126\n",
            "Epoch 27/30\n",
            "197/197 [==============================] - 7s 35ms/step - loss: 2.2470e-04 - accuracy: 1.0000 - val_loss: 0.1098 - val_accuracy: 0.9126\n",
            "Epoch 28/30\n",
            "197/197 [==============================] - 6s 29ms/step - loss: 1.9614e-04 - accuracy: 1.0000 - val_loss: 0.1106 - val_accuracy: 0.9116\n",
            "Epoch 29/30\n",
            "197/197 [==============================] - 5s 25ms/step - loss: 1.6894e-04 - accuracy: 1.0000 - val_loss: 0.1127 - val_accuracy: 0.9124\n",
            "Epoch 30/30\n",
            "197/197 [==============================] - 6s 29ms/step - loss: 1.8203e-04 - accuracy: 0.9999 - val_loss: 0.1168 - val_accuracy: 0.9092\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_models[\"bigger_embedding_size\"].save_weights('./bigger_embedding_size.h5')"
      ],
      "metadata": {
        "id": "tq6vJ58gjn2G"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_models_f1_scores[\"bigger_embedding_size\"] = compute_f1(final_models[\"bigger_embedding_size\"],x_st[\"val\"],y_cat[\"val\"],punctuation_enc)\n",
        "final_models_f1_scores[\"bigger_embedding_size\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75da14c0-88ee-4c2a-de67-992ff97bc560",
        "id": "_62C4gqvjn2G"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 3s 8ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.772912677062819"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check histories"
      ],
      "metadata": {
        "id": "bA-PMiaqkYhL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_history(final_models_history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "OYIW1TpWkdIo",
        "outputId": "436958a3-e14a-4f3c-eb1e-7fa0fea9ab0a"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-90-9af34d57a611>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_models_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'plot_history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation on test set"
      ],
      "metadata": {
        "id": "127lQqFIcDIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f1_scores_test = {}"
      ],
      "metadata": {
        "id": "aX2G4moTQXBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_scores_test[\"final\"] = compute_f1(models[\"final\"],x_st[\"test\"],y_cat[\"test\"],punctuation_enc)\n",
        "f1_scores_test[\"final\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "528p21iwQPL6",
        "outputId": "bb80006d-44f5-44fc-abec-876e95680602"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21/21 [==============================] - 0s 8ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8515409177582665"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "MQ0PSVGsWZBW",
        "sI97CALV0C34",
        "_0Xhe6fjWvqv",
        "qZUuz-bW_BO3",
        "mzQ6qRPF_86z",
        "b5RNdNYYHYwQ",
        "EElOhl9F-x9-",
        "mAv5AHB_REM5",
        "2HIZO1d8SPFq",
        "dzdywqEviQla",
        "i7frWEJB-OS7",
        "RTAMzroP_YH0",
        "ZdF3KP3rB7ee",
        "Qrrm53qAY0lY",
        "lTV8gJPwYWBc",
        "RsT_nmVpeG4g",
        "FG04_USsfRrb",
        "nhmqyuEAhOzv",
        "1LOJJ7FSjn2C",
        "bA-PMiaqkYhL"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}